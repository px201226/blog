{"componentChunkName":"component---src-pages-search-jsx","path":"/search/","result":{"data":{"allMarkdownRemark":{"nodes":[{"excerpt":"버퍼 I/O 운영체제의 I/O는 모두 버퍼를 통해 이루어진다. 프로세스는 버퍼에서 데이터를 채우는 (쓰기) 또는 버퍼에 데이터를 비우는 (읽기) 작업을 운영 체제에 요청함으로써 I/O를 수행한다.\n모든 데이터는 이 메커니즘을 통해 프로세스 내부로 이동하거나 나간다.\n 위 그림에서 사용자 공간(user space)과 커널 공간(kernel space)의 개…","fields":{"slug":"/java-nio-buffer/"},"frontmatter":{"date":"October 03, 2023","title":"Java NIO 파헤치기 - Buffer","tags":["Java"]},"rawMarkdownBody":"\n\n## 버퍼 I/O\n운영체제의 I/O는 모두 버퍼를 통해 이루어진다. 프로세스는 버퍼에서 데이터를 채우는 (쓰기) 또는 버퍼에 데이터를 비우는 (읽기) 작업을 운영 체제에 요청함으로써 I/O를 수행한다.\n모든 데이터는 이 메커니즘을 통해 프로세스 내부로 이동하거나 나간다.\n![운영체제 I/O](buffer/img_6.png)\n\n위 그림에서 사용자 공간(user space)과 커널 공간(kernel space)의 개념에 주목하자.\n사용자 공간은 일반 프로세스가 실행되는 곳이다. JVM도 사용자 공간에서 실행된다. 사용자 공간은 특권이 없어 하드웨어에 직접 접근할 수 없다.\n커널 공간은 운영 체제가 위치하는 곳으로 특별한 권한을 가진다. 모든 I/O는 커널 공간을 통해 이루어진다.\n\n프로세스가 I/O 작업을 요청하면 시스템 호출을 수행하여 커널로 제어권을 전달한다.\n커널은 필요한 데이터를 찾아 사용자 공간의 지정된 버퍼로 전송한다.\n커널은 데이터를 캐시하거나 미리 가져오려고 시도하기 때문에 프로세스가 요청하는 데이터는 이미 커널 공간에 있을 수 있다.\n\n운영체제의 버퍼 단위 I/O와 기존 java.io의 스트림 기반 I/O 모델 간에 불일치가 있다.\n운영 체제는 데이터를 큰 덩어리(버퍼)로 이동시키려고 하는 반면, 스트림 기반 I/O 클래스는 작은 단위(단일 바이트나 텍스트의 줄)로 데이터를 처리하려고 한다.\nJava의 NIO는 이러한 불일치를 해결하기 위해 도입되었다.\n\n## Buffer\nBuffer 객체는 고정된 양의 데이터를 관리하는 컨테이너이다. 버퍼는 채워지고 비워진다.\n버퍼는 채널과 밀접하게 작동한다. 채널은 I/O 전송이 이루어지는 포털이며, 버퍼는 그 데이터 전송의 출발지나 대상이다. 나가는 전송의 경우, 전송하고 싶은 데이터는 버퍼에 넣어져 채널로 전달된다.\n들어오는 전송의 경우, 채널은 제공하는 버퍼에 데이터를 저장한다.\n버퍼 사이의 협력하는 객체 사이의 이러한 핸드오프는 데이터 처리의 효율성을 향상시키는 핵심이다\n\n![Buffer 종류](buffer/img.png)\n\n### Buffer 속성\nBuffer 에는 4가지 속성이 있다.\n```JAVA\npublic abstract class Buffer {\n\n\t// Invariants: mark <= position <= limit <= capacity\n\tprivate int mark = -1;\n\tprivate int position = 0;\n\tprivate int limit;\n\tprivate int capacity;\n}\n```\n\n- mark : 기억된 위치. mark() 호출시 mark = position으로 설정된다. reset() 호출시 position = mark로 설정된다. 설정되기 전까지 mark는 정의되지 않는다.\n- position: 다음에 읽거나 쓸 요소의 인덱스. 상대적인 get() 및 put() 메서드에 의해 자동으로 업데이트 된다.\n- limit: 버퍼에서 읽거나 쓸 수 있는 첫 번째 요소가 아닌 요소. 즉, 버퍼 내의 활성 요소의 수를 나타낸다.\n- capacity: 버퍼가 가질 수 있는 데이터 요소의 최대 개수. 버퍼가 생성될 때 설정되며 변경할 수 없다.\n\n이 네 가지 속성 간의 관계는 항상 다음을 만족한다.    \n0 ≤ mark ≤ position ≤ limit ≤ capacity\n\n![Buffer.png](buffer/img_1.png)\n\n예를 들어, 10의 용량을 가진 Buffer는 위의 그림과 같이 속성이 초기화된다.\nmark는 mark()가 호출되기 전까지 정의되지 않고, postition은 0으로 설정되고, capcatity와 limit은 10으로 설정된다.\n이 상태에서 데이터를 5개만 쓴 후에 버퍼를 읽기 모드로 전환한다면(flip()을 호출), limit는 5로 설정된다.\n즉, 처음 5개의 데이터 요소만 읽을 수 있다는 얘기이다.\n\n\n### Buffer 접근\nByteBuffer와 같은 Buffer 클래스의 서브클래스에는 get(), put() 연산이 존재한다.\n이 연산은 상대적 연산과 절대적 연산으로 수행된다.\n\n```JAVA\npublic abstract class ByteBuffer extends Buffer implements Comparable {\n\t\n  public abstract byte get();\n  public abstract byte get(int index);\n  public abstract ByteBuffer put (byte b);\n  public abstract ByteBuffer put (int index, byte b);\n}\n```\n버퍼는 데이터 요소를 일정한 크기로 저장하는데 필요에 따라 버퍼를 완전히 채우지 않고 일부분만 채우고 버퍼를 다른 곳으로 전송하거나 읽을 수 있어야 할 것 이다.\n이때, 어디까지 데이터가 채워졌는지, 다음 데이터가 어디에 위치해야 하는지 등을 알아야 되는데 이를 위해 position 이 있다.\nByteBuffer 클래스의 index 인수를 받지 않는 get()과 put() 메서드는 이 position을 이용한 상대적 연산이다.\n\n상대적 연산은 position 값을 기준으로 데이터를 읽거나 쓰고, get(), put()을 호출하면 position 값이 1 증가한다.\n만약, put()을 호출할 때 position >= limit 이 되면 BufferOverflowException 발생하고\n마찬가지로 get()을 호출할 때 position >= limit 이라면 BufferUnderflowException 이 발생한다.\n\n절대적 연산은 특정 버퍼 위치(index)에 직접 데이터를 읽거나 쓴다.\n이 연산은 position의 값을 변경하지 않고, 버퍼의 인덱스 범위를 벗어나면 IndexOutOfBoundsException이 발생한다.\n\n### Buffer 채우기\n아래 코드는 capacity가 10인 ByteBuffer를 할당하고, 'hello' 라는 문자를 바이트로 버퍼에 채우는 코드이다.\n```JAVA\nByteBuffer byteBuffer = ByteBuffer.allocate(10);\nbyte[] bytes = \"hello\".getBytes();\nbyteBuffer.put(bytes);\n```\n![buffer 채우기](buffer/img_2.png)\n\n\n### Flipping\nBuffer를 채우기 버퍼의 데이터를 읽기 위해서는 Flipping 을 통해 Buffer의 동작을 전환해야한다.\nBuffer에 'hello'가 채워진 상태에서(position=5)에서 get()을 하게 되면 빈 값을 가져올 것 이다.\n따라서, Buffer에 채워진 데이터를 읽기 위해서는 아래와 같은 작업이 필요하다.\n```JAVA\nbuffer.limit(buffer.position()).position(0);\n```\nbuffer의 읽을 수 있는 값을 현재 buffer의 position으로 설정하고, 현재 position을 읽기 작업을 위해 0으로 설정한다.\n이 작업은 buffer.flip() 메서드와 같은 동작을 한다.\n\n\n### Draining\nDraining 이란 Buffer에서 데이터를 읽어 오는 것을 의미한다. 위에서 Buffer에 데이터를 읽기 전에 Flipping 이라는 작업이 필요하다는 것을 설명했다.\nFlipping후 Buffer의 읽기모드로 바꿔 position 에서 시작하여 limit 전까지의 데이터를 읽어야 한다.\n\n이 때, 사용되는 메서드가 hasRemaining() 과 remaining() 이다.\nhasRemaining() 는 현재 position과 limit을 비교하여 읽을 수 있는 데이터 있는지 여부를 반환한다.\nremaining()은 현재 position에서 limit 까지 남아있는 데이터의 수를 반환한다.\n```JAVA\nfor (int i = 0; buffer.hasRemaining(), i++) {\n\tbyteArray[i] = buffer.get();\n}\n```\n\n### Marking\nmark()메서드는 호출될 때 Buffer 클래스의 mark 속성을 현재 position 값으로 변경한다.\n이는 위리를 기억하고 있다가 나중에 해당 위치로 돌아갈 수 있도록 하기 위함이다.\nreset() 메서드는 position을 현재 mark 값으로 설정한다. mark 값이 정의되어 있지 않다면 Exception이 발생한다.\n\n밑에 코드를 실행하면 Buffer는 아래 그림과 같은 상태가 된다. \n```JAVA\nbuffer.position(2).mark().position(4);\n```\n![Marking](buffer/img_3.png)\n\nmark=2 이고, 현재 position이 4이므로 이 상태에서 read를 하게 되면 'ow' 를 읽을 것 이다.\n여기서 reset()을 하면 현재 position 값을 2로 설정된다.\n\n![reset 후 상태](buffer/img_4.png)\n\n\n### Comparing\n버퍼 두개가 동일하다는 것은 다음 조건을 만족해야 한다.\n- 두 객체가 같은 타입이어야 한다.\n- 두 버퍼에 남아있는 요소의 수가 같아야 한다. (즉, position에서 limit까지 요소 수)\n- 남아있는 데이터 요소의 순서가 각 버퍼에서 동일해야 한다.\n\ncompare 는 다음과 같은 기준으로 비교된다. 여기서 크다 작다는 버퍼의 남아있는 요소의 수가 많냐 적냐를 말한다.\n- 음수: 메서드를 호출한 버퍼가 전달된 버퍼보다 작다.\n- 0: 두 버퍼가 동일하다.\n- 양수: 메서드를 호출한 버퍼가 전달된 버퍼보다 크다.\n\n### Buffer의 생성\nBuffer는 생성자를 통해 직접 생성할 수 없다. 인스턴스를 생성하기 위해서는 각 클래스의 정적 팩토리 메서드를 사용해야 한다.\n\n```JAVA\n// 사이즈 100인 char형 buffer \nCharBuffer charBuffer = CharBuffer.allocate(100);\n\n// wrap 을 사용한 버퍼 생성\nchar [] myArray = new char [100];\nCharBuffer charbuffer = CharBuffer.wrap (myArray);\n\n// CharSequence를 입력받는 wrap\nCharBuffer.wrap (\"Hello World\");\n```\nwrap을 이용한 Buffer는 읽기/쓰기 작업 시, 실제 myArray를 참조하게 된다. 이렇게 생성한 Buffer를 non-direct buffer라고 한다.\nnon-direct buffer는 실제 데이터를 저장하기 위해 내부적으로 배열을 사용한다. 이 배열이 바로 backing arrays 라고 한다. wrap 의 예에서는 myArray가 backing array가 된다.\n이와 반대로, direct Buffer 는 JVM 밖의 위치하는 네이티브 메모리 영역에 직접 할당되어 GC에 영향받지 않는다.\n\n\n### ByteBuffer\n기본 원시 타입(int, long, char 등)에 대한 버퍼가 있지만 그 중에서도 ByteBuffer 는 특별하다.\n기본 원시 타입은 연손적인 바이트 시퀀스로 메모리에 저장된다.\n또한, JVM과 운영 체제 간에 데이터를 이동할 때 바이트 중심으로 이루어지기 때문이다. 때문에 다른 원시 타입에는 없는 ByteBuffer 만의 고유 API를 가진다.\n\n| Data Type | Size (bytes) |\n|-----------|--------------|\n| Byte      | 1            |\n| Char      | 2            |\n| Short     | 2            |\n| Int       | 4            |\n| Long      | 8            |\n| Float     | 4            |\n| Double    | 8            |\n\n> HTTP 에서는 8비트로 구성된 바이트를 옥텟(octet)이라고 한다. 이는 초기 컴퓨터에서 바이트가 꼭 8비트를 의미하는 것은 아니였기 때문이다.\n\nByteBuffer 는 다른 버퍼 유형과 다르게 채널에 의한 I/O 작업의 대상이 될 수 있다. 채널은 ByteBuffer만을 인자로 받기 때문이다.\n운영제제의 I/O는 연속된 바이트 메모리 영역에서 수행되는데, JVM 내에서의 바이트 배열은 연속적으로 메모리에 저장되지 않을 수 있으며, 가비지 컬렉터에 의해 언제든지 이동될 수 있다.\n그래서 바이트 배열이 연속적인 메모리 공간에 저장되는지는 JVM의 구현에 따라 달라질 수 있다.\n\n이런 문제점을 해결하기 위해 direct buffer가 있다. direct buffer는 채널 및 네이티브 I/O 함수와 상호작용하기 위해 설계되었다.\ndirect buffer는 네이티브 메모리 영역에 직접 할당되어 데이터를 JVM의 메모리에서 운영 체제의 메모리로 복사할 필요 없이 바로 네이티브 I/O 연산에 사용할 수 있다.\n그래서 일반적으로 I/O 작업 시에는 direct buffer를 사용하는데, non-direct buffer를 채널로 전달하게 되면 채널은 내부적으로 다음과 같은 작업을 수행한다.\n1. 임시 direct buffer 를 생성한다.\n2. non-direct buffer의 데이터를 direct buffer로 복사한다.\n3. direct buffer를 사용하여 I/O 작업을 수행한다.\n4. 작업이 끝나면, 임시 direct buffer는 GC된다.\n\n대신 일반적으로 direct buffer 생성 비용은 non-direct buffer 생성 비용보다 클 수 있다. direct 버퍼는 운영체제 코드를 통해 할당되기 때문이다. \ndirect buffer는 ByteBuffer 클래스의 allocateDirect() 정적 팩토리 메서드로 생성할 수 있다.\n\n\n## View Buffer\n뷰 버퍼는 원본 버퍼와 데이터를 공유하지만, 자체적인 속성 (예: position, limit, capacity 등)을 가진다.\n이는 뷰 버퍼를 통해 데이터를 읽거나 쓸 때 원본 버퍼의 데이터가 변경되며, 반대의 경우도 마찬가지이다.\n위에서 나온 duplicate()와 wrap() 메서드로 만든 버퍼도 뷰 버퍼의 일종으로 볼 수 있다.\n\n뷰 버퍼의 주요 사용 사례는 ByteBuffer의 바이트 데이터를 다른 원시 타입으로 해석할 필요가 있을 때이다.\n이 때, ByteBuffer의 asIntBuffer(), asCharBuffer() 등의 팩토리 메서드를 통해 원하는 원시 타입의 뷰 버퍼를 생성할 수 있다.\n\n```shell\npublic abstract class ByteBuffer extends Buffer implements Comparable {\n  \n  public abstract CharBuffer asCharBuffer();\n  public abstract ShortBuffer asShortBuffer();\n  public abstract IntBuffer asIntBuffer();\n  public abstract LongBuffer asLongBuffer();\n  public abstract FloatBuffer asFloatBuffer();\n  public abstract DoubleBuffer asDoubleBuffer();\n}    \n\n```\n![char형 view buffer](buffer/img_5.png)\n"},{"excerpt":"Socket Option 소켓 옵션은 자바의 Socket 클래스가 사용하는 네트워크 소켓이 데이터를 어떻게 보내고 받을 것인지를 결정한다. 자바에서는 클라이언트 측 소켓에 대해 9가지 옵션이 존재한다. TCP_NODELAY SO_BINDADDR SO_TIMEOUT SO_LINGER SO_SNDBUF SO_RCVBUF SO_KEEPALIVE OOBINLIN…","fields":{"slug":"/socket_option/"},"frontmatter":{"date":"September 29, 2023","title":"Java의 Socket Option 정리","tags":["Java"]},"rawMarkdownBody":"\n## Socket Option\n소켓 옵션은 자바의 Socket 클래스가 사용하는 네트워크 소켓이 데이터를 어떻게 보내고 받을 것인지를 결정한다. 자바에서는 클라이언트 측 소켓에 대해 9가지 옵션이 존재한다.\n- TCP\\_NODELAY\n- SO\\_BINDADDR\n- SO\\_TIMEOUT\n- SO\\_LINGER\n- SO\\_SNDBUF\n- SO\\_RCVBUF\n- SO\\_KEEPALIVE\n- OOBINLINE\n- IP\\_TOS\n\njava.net.SocketOptions 인터페이스에 각 옵션이 정의되어 있고 socket 클래스의 메서드를 통해 옵션을 설정할 수 있다. 여기서는 주요 옵션들에 기능에 대해 정리한다.\n\n\n## TCP\\_NODELAY\n\n```JAVA\npublic void setTcpNoDelay(boolean on) throws SocketException\npublic boolean getTcpNoDelay() throws SocketException\n```\n\nTCP는 기본적으로 Nagle’s 알고리즘을 사용하여 작은 패킷들을 합쳐서 하나의 큰 패킷으로 전송한다. 이렇게 하는 이유는 작은 패킷들을 하나씩 보내는 것보다, 여러 패킷을 하나의 큰 패킷으로 합쳐서 보내면 전송 효율이 높아지기 때문이다. Nagle’s 알고리즘은 데이터를 효율적으로 전송하기 좋은 방법이지만, 특정 상황에서는 좋은 방법이 아닐 수 있다. 예를 들면 실시간 빠른 응답이 필요한 애플리케이션(게임, GUI 프로그램 등)에서는 패킷이 지연 없이 바로 전송되어야 한다. TCP\\_NODELAY를 true로 설정하면, Nagle’s 알고리즘이 비활성화되어 작은 패킷도 즉시 전송된다.\n즉, 패킷을 버퍼링하지 않고 즉시 전송하는 것을 의미한다.\n\n\n\n## SO\\_LINGER\n\n```JAVA\npublic void setSoLinger(boolean on, int seconds) throws SocketException\npublic int getSoLinger() throws SocketException\n\n```\nSO\\_LINGER 옵션은 소켓을 닫을 때 아직 전송되지 않은 패킷을 어떻게 처리될지를 결정한다.\n큰 파일을 다른 컴퓨터에게 전송하고 있는 상태에서 파일 전송이 완전히 끝나기 전에 close() 메서드를 호출하면 어떻게 될까? 기본적으로 close() 메서드를 호출하면 연결을 종료하려고 시도하고, 아직 전송되지 않은 데이터가 있다면 그 데이터를 원격지에 전송하려고 한다. 이렇게 하는 이유는 연결을 종료하기 전에 전송되지 않은 데이터를 안전하게 전송하기 위해서이다. 따라서, close() 메서드가 즉시 반환되었다고 시스템 내부 작업이 완전히 끝났다고 판단할 수는 없다. 이 옵션은 소켓을 close 할 때 처리를 세밀하게 조정할 수 있다.\n\n- 비활성화된 경우 (-1): 소켓은 바로 닫히며 아직 전송되지 않은 데이터가 있다면 시스템은 그 데이터를 전송하려고 한다. 이 때 얼마나 오랜 시간 동안 노력할지는 시스템의 기본 설정에 따라 다르다.\n- 활성화된 경우 (0 이상의 값): 설정된 시간(초) 동안 아직 전송되지 않은 데이터를 전송하려고 노력하고, 그 시간이 지나면 남은 데이터를 전송하지 않고 소켓을 close한다.\n- 0인 경우: 아직 전송되지 않은 모든 데이터는 버려지고 즉시 소켓이 close된다.\n\n```JAVA\nsocket.setSoLinger(false, -1); // SO\\_LINGER 옵션 비활성화\nsocket.setSoLinger(true, 300); // close() 후, 5분 동안 추가 데이터 전송을 허용\n```\n\ngetSoLinger() 메서드는 SO\\_LINGER 옵션이 비활성화되어 있다면 -1을 반환하고, 그게 아니라면 현재 소켓의 \"linger\" 시간 즉, 닫히기 전에 남은 데이터를 전송하는 데 허용된 시간을 초 단위로 반환한다.\n\n\n## SO\\_TIMEOUT\n\n```JAVA\npublic void setSoTimeout(int milliseconds) throws SocketException\npublic int getSoTimeout() throws SocketException\n```\n\nSO\\_TIMEOUT 옵션은 너무 오랫동안 데이터를 기다리지 않도록 할 수 있다.\nsockect.read() 메서드는 소켓에서 데이터를 읽을 때까지 블록킹된다. 이 옵션을  사용하면 read() 메서드가 무한정으로 블록킹 되지 않도록 타임아웃을 설정할 수 있다. 0 으로 설정할 경우 타임아웃이 없음을 의미하고 기본값으로 사용된다.\n예를 들어, 1분의 read timeout을 설정하고 싶다면 socket.setSoTimeout(60000); 로 설정한다.\n\n\n## SO\\_RCVBUF, SO\\_SNDBUF\n\n```JAVA\npublic void setReceiveBufferSize(int size) throws SocketException, IllegalArgumentException\npublic int getReceiveBufferSize() throws SocketException\npublic void setSendBufferSize(int size) throws SocketException, IllegalArgumentException\npublic int getSendBufferSize() throws SocketException\n```\n\nSO\\_RCVBUF는 네트워크 입력을 위한 버퍼 크기를, SO\\_SNDBUF는 네트워크 출력을 위한 버퍼 크기를 제어한다.\n파일 전송과 같은 상황에서는 큰 버퍼가 이점이 있지만, 게임과 같은 실시간 통신이 필요한 상황의 경우에는 버퍼를 사용할 경우 전송 지연이 발생할 수 있다. 운영체제 마다 다르지만 일반적으로 128바이트가 일반적인 기본값이다.\n버퍼 크기는 소켓의 최대 속도를 결정하는데, 최대 가능한 대역폭은 버퍼 크기를 지연시간으로 나눈 값이다.\n예를 들어, 두 호스트 간의 전송 지연시간이 0.5초에 버퍼 크기가 128바이트라면 128byte/0.5s = 256byte/1s가 된다. 지연시간은 애플리케이션이 제어할 수 없는 변수이므로 버퍼 사이즈를 두 배로 늘리면 대역폭도 두 배로 증가한다.\n물론 네트워크가 처리할 수 있는 대역폭은 제한되어 있기 때문에 그 보다 작게 설정해야 한다.\n\njava doc을 확인해보면 setReceiveBufferSize, setSendBufferSize 는 네트워크 I/O 버퍼를 설정하기 위한 크기에 대한 힌트로 사용된다.\n> Sets the SO\\_SNDBUF option to the specified value for this Socket. The SO\\_SNDBUF option is used by the platform's networking code as a hint for the size to set the underlying network I/O buffers.\n\n이는 set으로 설정하더라도 실제 구현에서는 값이 달라질 수 있다는 얘기이다. 실제 버퍼가 어떤 크기로 설정되어 있는지 확인하기 위해 getSendBufferSize() 메서드로 확인할 수 있다.\n\n\n## SO\\_KEEPALIVE\n\n```JAVA\npublic void setKeepAlive(boolean on) throws SocketException \npublic boolean getKeepAlive() throws SocketException\n```\n\nSO\\_KEEPALIVE는 HTTP 프로토콜에 Keepalive 헤더와는 다른 옵션이다. SO\\_KEEPALIVE 옵션은 서버가 죽어있는지 헬스 체크를 확인하기 위해 주기적으로 패킷을 보내는 옵션이다. 서버가 이 패킷에 응답하지 않으면 클라이언트는 응답을 받을 때 까지 시도하다가 결국 응답을 받지 못하면 소켓을 close한다. 네트워크 연결이 적절히 종료되지 않고 클라이언트나 서버 중 한 쪽에서만 종료된 경우를 half open 연결이라고 하는데, SO\\_KEEPALIVE는 그 상태를 감지하기 위한 기능이다.\n\nTCP Keepalive의 상세 설정은 운영체제 파라미터를 통해 설정할 수 있다.\n아래는 Linux에서 keepalive 관련 설정값들이다.\n- /proc/sys/net/ipv4/tcp\\_keepalive\\_time   \n  이 파일에 저장된 값은 TCP keep-alive 패킷이 처음으로 전송되기 시작하는 시간을 초 단위로 나타낸다.\n  일반적으로 기본값은 7200초(2시간)이다. 즉, 연결이 비활성 상태로 있을 때 2시간 후에 첫 번째 keep-alive 패킷이 전송된다.\n\n- /proc/sys/net/ipv4/tcp\\_keepalive\\_intvl   \n  이 파일에 저장된 값은 keep-alive 패킷 간의 간격을 초 단위로 나타낸다.\n  예를 들어, 첫 번째 keep-alive 패킷에 대한 응답이 없으면 이 파일에 지정된 간격 후에 두 번째 패킷이 전송된다.\n  일반적으로 기본값은 75초이다.\n\n- /proc/sys/net/ipv4/tcp\\_keepalive\\_probes    \n  이 파일에 저장된 값은 연속적으로 전송될 수 있는 keep-alive 패킷의 최대 횟수를 나타낸다.\n  일반적으로 기본값은 9이다. 즉, keep-alive 패킷 9회 연속으로 응답이 없을 경우 연결이 끊어진다.\n\n\n## OOBINLINE\n\n```JAVA\npublic void sendUrgentData(int data) throws IOException\npublic void setOOBInline(boolean on) throws SocketException \npublic boolean getOOBInline() throws SocketException\n````\n\nTCP에는 긴급 데이터(Urgent Data)를 바로 전송하는 기능이 있다. sendUrgentData() 메서드를 사용하면 int data를 거의 바로 전송한다. 전송될 바이트는 data 파라미터의 최하위 8비트가 전송된다. OutputStream에 이미 데이터가 기록되어 있다면 이미 기록되어 있는 데이터 뒤에 전송된다.\n\nOOBINLINE 값이 true이면 소켓의 입력 스트림에 위치하게 되어 일반적인 방법으로 읽을 수 있다. 기본값은 false이다. Java에서는 긴급 데이터는 일반 데이터와 구별하지 않기 때문에 긴급 바이트를 처리하기가 어려운데, Ctrl-C 같은 특별한 의미를 갖는 바이트를 전송이 필요할 때 써볼 수 있다.\n\n\n## SO\\_REUSEADDR\n\n```JAVA\npublic void setReuseAddress(boolean on) throws SocketException \npublic boolean getReuseAddress() throws SocketException\n```\n\nSO\\_REUSEADDR 옵션은 소켓을 닫았을 때 해당 소켓의 포트를 즉시 다시 사용할 수 있게 해주는 역할은 한다.\n소켓 연결을 끊게 되면 먼저 연결을 끊는 쪽에서 TIME\\_WAIT 상태로 일정시간 유지되는데, 이는 네트워크 상에 아직 도착하지 않은 마지막 패킷들이 소켓에 도착할 시간을 확보하기 위한 것이다. 따라서, 소켓 연결이 끊어진다고 해서 그 포트가 즉시 재사용되지 않는다. 시스템은 이러한 늦게 도착한 패킷들을 처리하지 않지만, 그 패킷들이 같은 포트를 사용하는 다른 프로세스에게 잘못 전달되는 것을 방지하기 위해 일정시간을 대기한다.\nSO\\_REUSEADDR 옵션을 활성화하면, 이러한 대기 시간 없이 포트를 즉시 재사용할 수 있게 한다.\n\nTIME\\_WAIT 상태에 자세한 설명은 [카카오 기술블로그](https://tech.kakao.com/2016/04/21/closewait-timewait/)에 잘 정리된 것이 있으니 참고하길 바란다.\n\nsetReuseAddress() 메서드가 작동하려면 소켓이 포트에 바인됭되기 전에 setReuseAddress() 호출해야 한다.\n즉 인자없는 생성자 new Socket() 을 통해 소켓을 생성한다음 setReuseAddress(true)를 호출하고 connect() 메서드를 통해 소켓을 연결해야 한다.\n\n\n## 참조\n- TCP/IP Illustrated\n- 자바 네트워크 프로그래밍 4판\n\n"},{"excerpt":"Jakarta EE Jakarta EE(Java EE)는 기업용 애플리케이션에 필요한 기능들의 사양을 정의해둔 명세서이다.\n즉, 대규모 애플리케이션을 개발하는데 필요한 표준화된 Java API의 모음이라고 할 수 있다.\nJava API의 특징은 API를 제공하는 구현 벤더와 분리되어 있기 때문에 API를 준수한다면 플러그 형태로 구현 벤더를 교체할 수 있…","fields":{"slug":"/tomcat/"},"frontmatter":{"date":"September 26, 2023","title":"Apache Tomcat 이해하기(NIO Connector 중심)","tags":["Tomcat"]},"rawMarkdownBody":"\n## Jakarta EE\nJakarta EE(Java EE)는 기업용 애플리케이션에 필요한 기능들의 사양을 정의해둔 명세서이다.\n즉, 대규모 애플리케이션을 개발하는데 필요한 표준화된 Java API의 모음이라고 할 수 있다.\nJava API의 특징은 API를 제공하는 구현 벤더와 분리되어 있기 때문에 API를 준수한다면 플러그 형태로 구현 벤더를 교체할 수 있다는 장점이 있다.\n구체적으로는 JSP, Servlet, EJB, JMS, JMX, JTA 등 기업용 애플리케이션을 개발하고 실행하는 데 필요한 사양들을 명시하고 있다.\n[여기서](http://java.sun.com/javaee/technologies/) Jakarta EE(Java EE) API의 전체 목록을 확인할 수 있다.\n다양한 써드파티에서 Jakarta EE(Java EE) 스펙을 준수한 구현을 제공하는데 대표적으로 아래와 같은 벤더가 있다.\nJakarta EE(Java EE) 스펙을 완전히 구현한 것을 WAS(Web Application Server)라고 한다.\n- JBoss(www.jboss.org)\n- JOnAS(jonas.objectweb.org)\n- Geronimo(geronimo.apache.org)\n\n## Servlet\n서블릿은 Jakarta EE API 중 하나로, Java 기술을 기반으로 한 웹 컴포넌트이다. Servlet은 서버 측에서 실행되는 Java 클래스로, 클라이언트의 요청을 처리하고 동적인 웹 페이지를 생성한다.\nJakarta EE(Java EE)의 Servlet 주요 스펙을 요약하면 다음과 같다. [Servlet 3.1 Spec docs](https://download.oracle.com/otn-pub/jcp/servlet-3_1-fr-eval-spec/servlet-3_1-final.pdf?AuthParam=1695794208_54642e957120d983f4ca811f71280a25)\n- 요청/응답 모델: Servlet은 HTTP 요청을 받아 처리한 후, 응답을 반환하는 요청/응답 모델을 기반으로 한다.\n- 생명주기 관리: Servlet은 특정 생명주기를 가진다. 주요 메소드로는 init(), service(), doGet(), doPost(), destroy() 등이 있다.\n- 세션 관리: Servlet 스펙은 클라이언트 세션을 관리하기 위한 API를 제공한다.\n- 컨텍스트 공유: ServletContext를 통해 애플리케이션 전체에 걸쳐 정보를 공유할 수 있다.\n- 필터링: 필터를 사용하여 요청 및 응답에 대한 사전 및 사후 처리를 수행할 수 있다.\n- 이벤트 리스너: 웹 애플리케이션의 생명주기 이벤트나 세션 생성/소멸 등의 이벤트에 대한 리스너를 정의할 수 있다.\n- 멀티 스레딩: Servlet은 멀티 스레딩 환경에서 실행된다.\n- 포워딩 및 리다이렉션: 요청을 다른 리소스로 포워딩하거나, 클라이언트에게 다른 URL로 리다이렉션 요청을 보낼 수 있다.\n- 보안: Servlet 스펙은 선언적인 보안을 제공하여, 웹 리소스에 대한 접근 제어를 쉽게 구성할 수 있다.\n\n## Servlet Containner\n웹 서버나 애플리케이션 서버의 일부로서, 네트워크 서비스를 제공한다. 웹 애플리케이션의 생명 주기를 관리하며, 요청을 받아 처리하고, 웹 페이지의 동적인 내용을 생성하는 역할을 한다.\n클라이언트가 웹서버에 HTTP 요청을 보내면, 서블릿 컨테이너가 이 요청을 받아서 요청 URL에 해당하는 서블릿에 전달하며, 서블릿 쓰레드가 사용자의 요청을 처리한 후 서블릿 컨테이너를 통해 응답을 반환한다.\n\n## Tomcat\nTomcat은 Servlet 및 JSP 사양을 구현한 서블릿 컨테이너이다. JSP와 서블릿 처리, 서블릿의 수명 주기 관리, 요청 URL을 서블릿 코드로 매핑, HTTP 요청 수신 및 응답, 필터 체인 관리 등을 처리해준다. 톰캣은 Jakarta EE를 완전히 구현한 WAS는 아니고, JSP 와 Servlet 사양만 구현했기 때문에 Servlet Containner 또는 Web Container 라고 부른다.\n\n## Tomcat Architecture\n\n![Tomcat Architecture](./img.png)\n\n#### Server\n\nTomcat 웹 애플리케이션 서버 자체를 의미한다. 하나의 JVM 내에서 하나의 Server 인터턴스를 실행할 수 있다.\n여러 개의 JVM 인스턴스를 실행한다면 여러 대의 Tomcat Server 인스턴스를 생성할 수 있는데\n각각의 Server 인서턴스는 다른 네트워크 포트를 사용해야 충돌이 발생하지 않는다.\n\n#### Service\n\n톰캣 최상위 컴포넌트 중 하나로, container 와 Connector 를 하나로 묶는다. 일반적으로 하나의 Engine 타입의\n컨테이너 하나와 여러 개의 Connector로 구성된다. Service는 여러 웹 애플리케이션을 관리하고 클라이언트의 요청을 처리하는 단위이다. 클라이언트가 요청을 하면 Connector가 요청을 받아, Engine(container)에게 전달한다.\nEngine은 요청을 웹 애플리케이션으로 라우팅하고 결과를 반환한다.\n각 Service는 이름이 부여되어 있어 로그 메시지를 통해 Service를 쉽게 식별할 수 있다.\n\n#### Connectors\n\nConnectors는 클라이언트의 웹 요청을 받아서 적절한 애플리케이션으로 전달하는 역할을 하는 컴포넌트이다.\n이를 통해 HTTP, HTTPS 등 다양한 프로토콜과 포트를 사용하여 웹 애플리케이션에 접근할 수 있게 한다.\n하나의 Engine은 여러 개의 Connectors를 설정할 수 있는데, 각 Connectors의 포트는 유일해야 한다.\n기본 Connector는 Coyote이며 HTTP 1.1을 구현한다. 그 외에도 AJP, SSL Connector, HTTP 2.0 Connector 등이 있다.\n\n#### Engine\n\nEngine은 Tomcat 서버에서 가장 상위에 위치한 컨테이너이다.\nCatalina 서블릿 엔진을 대표하고, HTTP 헤더를 분석하여 요청을 어느 가상 호스트나 컨텍스트로 전달할지 결정한다.\n하나의 Engine 내에는 여러 Hosts가 포함될 수 있고, 각 Host는 여러 웹 애플리케이션을 나타낼 수 있다.\n또한 Context는 단일 웹 애플리케이션을 나타낸다.\n\n#### Realm\n\nRealm은 사용자 인증과 권한을 부여하는 컴포넌트이다. Realm은 전체 엔진에서 공통적으로 적용되므로 엔진 내의 애플리케이션은\n인증을 위한 Realm을 공유하게 된다.\n\n#### Valves\n\nValves 요청과 응답을 가로채서 사전 처리를 할 수 있다. 이는 Servlet의 필터와 비슷하지만, Valves 톰캣 고유의 컴포넌트이다.\nHosts, contexts, Engine에 Valves를 포함시킬 수 있다. Valves는 엔진과 컨텍스트 사이, 호스트와 컨텍스트 사이, 컨텍스트와 웹 리로스 사이에서 요청을 가로챌 수 있다.\nRequest 헤더 및 쿠키 저장, Response 헤더 및 쿠기 등을 로깅 등에 사용된다.\n\n#### Host\n\nHost는 아파치 웹 서버의 가상 호스트와 유사하다. 하나의 물리적 서버에 여러 개의 웹 사이트를 호스팅할 수 있다.\nHost는 보통 Engine 내에 위치해 Engine의 요청을 받아 해당 요청이 어느 Host로 전달될지 판단한다.\n\n#### Context\n\nContext는 웹 애플리케이션을 나타낸다. Engine이나 Host에게 애플리케이션의 루트 폴더 위치를 알려주는 등의 설정을 포함한다.\n여러 Context가 하나의 호스트를 공유할 수 있다.\n\n## server.xml\n\nserver.xml은 Tomcat 서버 구성 요소를 정의한다. Service, Connector, engine, Realm, Valve, Host 등의 구성이 포함된다.\ntomcat이 설치된 conf 디렉토리에서 확인할 수 있다. tomcat 8 버전 기준으로 설치 후 기본 설정을 확인해보면 아래와 같다.\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<Server port=\"8005\" shutdown=\"SHUTDOWN\">\n  <Listener className=\"org.apache.catalina.startup.VersionLoggerListener\"/>\n  <!--  ...-->\n\n  <GlobalNamingResources>\n    <Resource name=\"UserDatabase\" auth=\"Container\"\n      type=\"org.apache.catalina.UserDatabase\"\n      description=\"User database that can be updated and saved\"\n      factory=\"org.apache.catalina.users.MemoryUserDatabaseFactory\"\n      pathname=\"conf/tomcat-users.xml\"/>\n  </GlobalNamingResources>\n\n  <Service name=\"Catalina\">\n\n    <Connector port=\"8080\" protocol=\"HTTP/1.1\"\n      connectionTimeout=\"20000\"\n      redirectPort=\"8443\"\n      maxParameterCount=\"1000\"\n    />\n\n    <Engine name=\"Catalina\" defaultHost=\"localhost\">\n\n      <Realm className=\"org.apache.catalina.realm.LockOutRealm\">\n        <Realm className=\"org.apache.catalina.realm.UserDatabaseRealm\"\n          resourceName=\"UserDatabase\"/>\n      </Realm>\n\n      <Host name=\"localhost\" appBase=\"webapps\"\n        unpackWARs=\"true\" autoDeploy=\"true\">\n\n        <Valve className=\"org.apache.catalina.valves.AccessLogValve\" directory=\"logs\"\n          prefix=\"localhost_access_log\" suffix=\".txt\"\n          pattern=\"%h %l %u %t &quot;%r&quot; %s %b\"/>\n\n      </Host>\n    </Engine>\n  </Service>\n</Server>\n```\n\nserver.xml 파일의 컴포넌트 구성은 아래와 같이 컴포넌트가 부모-자식 관계를 가지고 있는 것을 볼 수 있다.\n\n```\nServer\n├── Listener (여러 개 존재 가능)\n├── GlobalNamingResources\n│   └── Resource (UserDatabase)\n└── Service (Catalina)\n    ├── Connector (port=8080, protocol=HTTP/1.1)\n    └── Engine (Catalina)\n        ├── Realm (LockOutRealm)\n        │   └── Realm (UserDatabaseRealm)\n        └── Host (localhost)\n            └── Valve (AccessLogValve)\n```\n\n- Server: 최상위 컴포넌트로 서버의 전반적인 설정을 관리한다.\n- Listener: 서버 라이프사이클 이벤트를 처리한다.\n- GlobalNamingResources: 글로벌 네이밍 리소스, UserDatabase 같은 리소스 설정이 있다.\n- Service: 하나 이상의 커넥터(Connector)와 하나의 엔진(Engine)을 가진다.\n- Connector: HTTP 요청을 처리한다.\n- Engine: 실제로 웹 애플리케이션을 처리하는 컴포넌트이다.\n- Realm: 보안 관련 설정을 담당한다.\n- Host: 가상 호스트 설정을 관리한다.\n- Valve: 로깅이나 보안 등 추가적인 처리를 담당한다.\n\n> Catalina라는 이름의 서비스에서 HTTP 1.1 프로토콜과 8080 포트 번호가 정의되어 있는 것을 볼 수 있다.\n> 이 설정은 톰캣을 설치했을 때 기본으로 제공되는 소개 페이지를 호스팅하는 역할을 한다.\n\n![img_1.png](img_1.png)\n\n## web.xml\n\nweb.xml 파일은 톰캣에 웹 애플리케이션을 어떻게 배포하고 실행할지에 대한 기본 설정을 제공한다.\n서블릿 사양에 따르면 모든 웹 애플리케이션에는 deployment descriptor(web.xml)가 포함되어야 한다.\n만약 웹 애플리케이션마다 개별 배포 설명자를 가지고 있다면 해당 개별 설정이 web.xml 설정을 덮어씌운다.\n\n아래와 같은 URL로 요청을 받으면 tomcat의 각 구성요소는 다음과 같은 흐름으로 처리한다.\n\n```https://www.example.com/store/book/```\n\n- https://: : Connector로 SSL 설정 (/conf/server.xml)\n- www.example.com : Virtual host name (/conf/server.xml)\n- /store : context path (Context Descriptor XML)\n- /book : 서블릿 맵핑 (/WEB-INF/web.xml) \n\n위 URL의 프로토콜(https://) 부분이 먼저 서비스에서 분석되고 Coyote Connector가 요청을 엔진으로 전달된다.\n다음으로, 엔진에서 호스트 이름(www.example.com)을 파싱하여 호스트 컴포넌트를 선택한다.\n호스트는 배포된 웹 애플리케이션 컨텍스트(/store)에 대해 URL을 맵핑하고, 마지막으로 web.xml에 의해 서블릿 맵핑을 수행한다.\n\n## Connector 아키텍처\n\nTomcat에는 Java로 작성된 org.apache.catalina.Connector 컴포넌트가\n있다. [Connector](https://github.com/Oreste-Luci/apache-tomcat-8.0.26-src/blob/master/java/org/apache/catalina/connector/Connector.java) 종류에는 HTTP/HTTPS 호출을 위한\nHTTP 1.1 커넥터, AJP(Apache JServ Protocol) 호출을 위한 AJP/1.3 커넥터가 있다. HTTP2 커넥터를 사용하기 위해서는 기존 HTTP 1.1 커넥터을 사용하고 HTTP2 UpgradeProtocol을 사용하면 된다.\n설정 바식은 server.xml 파일의 Connector 태그 내에서 protocol 속성을 통해 설정할 수 있다.\n\n- HTTP/1.1: org.apache.coyote.http11.Http11AprProtocol\n- AJP/1.3: org.apache.coyote.ajp.AjpAprProtocol\n\n### AJP 커넥터\n\nAJP(Apache JServ Protocol)란, Tomcat과 다른 웹 서버 (예: Apache) 간에 통신을 최적화하기 위한 프로토콜이다. 웹 서버와 Tomcat 간에 통신이 필요할 때 AJP는 HTTP 프록시보다 더 빠른 성능을 제공한다. 그렇다면 어떻게 AJP는 HTTP보다\n빠른 성능을 제공할까?\n\n- 바이너리 포맷 사용: AJP13는 데이터 전송을 위해 바이너리 형식을 사용한다. 이전 버전인 AJP10과 AJP11은 텍스트 기반의 데이터 형식을 사용하였다. 바이너리 형식은 텍스트 형식보다 효율적으로 데이터를 인코딩하여 전송할 수 있다.\n- 재사용 가능한 연결 및 영구적 연결: 웹 서버와 서블릿 컨테이너 간의 통신은 네트워크 소켓을 통해 이루어진다. 이 연결은 여러 요청 및 응답에 대해 재사용할 수 있어 핸드쉐이크에 필요한 추가적인 시간이 절약할 수 있다.\n- 바이너리 인코딩: AJP는 HTTP 명령 및 헤더에 대한 바이너리 인코딩을 정의한다. 예를 들어, HTTP의 'GET' 명령은 AJP에서는 단일 바이트 값인 2로 표현된다. 이러한 바이너리 인코딩은 데이터의 크기를 줄이고 전송 속도를 높인다.\n\n![img_2.png](img_2.png)\n\n### HTTP Connector\n\nHTTP Connector는 HTTP 프로토콜을 구현하는 Java 클래스이다. HTTP Connector는 서블릿 및 JSP에 대한 요청 이외에도 정적 컨텐츠 리소스에 대한 요청에도 응답한다.\nHTTP Connector는 HTTP 요청을 구문 분석하고 Tomcat 서블릿 엔진에 전달하는 코드가 있다.\nHTTP Connector 종류에는 HTTP/1.1 커넥터, NIO HTTP 커넥터, 네이티브 코드에 최적화된 APR HTTP 커넥터 등이 존재한다.\n이 컴포넌트는 서버의 특정 TCP 포트번호에서 연결을 대기(listen)한다.\n하나의 서비스 내에 여러 Connector 들이 구성될 수 있고, 요청을 Engine에게 전달하여 응답을 반환한다.\nConnector 설정은 아래와 같은 server.xml에서 xml 태그로 설정할 수 있다.\n\n```XML\n<Connector port=”8080”\n protocol=”HTTP/1.1”\n maxThreads=”150”\n connectionTimeout=”20000”\n redirectPort=”8443” />\n```   \n  \nHTTP 1.1 Connector의 동작방식은 공식문서에 잘 설명되어있다. 동시에 받은 요청이 현재 사용 가능한 worker 스레드보다 많으면, 설정된 최대치(maxThreads 속성의 값)까지 추가 스레드가 생성된다.\n더 많은 동시 요청이 오게되면, 현재 연결 수가 maxConnections에 도달할 때까지 Tomcat은 새로운 연결을 accept한다.\n연결은 Connector가 생성한 서버 소켓에서 연결을 처리할 스레드가 사용 가능해질 때까지 대기큐에 머물게 된다. maxConnections에 도달하면, 운영 체제는 추가 연결을 큐에 넣는다. 이 때, 운영 체제에서 제공하는 연결 큐의 크기는 acceptCount 속성으로 정의할 수\n있다. 운영 체제 큐가 가득 차면, 추가 연결 요청이 거부되거나 timeout이 발생하게 된다.\n스프링을 사용하면 로그에 **http-nio-8080-exec-?** 라는 Worker 스레드 이름을 볼 수 있는데, 이 Worker 스레드풀을 초기화하는 로직이 아래와 같다.\n\n```JAVA\n// https://github.com/apache/tomcat/blob/main/java/org/apache/tomcat/util/net/AbstractEndpoint.java\npublic void createExecutor(){\n    internalExecutor=true;\n    TaskQueue taskqueue=new TaskQueue();\n    TaskThreadFactory tf=new TaskThreadFactory(getName()+\"-exec-\",daemon,getThreadPriority());\n    executor=new ThreadPoolExecutor(getMinSpareThreads(),getMaxThreads(),60,TimeUnit.SECONDS,taskqueue,tf);\n    taskqueue.setParent((ThreadPoolExecutor)executor);\n}\n```\n\n`executor = new ThreadPoolExecutor(getMinSpareThreads(), getMaxThreads(), 60, TimeUnit.SECONDS,taskqueue, tf)` 라인을 보면 Executor 구현체로 ThreadPoolExecutor을 사용하는 것을\n볼 수 있다.\nThreadPoolExecutor 동작은 [여기](https://px201226.github.io/java-concurrency-executor/)에 정리해둔 내용이 있으니 참고하자.\nThreadPoolExecutor 기본 동작은 내부 Queue가 꽉 차지 않는 이상 corePoolSize를 늘리지 않는데, 공식문서에서 유휴 스레드가 없으면 스레드를 생성한다는 내용과 차이점이 있다. 이 점은 생성자로 주입한 TaskQueue 의 구현을 보면 이해할 수 있다.   \n\n```JAVA\n// https://github.com/apache/tomcat/blob/main/java/org/apache/tomcat/util/threads/TaskQueue.java\npublic class TaskQueue extends LinkedBlockingQueue<Runnable> {\n\n\t@Override\n\tpublic boolean offer(Runnable o) {\n\t\t//we can't do any checks\n\t\tif (parent == null) {\n\t\t\treturn super.offer(o);\n\t\t}\n\t\t//we are maxed out on threads, simply queue the object\n\t\tif (parent.getPoolSizeNoLock() == parent.getMaximumPoolSize()) {\n\t\t\treturn super.offer(o);\n\t\t}\n\t\t//we have idle threads, just add it to the queue\n\t\tif (parent.getSubmittedCount() <= parent.getPoolSizeNoLock()) {\n\t\t\treturn super.offer(o);\n\t\t}\n\t\t//if we have less threads than maximum force creation of a new thread\n\t\tif (parent.getPoolSizeNoLock() < parent.getMaximumPoolSize()) {\n\t\t\treturn false;\n\t\t}\n\t\t//if we reached here, we need to add it to the queue\n\t\treturn super.offer(o);\n\t}\n}\n```\n\nTaskQueue는 톰캣에서 LinkedBlockingQueue를 확장한 큐로 BlockingQueue::offer 메서드를 오버라이딩한다.\noffer 메서드의 내용을 살펴보면 현재 스레드 풀의 크기가 최대 스레드풀 크기가 동일하면 작업을 큐에 추가한다.\n그렇지 않다면 제출된 작업 수가 현재 스레드 풀보다 작은 경우, 즉 유휴 스레드가 있는 경우 작업을 큐에 추가한다.\n그것도 아니라면 현재 풀 사이즈가 maximum 풀사이즈보다 작으면 false를 반환하여 새로운 스레드를 생성한다.\n아래는 HTTP Connector를 구성하는 속성들이다.\n자세한 내용은 [여기서](https://tomcat.apache.org/tomcat-8.5-doc/config/http.html) 확인할 수 있다.   \n\n\n| 속성명                  | 설명                                                                                                                                                                                                                                                                                                                                                             |\n|----------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| maxConnections       | 서버가 한 번에 수용하고 처리할 수 있는 최대 연결 수. 이 숫자에 도달하면 서버는 추가로 한 개의 연결을 수용하지만 처리하지는 않는다. 이 추가 연결은 처리 중인 연결 수가 maxConnections 아래로 떨어질 때까지 차단된다. 제한에 도달했을 때 운영 체제는 여전히 acceptCount 설정을 기반으로 연결을 수락할 수 있다. NIO 및 NIO2의 경우 기본값은 10,000이다. APR/native의 경우 기본값은 8,192이다. NIO/NIO2에만 해당되는데, 이 값을 -1로 설정하면 maxConnections 기능이 비활성화되고 연결이 계산되지 않는다.                                 |\n| acceptCount          | maxConnections에 도달했을 때 들어오는 연결 요청에 대해 운영 체제에서 제공하는 대기열의 최대 길이. 운영 체제는 이 설정을 무시하고 대기열에 다른 크기를 사용할 수 있다. 이 큐가 가득 차면 운영 체제에서 추가 연결을 거부하거나 타임아웃이 발생한다. 기본값은 100                                                                                                                                                                                                    |\n| maxKeepAliveRequest  | 이 속성은 HTTP 요청의 \"keep-alive\" 동작을 제어하며 지속적인 연결(즉, 동일한 HTTP 연결을 통해 여러 요청을 보낼 수 있게 함)을 가능하게 한다. 서버에서 연결이 닫힐 때까지 파이프라인화할 수 있는 요청의 최대 수를 지정한다. maxKeepAliveRequest의 기본값은 100이며, 1로 설정하면 HTTP keep-alive 동작과 파이프라인화가 비활성화된다.                                                                                                                                          |\n| maxSpareThreads      | maxSpareThreads 속성은 사용되지 않는 스레드의 최대 수를 제어한다. Tomcat이 사용되지 않는 것들을 중지하기 전에 허용될 수 있는 스레드의 최대 수다. maxSpareThreads의 기본값은 50이다.                                                                                                                                                                                                                                      |\n| minSpareThreads      | minSpareThreads 속성은 커넥터가 초기화될 때 시작되는 스레드의 최소 수를 지정한다. minSpareThreads의 기본값은 4다.                                                                                                                                                                                                                                                                                |\n| maxThreads           | 이 속성은 이 커넥터가 요청을 처리하기 위해 생성되는 스레드의 최대 수를 지정한다. 이는 차례로 커넥터가 처리할 수 있는 동시 요청의 최대 수를 지정한다. maxThreads의 기본값은 200 스레드다.                                                                                                                                                                                                                                              |\n| socketBuffer         | 소켓 출력 버퍼링에 사용될 버퍼의 크기(바이트 단위)를 지정한다. 소켓 버퍼의 사용은 성능을 향상시킨다. 기본적으로 9,000 바이트 크기의 버퍼가 사용되며, socketBuffer를 -1로 설정하면 버퍼링이 꺼진다.                                                                                                                                                                                                                                      |\n| tcpNoDelay           | 이 속성이 true로 설정되면, TCP_NO_DELAY 네트워크 소켓 옵션이 활성화된다. 기본값은 true다.                                                                                                                                                                                                                                                                                                  |\n| connectionLinger     | 이 Connector에서 사용하는 소켓이 닫혔을 때 얼마 동안 대기할지 정하는 초 단위의 시간이다. 기본값은 -1로 설정되어 있어서 소켓 지속 기능이 비활성화된다.                                                                                                                                                                                                                                                                    |\n| connectionTimeout    | 이 Connector는 연결을 수락한 후 요청 URI 줄이 제시될 때까지 얼마 동안 기다릴지를 밀리초 단위로 정한다. -1을 사용하면 시간 제한이 없다는 의미다. 기본값은 60000(즉, 60초)이지만 Tomcat에 포함된 표준 server.xml에서는 이 값을 20000(즉, 20초)으로 설정한다는 것을 주의하라. disableUploadTimeout이 false로 설정되지 않으면, 요청 본문(있는 경우)을 읽을 때 이 시간 제한도 사용된다.                                                                                                     |\n| keepAliveTimeout     | 이 Connector는 다른 HTTP 요청을 기다리기 전에 연결을 닫을 때까지 얼마 동안 기다릴지를 밀리초 단위로 정한다. 기본값은 connectionTimeout 속성에 설정된 값을 사용한다. -1 값을 사용하면 시간 제한이 없다는 의미다.                                                                                                                                                                                                                        |\n| maxKeepAliveRequests | 서버에 의해 연결이 닫힐 때까지 파이프라인에 넣을 수 있는 HTTP 요청의 최대 수를 정한다. 이 속성을 1로 설정하면 HTTP/1.0 지속 연결과 HTTP/1.1 지속 연결 및 파이프라이닝이 모두 비활성화된다. -1로 설정하면 파이프라인 또는 지속 연결 HTTP 요청의 수에 제한이                                                                                                                                                                  없다. 지정되지 않으면 이 속성은 100으로 설정된다. |\n\n## HTTP NIO Connector\n\nHTTP Connector에는 내부 프로토콜에 따라 크게 3가지 프로토콜 구현체가 존재한다.\nBIO Connnector는 Tomcat 8.0부터 삭제되어 여기서는 NIO Connector 중심으로 알아본다.\n\n| 이름            | 설명                                                                                                                           |\n|---------------|------------------------------------------------------------------------------------------------------------------------------|\n| BIO Connector | Tomcat 7의 기본 Connector (org.apache.coyote.http11.Http11Protocol)<br/>Java Blocking API를 사용하여 구현                              |\n| NIO Connector | Tomcat 8 이후 기본 Connector (org.apache.coyote.http11.Http11NioProtocol)<br/> Java NIO API를 사용하여 구현                             |\n| APR Connector | APR 라이브러리를 사용해 더 나은 성능의 Connector (org.apache.coyote.http11.Http11AprProtocol)<br/>JNI(Java Native Interface) 라이브러리를 사용하여 구현 |\n\n### Http11NioProtocol\n\nJava Non-Blocking IO의 핵심은 Selector를 이용한 채널 관리이다.\n관심있는 채널(요청, 읽기, 준비완료 등)에 Selector에 등록하고 싱글 스레드가 Selector를 폴링하여 준비된 채널에 대해 지정된 콜백을 실행하여 작업을 처리한다.\nHTTP NIO Connector 도 위와 같은 방식으로 이벤트를 처리하고 있으며, 아래 그림과 아키텍처를 가진다.   \n![NIO Connector 구성](img_3.png)\n\n\n#### Acceptor\n\nAcceptor 스레드는 serverSocket.accept() 로 소켓 연결을 하고 반환된 SocketChannel 을\nTomcat의 NioChannel로 캡슐화한다. NioChannel은 다시 PollerEvent로 래핑되고 이벤트 큐에 등록한다.\nAcceptor 스레드는 소켓 연결 수락에 대한 이벤트를 생성하는 생성자 스레드를 의미한다.\n\n#### Poller\n\nNon Blocking IO 처리의 핵심인 이벤트 루프 로직이 포함되어 있다. Poller는 이벤트 큐에서 PollerEvent를 소비한다.\nPollerEvent 에서 꺼낸 Channel을 Selector에 등록하고 Selector는 읽을 수 있는 소켓을 순회하며 해당 소켓을 Worker 스레드에 전달한다.\n\n#### Executor(Worker Thread)\n\nWorker 스레드에서는 Poller로부터 소켓을 받아 SocketProcessor 객체로 캡슐화하고 Http11NioProcessor에서 CoyoteAdapter를 호출한다.\n스프링 로그에 출력되는 `http-nio-8080-exec-?` 가 바로 이 Worker 스레드를 의미한다.\nCoyoteAdapter는 Connector와 Container(Engine) 사에에 다리 역할을 한다. 요청의 매개 변수를 파싱하고 해당 context를 찾아 Engine에게 전달한다.\nEngine은 요청을 처리하여 반환값을 반환한다.\n\n\n### 요청 플로우\n\n### 1. [Acceptor Thread] serverSock.accept()로 연결을 수락한다.\n\n```JAVA\npublic class NioEndpoint extends AbstractJsseEndpoint<NioChannel, SocketChannel> {\n\n\t@Override\n\tprotected SocketChannel serverSocketAccept() throws Exception {\n\t\tSocketChannel result = serverSock.accept();\n\n\t\t// Bug does not affect Windows platform and Unix Domain Socket. Skip the check.\n\t\tif (!JrePlatform.IS_WINDOWS && getUnixDomainSocketPath() == null) {\n\t\t\tSocketAddress currentRemoteAddress = result.getRemoteAddress();\n\t\t\tlong currentNanoTime = System.nanoTime();\n\t\t\tif (currentRemoteAddress.equals(previousAcceptedSocketRemoteAddress) &&\n\t\t\t\t\tcurrentNanoTime - previousAcceptedSocketNanoTime < 1000) {\n\t\t\t\tthrow new IOException(sm.getString(\"endpoint.err.duplicateAccept\"));\n\t\t\t}\n\t\t\tpreviousAcceptedSocketRemoteAddress = currentRemoteAddress;\n\t\t\tpreviousAcceptedSocketNanoTime = currentNanoTime;\n\t\t}\n\n\t\treturn result;\n\t}\n}\n```\n\n### 2. [Acceptor Thread] 생성된 소켓을 PollerEvent로 Poller 이벤트 큐에 등록\n\n```JAVA\npublic class NioEndpoint extends AbstractJsseEndpoint<NioChannel, SocketChannel> {\n\n\t@Override\n\tprotected boolean setSocketOptions(SocketChannel socket) {\n\t\tNioSocketWrapper socketWrapper = null;\n\t\ttry {\n\n\t\t\t//...\n\t\t\tNioSocketWrapper newWrapper = new NioSocketWrapper(channel, this);\n\n\t\t\tsocketWrapper = newWrapper;\n\n\t\t\t//...\n\t\t\tpoller.register(socketWrapper);\n\t\t\treturn true;\n\t\t} catch (Throwable t) {\n\t\t\t//...\n\t\t}\n\t\treturn false;\n\t}\n\n\tpublic void register(final NioSocketWrapper socketWrapper) {\n\t\tsocketWrapper.interestOps(SelectionKey.OP_READ);//this is what OP_REGISTER turns into.\n\t\tPollerEvent pollerEvent = createPollerEvent(socketWrapper, OP_REGISTER);\n\t\taddEvent(pollerEvent);\n\t}\n\n}        \n```\n\n### 3. [Poller Thread] 이벤트 큐를 돌면서 SocketChannel.register()로 Selector에 소켓 채널을 등록\n\n```JAVA\npublic class Poller implements Runnable {\n\n\tpublic boolean events() {\n\t\tboolean result = false;\n\n\t\tPollerEvent pe = null;\n\t\tfor (int i = 0, size = events.size(); i < size && (pe = events.poll()) != null; i++) {\n\t\t\tresult = true;\n\t\t\tNioSocketWrapper socketWrapper = pe.getSocketWrapper();\n\t\t\tSocketChannel sc = socketWrapper.getSocket().getIOChannel();\n\t\t\tint interestOps = pe.getInterestOps();\n\t\t\tif (sc == null) {\n\t\t\t\tlog.warn(sm.getString(\"endpoint.nio.nullSocketChannel\"));\n\t\t\t\tsocketWrapper.close();\n\t\t\t} else if (interestOps == OP_REGISTER) {\n\t\t\t\ttry {\n\t\t\t\t\tsc.register(getSelector(), SelectionKey.OP_READ, socketWrapper);\n\t\t\t\t} catch (Exception x) {\n\t\t\t\t\tlog.error(sm.getString(\"endpoint.nio.registerFail\"), x);\n\t\t\t\t}\n\t\t\t}\n\t\t\t//..\n\t\t}\n\n\t\treturn result;\n\t}\n}\n```\n\n### 4. [Poller Thread] 무한 루프를 돌면서, selector.select() 로 이벤트 수신, processKey()로 이벤트 처리\n\n```JAVA\npublic class Poller implements Runnable {\n\n\t@Override\n\tpublic void run() {\n\t\t// Loop until destroy() is called\n\t\twhile (true) {\n\n\t\t\tboolean hasEvents = false;\n\n\t\t\ttry {\n\t\t\t\tif (!close) {\n\t\t\t\t\thasEvents = events();\n\t\t\t\t\tif (wakeupCounter.getAndSet(-1) > 0) {\n\t\t\t\t\t\t// If we are here, means we have other stuff to do\n\t\t\t\t\t\t// Do a non blocking select\n\t\t\t\t\t\tkeyCount = selector.selectNow();\n\t\t\t\t\t} else {\n\t\t\t\t\t\tkeyCount = selector.select(selectorTimeout);\n\t\t\t\t\t}\n\t\t\t\t\twakeupCounter.set(0);\n\t\t\t\t}\n\n\n\t\t\t} catch (Throwable x) {\n\t\t\t\t// ... \n\t\t\t}\n\n\t\t\tIterator<SelectionKey> iterator =\n\t\t\t\t\tkeyCount > 0 ? selector.selectedKeys().iterator() : null;\n\n\t\t\t// Walk through the collection of ready keys and dispatch\n\t\t\t// any active event.\n\t\t\twhile (iterator != null && iterator.hasNext()) {\n\t\t\t\tSelectionKey sk = iterator.next();\n\t\t\t\titerator.remove();\n\t\t\t\tNioSocketWrapper socketWrapper = (NioSocketWrapper) sk.attachment();\n\t\t\t\t// Attachment may be null if another thread has called\n\t\t\t\t// cancelledKey()\n\t\t\t\tif (socketWrapper != null) {\n\t\t\t\t\tprocessKey(sk, socketWrapper);\n\t\t\t\t}\n\t\t\t}\n\n\n\t\t}\n\n\t}\n}\n```\n\n### 5. [Poller Thread] SelectionKey에 따라 SocketProcessor를 구성하고, Worker 스레드에 요청 제출\n\n```JAVA\npublic abstract class AbstractEndpoint<S, U> {\n\n\tpublic boolean processSocket(SocketWrapperBase<S> socketWrapper, SocketEvent event, boolean dispatch) {\n\n\t\t//...\n\t\tSocketProcessorBase<S> sc = null;\n\n\t\tif (sc == null) {\n\t\t\tsc = this.createSocketProcessor(socketWrapper, event);\n\t\t} else {\n\t\t\tsc.reset(socketWrapper, event);\n\t\t}\n\n\t\tExecutor executor = this.getExecutor();\n\t\tif (dispatch && executor != null) {\n\t\t\texecutor.execute(sc);\n\t\t} else {\n\t\t\tsc.run();\n\t\t}\n\n\t\treturn true;\n\n\t}\n}\n```\n\n### 4. [WorkerThread] CoyoteAdapter로 요청 위임 및 컨테이너로 요청 전달\n\n```JAVA\n// SocketProcessor.java\ngetHandler().process(socketWrapper,SocketEvent.OPEN_READ);\n\n// AbstractProcessorLight.java\n\t\tstate=service(socketWrapper); // 요청 위임\n\n// Http11Processor.java\n\t\tgetAdapter().service(request,response); // CoyoteAdapter로 요청 위임  \n\n// CoyoteAdapter.java\n\t\tconnector.getService().getContainer().getPipeline().getFirst().invoke(request,response); // 컨테이너로 요청 전달\n```\n\n## 참조\n- https://tomcat.apache.org/tomcat-8.5-doc/config/http.html\n- https://download.oracle.com/otn-pub/jcp/servlet-3_1-fr-eval-spec/servlet-3_1-final.pdf?AuthParam=1695794208_54642e957120d983f4ca811f71280a25\n- https://velog.io/@jihoson94/BIO-NIO-Connector-in-Tomcat\n- https://www.programmersought.com/article/90283888271/\n- Pro apache tomcat 6"},{"excerpt":"ReentrantLock 고유락(intrinsic locking, synchronized lock. monitor lock)과 달리 ReentrantLock은 폴링, 타임아웃, 인터럽트 가능한 잠금 획득을 선택할 수 있으며, 모든 잠금 및 해제 연산이 명시적이다. 아래 Lock 인터페이스는 추상적인 잠금 연산을 정의한다. ReentrantLock은 Loc…","fields":{"slug":"/java-concurrency-lock/"},"frontmatter":{"date":"September 19, 2023","title":"Java의 동시성 프로그래밍 - Lock","tags":["Java"]},"rawMarkdownBody":"## ReentrantLock\n고유락(intrinsic locking, synchronized lock. monitor lock)과 달리 ReentrantLock은 폴링, 타임아웃, 인터럽트 가능한 잠금 획득을 선택할 수 있으며, 모든 잠금 및 해제 연산이 명시적이다. 아래 Lock 인터페이스는 추상적인 잠금 연산을 정의한다.\n\n```JAVA\npublic interface Lock {\n\n    void lock();\n\n    void lockInterruptibly() throws InterruptedException;\n\n    boolean tryLock();\n\n    boolean tryLock(long timeout, TimeUnit unit)\n            throws InterruptedException;\n\n    void unlock();\n\n    Condition newCondition();\n}\n\n```\n\nReentrantLock은 Lock 인터페이스를 구현한 구현체하여, ReentrantLock을 획득과 해제는 synchronized 블록에 진입하고 종료하는 것과 동일한 메모리 시맨틱(가시성)을 가진다.\n\nReentrantLock을 사용하는 이유는 고유락의 한계 때문에 탄생하였다. 고유락은 데드락 같은 상황이 발생하더라도 영원히 대기해야 되고 또, 코드 블록 단위로 잠금을 획득하고 해제되어야 되기 때문에 좀 더 유연한 잠금 메커니즘이 필요하거나 더 나은 성능을 위해 탄생되었다. 잠금 관리에 많은 리소스가 사용되면 애플리케이션이 사용할 수 있는 리소스가 줄어들기 때문이다.\n\nReentrantLock은 고유락보다 더 많은 주의가 필요한데 락의 해제를 직접 관리해주어야 되기 때문에 더 많은 주의가 필요하다.\n\n```JAVA\nLock lock = new ReentrantLock(); ...\nlock.lock();\ntry {\n    // update object state\n    // catch exceptions and restore invariants if necessary\n} finally {\n    lock.unlock();\n}\n```\n> Java 6.0 부터 synchronized와 비교했을 때 ReentrantLock 이 성능적으로 약간 더 우세하다고 한다.\n성능 상의 이유로 synchronized 대신 ReentrantLock 을 사용하는 것은 불필요한 복잡성을 추가하는 것일 수 있으므로, 특별한 이유가 없다면 굳이 그렇게 할 필요가 없다고 생각한다.\n\n## 타임아웃 Lock\nlock::tyrLock 을 사용하면 고유락보다 더 정교한 오류 복구가 가능해진다. 고유락을 사용하여 데드락이 발생하면 애플리케이션을 재시작해야만 복구할 수 있지만 시간제한 잠금은 확률론적 방식으로 교착 상태 회피를 제공한다.\nlock::lockInterruptibly 메서드는 락을 획득하려고 시도할 때, 현재 스레드가 인터럽트되었는지도 확인한다. 락을 기다리는 동안 인터럽트가 발생하면 예외처리가 가능하고 고유락 처럼 무한정 대기하여 데드락에 빠지는 상황을 방지할 수 있다.\n\n```JAVA\nLock lock = new ReentrantLock();\n\ntry {\n    lock.lockInterruptibly();\n    try {\n        // Critical section\n    } finally {\n        lock.unlock();\n    }\n} catch (InterruptedException e) {\n    // Handle interruption\n}\n```\n\n## 공정성(fairness)\nReentrantLock 생성자에는 boolean 타입의 fairness 공정성 옵션을 제공한다.\n- 공정한 락(Fair Lock): 스레드들이 요청한 순서대로 락을 획득한다. 즉, 먼저 요청한 스레드가 먼저 락을 얻는다.\n- 비공정한 락(Nonfair Lock): 락이 사용 가능한 상태에서 요청한 스레드는 대기 중인 스레드를 무시하고 락을 바로 획득할 수 있다. 이를 \"barging\"이라고 한다. (기본값)\n\n공정성은 항상 옳은 것 처럼 보일 수 있지만 실제로는 성낭 상의 비용이 발생하여 비공정한 락이 대부분의 경우에 더 높은 성능을 보인다. 비공정한 락에서는 \"barging\"이라는 현상이 성능을 향상시킨다. 예를 들어, 스레드 A가 락을 보유하고 있고, 스레드 B가 그 락을 요청했다면, B는 대기 상태로 들어간다. A가 락을 해제하면, B는 다시 실행되고, 그 사이에 스레드 C가 락을 요청하면, C는 B가 깨어나기도 전에 락을 얻을 수 있다. 이로 인해 전반적인 처리량(throughput)이 향상될 수 있다. 공정한 락은 락을 오랫동안 보유하여 락 요청 시 대기 시간이 길 때 비공정 락 방식보다 유리할 수 있다.\n\n비공정한 락에서는 락을 요청한 순서와 무관하게 락을 획득할 수 있어 일부 스레드는 락을 획득하지 못하는 기아 상태가 발생할 수 있다. 대부분의 비공정한 락의 구현은 통계정 공정성을 기반으로 하는데 통계적 공정성이란 시스템이 모든 작업에 완벽한 공정성을 보장하지 않더라도, 긴 시간 동안 봤을 때 거의 모든 요청 또는 작업이 공정하게 처리될 것이라는 확률적인 보장을 의미한다.\n\n## Read-write locks\n대부분의 데이터 구조는 읽기 중심 작업으로 때때로 수정 작업이 발생한다. Read-write lock은 리소스는 여러 읽기 작업에 의해 동시에 접근될 수 있지만, 쓰기 작업이 일어날 때는 해당 리소스에 단독으로 접근하며 다른 읽기나 쓰기 작업은 접근할 수 없게 된다. 이러한 방식은 데이터의 일관성을 유지하면서 동시성(concurrency)을 높일 수 있다.\n\n```JAVA\npublic interface ReadWriteLock {\n    Lock readLock();\n    Lock writeLock();\n}\n```\n\nReadWriteLock을 구현하기 위해서는 아래와 같은 고려사항이 있을 수 있다.\n- Release Preference: 쓰기 락(write lock)이 해제될 때 대기 중인 읽기 작업(readers)과 쓰기 작업(writers) 중 누구에게 우선권을 줄 것인지를 의미한다. 이를 선택하는 방법에 따라 성능과 공정성이 달라질 수 있다.\n\n- Reader Barging: 읽기 락(read lock)이 활성화되어 있고 쓰기 작업(writer)이 대기 중일 때, 새로 도착하는 읽기 작업이 즉시 접근할 수 있을지, 아니면 대기 중인 쓰기 작업 뒤에 줄을 서야 하는지를 의미한다. 읽기 작업이 쓰기 작업보다 먼저 접근하는 것은 동시성을 향상시키지만, 쓰기 작업이 계속 대기 상태에 머물러 기아 상태에 빠질 수 있다.\n\n- Reentrancy: 읽기 락과 쓰기 락이 재진입 가능한지(reentrant) 여부입니다. 재진입 가능하다는 것은 하나의 스레드가 이미 획득한 락을 다시 획득할 수 있다는 의미이다.\n\n- Downgrading: 쓰기 락을 보유하고 있는 스레드가 쓰기 락을 해제하지 않고 읽기 락을 획득할 수 있는지 여부입니다. 이렇게 하면 쓰기 작업을 수행한 후에 읽기 작업으로 레벨을 낮춰서 다른 쓰기 작업이 도중에 리소스를 변경하지 못하게 할 수 있다.\n\n- Upgrading: 읽기 락을 보유하고 있는 상태에서 쓰기 락으로 업그레이드할 수 있는지 여부입니다. 대부분의 읽기-쓰기 락 구현체에서는 업그레이드를 지원하지 않는데, 두 개의 리더가 동시에 쓰기 잠금으로 업그레이드를 시도하면 어느 쪽도 읽기 잠금을 해제못하는 데드락이 발생할 수 있기 때문이다.\n\n\n## 참조\n- Java Concurrency in practice"},{"excerpt":"DeadLock 스레드 A각 잠금 L을 점유하고 있고 잠금 M을 획득하려고 시도하는 동시에 스레드 B가 잠금 M을 보유하고 있고 잠금 L을 획득하려고 시도하면 두 스레드는 영원히 대기하게 된다. 이러한 상황을 데드락이라고 한다. lock-ordering deadlocks 아래 코드는 leftRight(), rightLeft 메서드가 left, right …","fields":{"slug":"/java-concurrency-deadlock/"},"frontmatter":{"date":"September 18, 2023","title":"Java의 동시성 프로그래밍 - Deadlock","tags":["Java"]},"rawMarkdownBody":"\n## DeadLock\n스레드 A각 잠금 L을 점유하고 있고 잠금 M을 획득하려고 시도하는 동시에 스레드 B가 잠금 M을 보유하고 있고 잠금 L을 획득하려고 시도하면 두 스레드는 영원히 대기하게 된다. 이러한 상황을 데드락이라고 한다.\n\n## lock-ordering deadlocks\n아래 코드는 leftRight(), rightLeft 메서드가 left, right 락을 서로 다른 순서로 잠금을 획득하려고 하기 때문에 데드락이 발생할 수 있다. lock-ordering 은 left, right 락을 필요로 하는 모든 스레드에서 항상 같은 순서로 left, right 락을 획득하도록 하면 데드락이 발생하지 않는다.\n\n```JAVA\npublic class LeftRightDeadlock {\n\n    private final Object left = new Object();\n    private final Object right = new Object();\n\n    public void leftRight() {\n        synchronized (left) {\n            synchronized (right) {\n                doSomething();\n            }\n        }\n    }\n\n    public void rightLeft() {\n        synchronized (right) {\n            synchronized (left) {\n                doSomethingElse();\n            }\n        }\n    }\n}\n```\n\n```\nA ---> lock left -> try to lock right -> wait forever\nB -----> lock right -> try to lock left -> wait forever\n```\n\n\n## Dynamic lock order deadlocks\n데드락을 예방하기 위해 잠금 순서를 제어하기 명확하지 않을 때가 있다. 예를 들면 다음과 같은 fromAccount 에서 toAccount로 계좌 이체하는 코드이다.\n\n```JAVA\npublic void transferMoney(Account fromAccount, Account toAccount, DollarAmount amount){\n    synchronized (fromAccount) {\n        synchronized (toAccount) {\n            ...\n        }\n\n    }\n}       \n```\n위의 코드는 아래와 같은 방식으로 from, to Account를 반대로 호출하면 데드락이 발생할 수 있다.\n- A: transferMoney(myAccount, yourAccount, 10);\n- B: transferMoney(yourAccount, myAccount, 20);\n\n이런 경우에는 System::identityHashCode 와 같은 해시 코드를 사용하여 일관된 잠금 순서를 보장할 수 있다.\n다만, hashCode 는 드물지만 중복되는 경우도 있기 때문에 해시 코드가 동일한 경우에도 잠금 순서를 보장할 수 있어야 한다. 이런 경우에 사용할 수 있는 방법이 *tie breaking* 방식이다.\n\ntie breaking 방식은 fromAccount, toAccount 잠금을 획득하기 전에 tie breaking 잠금을 획득함으로써 한번에 두개의 잠금을 획득하여 데드락 가능성을 제거할 수 있다.\n\n```JAVA\nprivate static final Object tie = new Object();\n\npublic void transferMoney(Account fromAccount, Account toAccount, DollarAmount amount) {\n    \n    int fromHash = System.identityHashCode(fromAccount);\n    int toHash = System.identityHashCode(toAccount);\n    \n    if(fromHash > toHash){\n        synchronized (fromAccount){\n            synchronized (toAccount){\n                //...\n            }\n        }\n    } else if(fromHash < toHash){\n        synchronized (toAccount){\n            synchronized (fromHash){\n                //...\n            }\n        }\n    } else {\n        synchronized (tie){\n            synchronized (fromAccount){\n                synchronized (toAccount){\n                    //...\n                }\n            }\n        }\n    }\n}\n```\n\n## 객체 협력관계에서의 deadlocks\n두 개 이상의 자원(또는 객체, 클래스 등)이 상호 작용을 해야 하는 상황에서 데드락이 발생할 수 있다.\n클래스 A의 method1은 A의 상태를 업데이트하고, 클래스 B의 어떤 메서드를 호출한다.   \n클래스 B의 method2는 B의 상태를 업데이트하고, 클래스 A의 상태를 참조한다.\n\n이 두 메서드가 서로 다른 스레드에서 동시에 호출될 경우 데드락이 발생할 수 있다.\n- method1은 A의 락을 획득하고 B의 메서드를 호출하기 전에 락을 유지한다.\n- method2는 B의 락을 획득하고 A의 상태를 참조하기 전에 락을 유지한다.\n\n이런 상황에서는 open call 이나 락의 범위를 축소하여 데드락 가능성을 제거할 수 있다.\n- Open Call: 락 없이 메소드를 호출하는 것.\n- synchronized 블록 축소: 전체 메소드에 synchronized를 사용하는 대신에, 실제로 공유 상태에 접근하는 부분만 synchronized 블록으로 묶는다.\n\n> 결합된(composed) 객체를 나중에 동기화(synchronizing)하는 대신에 처음부터 동기화된 객체를 결합하는 것이 더 복잡하다. 동기화된 객체를 안전하게 사용하려면 오픈 콜(open calls)과 락의 순서 정하기(careful lock ordering) 같은 기술이 필요하다.\n\n\n## 리소스 deadlocks\n### 리소스 기반 데드락(Resource-based Deadlock)\n예를 들어 두 개의 데이터베이스 연결 풀이 있다고 가정해보자. 스레드 A가 데이터베이스 D1에 연결을 확보하고, D2에 연결을 기다리고 있을 수 있다.\n동시에 스레드 B가 D2에 연결을 확보하고 D1에 연결을 기다릴 수 있다.\n이런 상황에서 두 스레드는 각각 다른 스레드가 확보하고 있는 리소스를 기다리므로 데드락이 발생한다.\n\n### 스레드 기아 데드락(Thread-Starvation Deadlock)\n이 형태의 데드락은 하나의 스레드가 결과를 기다리는 동안 다른 스레드가 그 결과를 생성해야 하는 상황에서 발생한다.\n예를 들어, 하나의 작업이 결과를 생성하고, 다른 작업이 그 결과를 기다리는 경우, 첫 번째 작업이 완료되지 않으면 두 번째 작업도 영원히 기다리게 된다. 이는 특히 작업들이 한정된 스레드 풀에서 실행될 때 문제가 될 수 있다.\n\n\n## Timed tryLock\n명시적인 Lock 클래스의 \"timed tryLock\" 기능을 사용하면 무한정 대기하는 대신에 타임아웃을 설정할 수 있다.\n일반적인 내장 락(intrinsic locks)은 락을 획득할 수 없으면 영원히 대기하게 되지만 명시적인 락(explicit locks)은 타임아웃을 설정할 수 있어, 락 획득에 실패하면 재시도할 수 있는 제어권을 얻을 수 있다.\n\n\n## livelock\n라이브락은 스레드가 차단되지는 않았지만 계속 실패할 수 있는 작업을 계속 재시도하여 스레드가 계속 진행되지 못하는 상태의 한 형태를 말한다.\n\n예를 들어, 메시징 애플리케이션에서 메시지 처리에서 버그로 인해 특정 유형의 메시지가 항상 실패하면, 그 메시지는 계속해서 큐의 앞으로 돌아가고 다시 처리된다. 이러한 문제는 \"poison message problem\"이라고도 부른다. 스레드는 차단되지 않지만, 계속해서 같은 실패를 반복하므로 실제로는 작업이 진행되지 않는다.\n\n또는, 협력하는 스레드에서 여러 스레드가 서로의 상태에 반응하여 변경하되, 그 결과로 어느 스레드도 진행되지 못하는 상태가 될 수 있다. 두 사람이 복도에서 서로 양보하면서 영원히 지나가지 못하는 상황을 생각할 수 있다.\n\n이러한 유형의 라이브락을 해결하는 하나의 방법은 재시도 메커니즘에 무작위성을 도입하는 것 이다. 예를 들어, 이더넷 네트워크에서 두 스테이션이 동시에 패킷을 보내면 충돌이 발생한다고 할 때 두 스테이션은 재시도 시간에 무작위성을 도입하여 충돌을 피할 수 있다.\n\n아래는 Worker1 과 Worker2가 같은 자원 commonResource에 접근하려고 시도하고, 스레드가 자원에 접근할 수 없는 경우 자원을 상대방에게 양보하여 livelock이 발생하는 예제이다.\n```JAVA\npublic class LiveLockExample {\n    static class CommonResource {\n        private Worker owner;\n\n        public CommonResource(Worker owner) {\n            this.owner = owner;\n        }\n\n        public Worker getOwner() {\n            return owner;\n        }\n\n        public synchronized void setOwner(Worker d) {\n            owner = d;\n        }\n    }\n\n    static class Worker {\n        private String name;\n        private boolean active;\n\n        public Worker(String name, boolean active) {\n            this.name = name;\n            this.active = active;\n        }\n\n        public String getName() {\n            return name;\n        }\n\n        public boolean isActive() {\n            return active;\n        }\n\n        public synchronized void work(CommonResource commonResource, Worker otherWorker) {\n            while (active) {\n                // If resource is owned by someone else, wait\n                if (commonResource.getOwner() != this) {\n                    try {\n                        wait(10);\n                    } catch (InterruptedException e) {\n                        // handle\n                    }\n                    continue;\n                }\n\n                // If other worker is also active, hand over the common resource to the other worker\n                if (otherWorker.isActive()) {\n                    System.out.println(getName() + \" : handing over the resource to the worker: \" + otherWorker.getName());\n                    commonResource.setOwner(otherWorker);\n                    continue;\n                }\n\n                // Now use the commonResource\n                System.out.println(getName() + \": working on the common resource\");\n                active = false;  // work completed, so set active to false\n                commonResource.setOwner(otherWorker);\n            }\n        }\n    }\n\n    public static void main(String[] args) {\n        final Worker worker1 = new Worker(\"Worker 1 \", true);\n        final Worker worker2 = new Worker(\"Worker 2\", true);\n\n        final CommonResource s = new CommonResource(worker1);\n\n        new Thread(() -> worker1.work(s, worker2)).start();\n        new Thread(() -> worker2.work(s, worker1)).start();\n    }\n}\n\n```\n\n> 위의 메시징 애플리케이션에서는 Dead-letter-Queue 나 Retry Limit, Exponential Backoff 방식을 사용할 수 있다.\n\n\n## 참조\n- Java Concurrency in practice"},{"excerpt":"Executor Task는 논리적인 작업 단위이며, 스레드는 Task를 비동기적으로 실행할 수 있는 기술이다. Java에서는 Task 실행을 추상화하여 Executor 라는 인터페이스를 제공한다. Executor는 다양한 Task 실행 정책을 지원하는 비동기 프레임워크에 기반이 된다. Executor 구현은 통계 수집, 애플리케이션 관리 및 모니터링을 추…","fields":{"slug":"/java-concurrency-executor/"},"frontmatter":{"date":"September 17, 2023","title":"Java의 동시성 프로그래밍 - Executor","tags":["Java"]},"rawMarkdownBody":"\n## Executor\n\nTask는 논리적인 작업 단위이며, 스레드는 Task를 비동기적으로 실행할 수 있는 기술이다. Java에서는 Task 실행을 추상화하여 Executor 라는 인터페이스를 제공한다. Executor는 다양한 Task 실행 정책을 지원하는 비동기 프레임워크에 기반이 된다.\n\n```JAVA\npublic interface Executor {\n\n\tvoid execute(Runnable command);\n}\n```\n\nExecutor 구현은 통계 수집, 애플리케이션 관리 및 모니터링을 추가하기 위한 라이프사이클 지원 및 후크를 제공한다.\nExecutor는 생산자-소비자 패턴을 기반으로 Task을 등록하는 작업과 Task를 처리하는 작업을 분리하였다.\nTask의 등록과 처리를 분리는 특정 Task의 실행 정책을 쉽게 변경할 수 있다는 장점이 있다.\n실행 정책은 무엇을, 어디서, 언제, 어떻게를 포함한다.\n\n- Task는 어떤 스레드에서 실행되는가?\n- Task는 어떤 순서로 실행되어야 하는가? (FIFO, LIFO, Priority)\n- 동시에 실행할 수 있는 작업 수는?\n- 몇 개의 작업이 실행 대기열에 포함될 수 있나?\n- 처리량 제한으로 작업을 거부해야하는 경우, 어떻게 처리해야 하나?\n- 작업을 실행하기 전후 조치는?\n\n> 현재 new Thread(runnable).start() 와 같은 저수준의 스레드를 직접 다루고 있다면 Executor 나 비동기 프레임워크 사용을 적극적으로 고려해보는 것이 좋다.\n\n## Executor 라이프사이클\n\nExecutor는 Task를 비동기적으로 처리하기 때문에 특정 시점에 제출된 작업의 상태를 즉시 알 수 없다.\n완료되거나 실행 중이거나 실행대기 중일 수 도 있다. Executor는 애플리케이션이 정상적으로 또는 갑작스럽게 종료되더라도 종료로 인한 영향받는 작업의 상태 정보를 애플리케이션에 전달할 수 있어야 한다.\nExecutor의 수명 주기 문제를 해결하기 위해 ExecutorService 인터페이스는 Executor를 확장하여 라이프 사이클 관리를 위한 여러 가지 메서드를 제공한다.\n\n```JAVA\npublic interface ExecutorService extends Executor {\n\n\tvoid shutdown();\n\n\tList<Runnable> shutdownNow();\n\n\tboolean isShutdown();\n\n\tboolean isTerminated();\n\n\tboolean awaitTermination(long timeout, TimeUnit unit) throws InterruptedException;\n\t//...\n}\n```\n\n> ExecutorService , ExecutorCompletionService 차이\n> ExecutorService 는 Task를 제출한 순서대로 결과를 가져와서 처리할 수 있다.\n> ExecutorCompletionService 는 Task를 제출한 순서와 상관없이 내부적으로 BlockingQueue 사용하여 완료된 작업 목록 리스트를 유지하여 완료된 Task를 poll 하거나 take할 수 있다.\n\n## ThreadPoolExecutor\n\nThreadPoolExecutor 는 Executors의 정적 팩토리 메서드로 생성할 수 있는 newCachedThreadPool, newFixedThreadPool, newScheduledThreadPool 의 기본 구현을 제공한다.\n기본 구현의 실행 정책이 필요에 맞지 않는 경우 ThreadPoolExecutor 생성자를 통해 정의할 수 있다.\n\n```JAVA\npublic ThreadPoolExecutor(int corePoolSize,\n\t\tint maximumPoolSize,\n\t\tlong keepAliveTime,\n\t\tTimeUnit unit,\n\t\tBlockingQueue<Runnable> workQueue,\n\t\tThreadFactory threadFactory,\n\t\tRejectedExecutionHandler handler\n\t\t) \n```\n\n- corePoolSize : 스레드 수의 하한, 최소 corePoolSize 만큼의 스레드 수를 유지한다. workQueue가 꽉 차지 않는 이상 스레드 수를 늘리지 않는다.\n- maximumPoolSize : 스레드 수의 상한, workQueue가 꽉찰 경우 최대로 생성될 수 있는 스레드 수\n- keepAliveTime : 유휴 상태인 스레드가 keepAliveTime 시간이 지나면 스레드를 회수하여 corePoolSize를 유지한다.\n\nTask 마다 스레드를 생성해서 처리하는 것과 비교하여 스레드 풀을 사용하면 CPU를 차지하기 위해 경쟁하면서 대기하는 대신 ThreadPoolExecutor를 사용하면 ThreadPoolExecutor이 관리하는 Runnable Queue에서 대기시킬 수 있다. 이는 스레드를 직접\n만들어 대기하는 것보다 훨씬 경제적이지만, 클라이언트가 서버가 처리할 수 있는 속도보다 더 많은 요청을 몰릴 경우 메모리 부족또는 응답 시간 지연 같은 문제가 여전히 발생할 수 있다.\n\nThreadPoolExecutor는 실행 대기 중인 태스크를 보관하기 위해 BlockingQueue를 사용할 수 있다. 이러한 Task 큐 종류에는 unbounded 큐, bounded 큐, synchronous handoff가 있다.\nnewFixedThreadPool 및 newSingleThreadExecutor 의 기본 Task 큐로는 unbounded LinkedBlockingQueue를 사용하는 것 이다. 따라서, 작업이 실행할 수 있는 속도보다 빨리 도착하는 경우 큐가 제한 없이 커질 수 있다.\n\n보다 안정적인 리소스를 관리 전략으로는 ArrayBlockingQueue나 bounded LinkedBlockingQueue, PriorityBlockingQueue 와 같은 bounded 큐를 사용하는 것이다.\n\nsynchronous handoff은 큐를 사용하는 것이 아니라 스레드 간의 핸드 오프를 관리하는 메커니즘이다.\n핸드 오프를 사용하는 SynchronousQueue는 작업을 큐에 넣고 소비자가 큐에서 작업을 꺼내서 실행하는 방식이 아니라 작업을 큐에 넣으려면 다른 스레드가 이미 핸드오프 수락을 위해 대기 중이어야 한다. 작업을 실행할 스레드에 바로 전달할 수 있으므로 더 효율적이다.\nSynchronousQueue는 스레드풀이 무제한이거나 초과 작업을 거부하는 것이 허용되는 경우에 유용한 선택지이다. newCachedThreadPool이 SynchronousQueue를 사용한다.\n\n## 포화 정책(Saturation policies)\n\n포화 정책은 스레드 풀의 작업 대기열이 가득 찼을 때 어떻게 동작할지를 설명한다. bounded 큐가 가득 차면 포화 정책이 실행된다. ThreadPoolExecutor에 대한 포화 정책은 setRejectedExecutionHandler 메서드를 호출하여 설정할 수 있다.\nRejectedExecutionHandler 구현에는 AbortPolicy, CallerRunsPolicy, DiscardOldestPolicy가 있다.\n\n- AbortPolicy: 기본 정책으로 작업 대기열이 가득 차면 RejectedExecutionException을 발생시킨다. 호출자는 이 예외를 잡아서(try-catch) 오버플로우를 처리할 수 있다.\n\n- DiscardPolicy: 새로 제출된 작업이 대기열에 들어갈 수 없다면, 그 작업을 무시한다.\n\n- DiscardOldestPolicy: 대기열에서 가장 먼저 실행될 작업을 제거하고 새로운 작업을 대기열에 추가하려고 시도한다. 만약 대기열이 우선순위 큐라면, 가장 높은 우선순위의 작업이 제거된다.\n\n- CallerRunsPolicy: 이 정책은 작업을 무시하지도, 예외를 발생시키지도 않는다. 대신, 새로운 작업을 제출한 스레드에서 작업을 실행한다. 이는 일종의 '스로틀링'(throttling)으로, 새 작업의 흐름을 늦추기 위해 일부 작업을 호출자에게 다시 돌려보낸다.\n  CallerRunsPolicy를 사용하면, 예를 들어 웹 서버에서 모든 스레드가 사용 중이고 대기열이 가득 차면, 다음 작업은 execute 호출을 하는 메인 스레드에서 실행된다.\n\n다음은 CallerRunsPolicy 를 사용한 고정 스레드풀 Executor를 생성하는 코드이다.\n\n```JAVA\nThreadPoolExecutor executor=new ThreadPoolExecutor(\n\t\tN_THREADS,\n\t\tN_THREADS,\n\t\t0L,\n\t\tTimeUnit.MILLISECONDS,\n\t\tnew LinkedBlockingQueue<Runnable>(CAPACITY)\n\t\t);\nexecutor.setRejectedExecutionHandler(new ThreadPoolExecutor.CallerRunsPolicy());\n```\n\n## ThreadFactory\n\n스레드 풀에서 새로운 스레드를 생성해야 할 때 ThreadFactory 를 통해 스레드를 생성한다. 기본 스레드 팩토리는 논데몬 스레드를 생성한다. 사용자 정의 스레드 팩토리를 사용하는 이유는 UncaughtExceptionHandler를 지정하거나 디버그 로깅을 수행하는 것과 같은\n사용자 지정 스레드 클래스의 인스턴스를 인스턴스화할 수 있다.\n\n```JAVA\npublic interface ThreadFactory {\n\n\tThread newThread(Runnable r);\n}\n```\n\n## Extending ThreadPoolExecutor\n\nThreadPoolExecutor 는 확장을 위해 설계되어 서브클래스가 오바라이드할 수 있는 후크 메서드를 제공한다.\nbeforeExecute, afterExecute 메서드는 작업을 실행하는 스레드에서 호출되며, beforeExecute가 RuntimeException을 던지면 태스트가 실행되지 않고 afterExecute도 호출되지 않는다.\nterminate 메서드는 모든 작업이 완료되고 워커 스레드가 종료된 후 스레드 풀 종료가 완료될 때 호출된다."},{"excerpt":"동시성 프로그래밍 모델 동시성은 여러 태스크가 동시에 실행된다는 시스템 속성이다. 또한 태스크들 사이에서 상호 작용을 수행할 수 있다.\n이러한 동시성은 단일 코어 프로세서부터 멀티 코어 프로세서, 다중 프로세서, 그리고 분산 시스템까지 다양한 컴퓨팅 환경에서 구현될 수 있다.\n주 목적은 사용자의 응답성을 향상시키고 처리량을 증가시키는 것이다. 동시성은 주…","fields":{"slug":"/java-concurrency-model/"},"frontmatter":{"date":"September 07, 2023","title":"웹 서버를 위한 동시성 프로그래밍 모델","tags":["Java"]},"rawMarkdownBody":"\n\n\n## 동시성 프로그래밍 모델\n동시성은 여러 태스크가 동시에 실행된다는 시스템 속성이다. 또한 태스크들 사이에서 상호 작용을 수행할 수 있다.\n이러한 동시성은 단일 코어 프로세서부터 멀티 코어 프로세서, 다중 프로세서, 그리고 분산 시스템까지 다양한 컴퓨팅 환경에서 구현될 수 있다.\n주 목적은 사용자의 응답성을 향상시키고 처리량을 증가시키는 것이다.\n\n동시성은 주로 멀티스레딩과 연관되어 있지만, 멀티스레딩에서 발생하는 문제들은 분산 시스템에서도 유사하게 나타난다.\n이는 두 시스템 모두 컴퓨팅 리소스를 효율적으로 활용하여 하나의 목표를 달성하기 위한 메커니즘이기 때문이다.\n공유 상태 관리, 작업 분산, 그리고 작업 순서 조정과 같은 공통적인 문제가 포함된다.\n\n웹 서버의 경우, 일반적으로 요청과 처리의 워크플로우를 가지며, 여러 웹 요청을 동시에 처리할 수 있어야 한다.\n여기서는 인기있는 인기있는 웹 프레임워크의 동시성 프로그래밍 모델에 대해서 알아보려고 한다. \n\n\n## Thread-based Concurrency\n스레드 기반 접근 방식은 들어오는 각 요청을 별도의 스레드와 연결한다. thread-per-request 모델이라고도 한다.\nThread-based Concurrency 모델은 스레드가 원격 호출, File I/O 등의 이유로 블로킹될 수 있다고 가정한다.\n이러한 이유로 대량 스레드풀을 사용하여 스레드 하나가 요청 하나를 처리한다.\n또한 요청 처리에 필요한 모든 작업을 순차적으로 코딩할 수 있기 때문에 코딩 난이도 및 디버깅이 용이하다는 장점이 있다.\n아래는 Socket 기반 요청이 들어올 때 마다 Counter 값을 증가시키고 응답하는 간단한 웹 서버를 구현한 코드이다.\n\n```JAVA\npublic class Main {\n\n\tpublic static void main(String[] args) throws IOException {\n\t\tlog.info(\"start\");\n\t\tfinal var counter = new Counter();\n\t\ttry (var socket = new ServerSocket(8080)) {\n\n\t\t\twhile (true) {\n\t\t\t\tfinal var clientSocket = socket.accept();\n\t\t\t\tlog.info(\"accept client\");\n\t\t\t\tnew Thread(new WorkerRunnable(clientSocket, counter)).start();\n\t\t\t}\n\t\t}\n\n\n\t}\n\n\tstatic class Counter {\n\n\t\tprivate Integer count = 0;\n\n\n\t\tpublic synchronized Integer increase() {\n\t\t\treturn count++;\n\t\t}\n\t}\n\n\tstatic class WorkerRunnable implements Runnable {\n\n\t\tprivate final Socket clientSocket;\n\t\tprivate final Counter counter;\n\n\t\tpublic WorkerRunnable(Socket clientSocket, Counter counter) {\n\t\t\tthis.clientSocket = clientSocket;\n\t\t\tthis.counter = counter;\n\t\t}\n\n\t\t@Override\n\t\tpublic void run() {\n\t\t\ttry {\n\t\t\t\tBufferedReader input = new BufferedReader(new InputStreamReader(clientSocket.getInputStream()));\n\t\t\t\tOutputStream output = clientSocket.getOutputStream();\n\t\t\t\tfinal var time = LocalDateTime.now();\n\t\t\t\tString readLine;\n\t\t\t\tString req = \"\";\n\t\t\t\twhile ((readLine = input.readLine()) != null) {\n\t\t\t\t\tif (req.equals(\"\")) {\n\t\t\t\t\t\treq = readLine;\n\t\t\t\t\t}\n\t\t\t\t\tif (readLine.equals(\"\")) { // If the end of the http request, stop\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tif (req == null || req.equals(\"\") || req.contains(\"favicon.ico\")) {\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\tfinal var increase = counter.increase();\n\n\t\t\t\toutput.write(\n\t\t\t\t\t\t(\"HTTP/1.1 200 OK\\n\\nWorkerRunnable: \" +\n\t\t\t\t\t\t\t\tincrease + \" - \" + time + \"\").getBytes()\n\t\t\t\t);\n\t\t\t\toutput.flush();\n\t\t\t\toutput.close();\n\t\t\t\tinput.close();\n\t\t\t\tlog.info(\"Request processed: {}\", increase);\n\t\t\t} catch (IOException ex) {\n\t\t\t\tthrow new RuntimeException(ex);\n\t\t\t}\n\n\t\t}\n\t}\n}\n```\n\nCounter 클래스는 여러 스레드가 Counter 값을 증가시키기 위해 쓰기 경쟁이 발생할 수 있다.\n이는 Counter 값이 변경 가능한 공유 상태이기 때문에 Counter 값이 CPU 스케줄링과 같은 \n특정 타이밍에 따라 연산의 결과가 달라질 수 있기 때문이다. 이러한 상황을 경쟁 상태(Race Condition) 이라고 한다.\n\n경쟁 상태의 원인은 변경 가능한 공유 변수에 대한 연산이 atomic operation이 아니기 때문이다.\nwiki 에서는 atomic operation을 다음과 같이 정의하고 있다.\n> 원자적 연산은 연산이 실행되는 동안 다른 프로세스가 해당 연산 중에 읽거나 변경하는 상태를 읽거나 변경할 수 없는 연산을 의미합니다.\n\n즉, atomic operation은 단순히 쪼갤 수 없는 연산이 아니라 한 번에 하나의 코드 섹션을 실행할 수 있는 operation 이라고 볼 수 있다.\n여기서는 counter 변수에 값을 증가시키는 메서드를 synchronized 로 동기화하여 경쟁 상태를 해결하였다.\n공유 상태를 사용하는 동시성 모델의 경우 자바에서는 synchronized 와 같은 잠금 메커니즘을 사용하게 된다.\n\n잠금을 사용하면 임계 영역에 대한 엑세스를 직렬화하여 atomic operation을 구현할 수 있다. \n잠금은 너무 크게 잡으면 동시성이 떨어지고, 잠금을 너무 미세하게 잡으면 데드락, 기아상태 등을 유발하기 쉬워진다.\n\n스레드 기반 동시성 모델의 또 다른 단점은 Context-Switching 오버헤드이다.\nCPU가 한 스레드 실행에서 다른 스레드 실행으로 전환할 때 CPU는 현재 스레드의 로컬 데이터, 프로그램 포인터 등을 저장하고 실행할 다음 스레드의 로컬 데이터, 프로그램 포인터 등을 로드해야 한다.\n이 비용은 결코 저렴하지 않다. 불필요한 컨텍스트 스위칭으로 많은 시간을 허비할 수도 있다.\n\n## Event-driven Concurrency\nEvent-driven Concurrency은 이벤트에 응답하여 동시에 여러 작업을 수행하는 프로그래밍 방식을 의미한다.\n이는 전통적인 스레드 기반의 동시성과는 다르게 동작하는데, 스레드 기반 동시성은 여러 스레드가 동시에 실행되는 반면,\nEvent-driven Concurrency은 일반적으로 한 스레드 내에서 여러 작업을 비동기적으로 수행된다.\n따라서 스레드 관리, 동기화 문제, 데드락 등의 복잡한 동시성 문제에서 자유롭다.\n\n대신, 스레드 기반 동시성에 비해 실행 흐름을 파악하기 어렵고 콜백 지옥 같은 문제로 코드 복잡성이 증가할 수 있다.\nCPU 집약적인 작업(이미지 처리, 동영상 처리) 등 에는 적합하지 않을 수 있다. 한 작업이 너무 오래 걸리면 다른 이벤트 처리가 지연될 수 있기 때문이다.\n\n이러한 패러다임은 Node.js, Vert.x 등의 프레임워크에서 사용된다.\n\n```JAVA\ninterface EventHandler {\n    void handle(SelectionKey key) throws IOException;\n}\n\npublic class ReactorEventLoopExample {\n    public static void main(String[] args) throws IOException {\n        Selector selector = Selector.open();\n        ServerSocketChannel serverChannel = ServerSocketChannel.open();\n        serverChannel.configureBlocking(false);\n        serverChannel.socket().bind(new InetSocketAddress(8080));\n        SelectionKey key = serverChannel.register(selector, SelectionKey.OP_ACCEPT);\n        key.attach(new AcceptHandler(selector, serverChannel));\n\n        while (true) {\n            int readyChannels = selector.select();\n            if (readyChannels == 0) continue;\n            Set<SelectionKey> selectedKeys = selector.selectedKeys();\n            Iterator<SelectionKey> keyIterator = selectedKeys.iterator();\n            while (keyIterator.hasNext()) {\n                SelectionKey selectionKey = keyIterator.next();\n                EventHandler handler = (EventHandler) selectionKey.attachment();\n                if (handler != null) {\n                    handler.handle(selectionKey);\n                }\n                keyIterator.remove();\n            }\n        }\n    }\n}\n\nclass AcceptHandler implements EventHandler {\n    private final Selector selector;\n    private final ServerSocketChannel serverSocketChannel;\n    private int counter = 0;  // 카운터 추가\n\n    public AcceptHandler(Selector selector, ServerSocketChannel serverSocketChannel) {\n        this.selector = selector;\n        this.serverSocketChannel = serverSocketChannel;\n    }\n\n    @Override\n    public void handle(SelectionKey key) throws IOException {\n        SocketChannel clientChannel = serverSocketChannel.accept();\n        if (clientChannel != null) {\n            counter++;  // 클라이언트가 연결될 때마다 카운터 증가\n            System.out.println(\"Client accepted. Current connection count: \" + counter);\n            clientChannel.configureBlocking(false);\n            SelectionKey clientKey = clientChannel.register(selector, SelectionKey.OP_READ);\n            clientKey.attach(new ReadHandler(clientChannel));\n        }\n    }\n}\n\nclass ReadHandler implements EventHandler {\n    private final SocketChannel socketChannel;\n\n    public ReadHandler(SocketChannel socketChannel) {\n        this.socketChannel = socketChannel;\n    }\n\n    @Override\n    public void handle(SelectionKey key) throws IOException {\n        ByteBuffer buffer = ByteBuffer.allocate(256);\n        int read = socketChannel.read(buffer);\n\n        if (read > 0) {\n            String output = new String(buffer.array()).trim();\n            System.out.println(\"Received: \" + output);\n        } else if (read == -1) {\n            socketChannel.close();\n        }\n    }\n}\n```\n위의 예제는 싱글 스레드를 사용한 이벤트 루프 방식의 간단한 서버이다. 싱글 스레드로 동작하기 때문에 counter 값을 동기화하기 위한 스레드 조정이 필요없다.\n싱글 스레드를 사용하기 때문에 Race condition이 발생하지 않고 context switching 오버헤드도 발생하지 않는다.\n이벤트 루프 내 Blocking I/O 작업이 발생하면 이벤트 루프가 블록킹 상태로 유지되기 때문에 이러한 작업은 별도의 백그라운드 스레드에서 처리해야 동시성을 높일 수 있다.\n\n\n## Actor-based Concurrency \n\n"},{"excerpt":"synchronized 락의 단점 락이 걸린 객체에서 일어나는 동기화 작업은 모두 균등하게 취급된다. 락 획득/해제는 반드시 메서드 수준이나 메서드 내부의 동기화 블록 안에서 이루어져야 한다. 락을 얻지 못한 스레드는 블로킹된다. 락을 얻지 못할 경우, 락을 얻어 처리를 계속하려고 시도하는 것조차 불가능하다. 락이 걸린 데이터에 모든 연산이 동등하게 취급…","fields":{"slug":"/java-concurrency/"},"frontmatter":{"date":"August 14, 2023","title":"Java의 동시성 프로그래밍 - overview","tags":["Java"]},"rawMarkdownBody":"\n\n## synchronized 락의 단점\n- 락이 걸린 객체에서 일어나는 동기화 작업은 모두 균등하게 취급된다.\n- 락 획득/해제는 반드시 메서드 수준이나 메서드 내부의 동기화 블록 안에서 이루어져야 한다.\n- 락을 얻지 못한 스레드는 블로킹된다. 락을 얻지 못할 경우, 락을 얻어 처리를 계속하려고 시도하는 것조차 불가능하다.\n\n락이 걸린 데이터에 모든 연산이 동등하게 취급된다는 의미는 읽기/쓰기 작업에 동일한 레벨의 락의 필요하다는 의미이다.\n\n## Java 동시성 라이브러리\njava.util.concurrent 패키지에는 멀티스레드 애플리케이션을 더 쉽게 개발할 수 있게 설계된 자바의 표준 라이브러리이다. 이 라이브러리에서 제공하는 기능은 크게 다음과 같다.\n- 락, 세마포어\n- atomics\n- Blocking Queue\n- latch\n- Executor\n<!-- more -->\n\n### java.util.concurrent.locks.Lock\n\n```JAVA\npublic interface Lock {\n\n\n    /**\n    * 기존 방식대로 락을 획득하고 락을 사용할 수 있을 때까지 블록킹한다\n    **/\n    void lock();\n\n    /**\n    * 대기중인 스레드에 인터럽트할 수 있게 해준다. interrupt() 가 호출되면 대기 상태가 * 인터럽트되며 InterruptedException 이 던져진다.\n    **/\n    void lockInterruptibly() throws InterruptedException;\n\n\n    /**\n    * 호출 시점에 잠금이 해제된 경우에만 잠금을 획득한다.\n    **/\n    boolean tryLock();\n\n    \n    /**\n    * 락을 획득하려고 시도한다. 타임아웃이 설정이 가능하다.\n    **/\n    boolean tryLock(long time, TimeUnit unit) throws InterruptedException;\n\n\n    /**\n    * 락을 해제한다. lock()에 대응되는 후속 호출이다.\n    **/\n    void unlock();\n\n\n    /**\n    * 락 주위에 조건을 설정해 유연하게 락을 활용할 수 있다. (읽기와 쓰기를 분리할 수 있다)\n    **/  \n    Condition newCondition();\n}\n\n```\n\nReentrantLock 클래스는 Lock의 주요 구현체로, 내부적으로 int 값으로 compareAndSwap()을 한다.\n(AtomicInteger 클래스의 Unsafe 클래스 참조)\n\n### 읽기/쓰기 락\n기존 synchronized 나 ReentrantLock 을 이용하면 한 가지 락 정책을 따를 수 밖에 없다.\n한 읽기 스레드 때문에 나머지 읽기 스레드를 블로킹하여 처리율이 낮아질 수 있다.\n이럴 때 ReentrantReadWriteLock 클래스의 ReadLock, WriteLock을 활용하면 여러 스레드가\n읽기 작업을 하는 도중에도 다른 읽기 스레드를 블로킹하지 않게 할 수 있다. 블로킹은 쓰기 작업을 할 때만 발생한다.\nReentrantReadWriteLock의 생성자로 boolean fair 라는 파라미터를 받는데 기본값은 false, 불공정(non-fair) 모드이다.\n'불공정’이란 말 자체의 의미처럼 락을 획득한 스레드 하나가 다른 여러 스레드가 고갈되건 말건 상관하지 않습니다. 반대로, '공정’ 모드에서는 어느 정도 스레드 간 공정성이 보장되도록 FIFO에 가까운 방식으로 락을 획득할 수 있게 함으로써 각 스레드가 대기하는 시간을 최대한 균등하게 분배한다.\n\n```JAVA\n\n@Slf4j\npublic class StockInventory {\n\n    private final ReentrantReadWriteLock rwl = new ReentrantReadWriteLock();\n    private final Lock readLock = rwl.readLock();\n    private final Lock writeLock = rwl.writeLock();\n    private final Map<String, Integer> stockRepository = new HashMap<>();\n\n\n    public Integer getStock(String item) {\n        readLock.lock();\n        log.info(\"readLock lock\");\n        try {\n            Thread.sleep(2000);\n            return stockRepository.getOrDefault(item, 0);\n        } catch (InterruptedException e) {\n            throw new RuntimeException(e);\n        } finally {\n            readLock.unlock();\n            log.info(\"readLock unLock\");\n        }\n    }\n\n    public void increaseStock(String item) {\n        writeLock.lock();\n        log.info(\"writeLock lock\");\n        try {\n            Thread.sleep(2000);\n            stockRepository.put(item, stockRepository.getOrDefault(item, 0) + 1);\n        } catch (InterruptedException e) {\n            throw new RuntimeException(e);\n        } finally {\n            writeLock.unlock();\n            log.info(\"writeLock unlock\");\n        }\n    }\n\n}\n\n```\n\n### ReadLock vs ReadLock\n\n```JAVA\n@Test\nvoid readLock() throws InterruptedException {\n    final StockInventory stockInventory = new StockInventory();\n\n    new Thread(\n            () -> {\n                final var qty = stockInventory.getStock(\"aaa\");\n                System.out.println(qty);\n            }\n    ).start();\n\n    new Thread(\n            () -> {\n                final var qty = stockInventory.getStock(\"aaa\");\n                System.out.println(qty);\n            }\n    ).start();\n\n    Thread.sleep(5000L);\n}\n```\n```console\n15:40:09.316 [Thread-0] INFO com.example.javaconcurrency.lib.StockInventory -- readLock lock\n15:40:09.316 [Thread-1] INFO com.example.javaconcurrency.lib.StockInventory -- readLock lock\n15:40:11.321 [Thread-0] INFO com.example.javaconcurrency.lib.StockInventory -- readLock unLock\n0\n15:40:11.324 [Thread-1] INFO com.example.javaconcurrency.lib.StockInventory -- readLock unLock\n0\n\n```\n읽기 vs 읽기 시, 락 경합이 발생하지 않는다.\n\n\n### WriteLock vs WriteLock\n\n```JAVA\n@Test\nvoid writeLock() {\n    final StockInventory stockInventory = new StockInventory();\n\n    new Thread(\n            () -> {\n                stockInventory.increaseStock(\"aaa\");\n            }\n    ).start();\n\n    new Thread(\n            () -> {\n                stockInventory.increaseStock(\"aaa\");\n            }\n    ).start();\n\n    try {\n        Thread.sleep(3000L);\n    } catch (InterruptedException e) {\n        throw new RuntimeException(e);\n    }\n}\n```\n\n```console\n15:42:00.459 [Thread-0] INFO com.example.javaconcurrency.lib.StockInventory -- writeLock lock\n15:42:02.467 [Thread-1] INFO com.example.javaconcurrency.lib.StockInventory -- writeLock lock\n15:42:02.467 [Thread-0] INFO com.example.javaconcurrency.lib.StockInventory -- writeLock unlock\n15:42:04.471 [Thread-1] INFO com.example.javaconcurrency.lib.StockInventory -- writeLock unlock\n```\n먼저 writeLock을 점유한 스레드가 unlock 할 때까지, 뒤에 writeLock 쓰레드가 대기한다.\n\n\n### WriteLock vs ReadLock\n```JAVA\n@Test\nvoid writeLockVsReadLock() throws InterruptedException {\n    final StockInventory stockInventory = new StockInventory();\n\n    new Thread(\n            () -> {\n                stockInventory.increaseStock(\"aaa\");\n            }\n    ).start();\n\n    new Thread(\n            () -> {\n                final var qty = stockInventory.getStock(\"aaa\");\n                System.out.println(qty);\n            }\n    ).start();\n\n    Thread.sleep(3000L);\n}\n```\n\n```Console\n15:44:10.126 [Thread-0] INFO com.example.javaconcurrency.lib.StockInventory -- writeLock lock\n15:44:12.133 [Thread-1] INFO com.example.javaconcurrency.lib.StockInventory -- readLock lock\n15:44:12.133 [Thread-0] INFO com.example.javaconcurrency.lib.StockInventory -- writeLock unlock\n15:44:14.144 [Thread-1] INFO com.example.javaconcurrency.lib.StockInventory -- readLock unLock\n1\n```\nwriteLock을 점유한 스레드가 unlock 할 때 까지, readLock이 대기한다.\n\n\n### ReadWrite vs WriteLock\n```JAVA\n15:46:12.891 [Thread-0] INFO com.example.javaconcurrency.lib.StockInventory -- readLock lock\n15:46:14.899 [Thread-1] INFO com.example.javaconcurrency.lib.StockInventory -- writeLock lock\n15:46:14.899 [Thread-0] INFO com.example.javaconcurrency.lib.StockInventory -- readLock unLock\n0\n15:46:16.904 [Thread-1] INFO com.example.javaconcurrency.lib.StockInventory -- writeLock unlock\n```\n\n```Console\n15:46:56.315 [Thread-0] INFO com.example.javaconcurrency.lib.StockInventory -- readLock lock\n15:46:58.323 [Thread-0] INFO com.example.javaconcurrency.lib.StockInventory -- readLock unLock\n0\n15:46:58.325 [Thread-1] INFO com.example.javaconcurrency.lib.StockInventory -- writeLock lock\n15:47:00.330 [Thread-1] INFO com.example.javaconcurrency.lib.StockInventory -- writeLock unlock\n```\nreadLock 점유한 스레드가 unlock 할 때 까지, writeLock 대기한다.\n\n\n\n## 세마포어\n세마포어는 풀 스레드나 DB 접속 객체 등 여러 리소스를 최대 X개 객체까지만 액세스를 허용한다는 전제하에 정해진 수량의 퍼밋으로 액세스를 제어한다.\nSemaphore 클래스의 acquire() 메서드는 사용 가능한 퍼밋 수를 하나씩 줄이는데, 더 이상 쓸 수 있는 퍼밋이 없을 경우 블로킹된다.\nrelease() 메서드는 퍼밋을 반납하고 대기 중인 스레드 중에서 하나에게 해제한 퍼밋을 전달한다.\n세마포어는 리소스를 기다리는 스레드가 리소스를 점유하지 못하는 기아상태가 될 가능성이 커서 공정모드로 초기화하는 경우가 많다.\n퍼밋이 하나뿐인 세마포어는 뮤텍스와 동등하다. 그러나 뮤텍스는 뮤텍스가 걸린 스레드만 해제할 수 있는 반면, 세마포어는 비소유 스레드도 락을 해제할 수 있다는 점이 다르다.\n\n### Connection Pool 예제\n```JAVA\n@Slf4j\npublic class ConnectionPool {\n\n    private final Semaphore semaphore;\n    private final Queue<String> connectionPool;\n\n    public ConnectionPool(int poolSize) {\n        this.semaphore = new Semaphore(poolSize, true);\n        this.connectionPool = new LinkedList<>();\n        for (int i = 0; i < poolSize; i++) {\n            connectionPool.add(\"pool\" + i);\n        }\n    }\n\n    public String acquireConnection() throws InterruptedException {\n        semaphore.acquire();\n        log.info(\"acquire connection\");\n        return connectionPool.poll();\n    }\n\n    public void releaseConnection(String connection) {\n        log.info(\"release connection\");\n        connectionPool.offer(connection);\n        semaphore.release();\n    }\n\n}\n```\n\n```JAVA\n@Slf4j\nclass ConnectionPoolTest {\n\n    @Test\n    void semaphoreTest() throws InterruptedException {\n        final var connectionPool = new ConnectionPool(2);\n\n        final var executorService = Executors.newFixedThreadPool(4);\n\n        for (int i=0; i<4; i++){\n            executorService.execute(() -> {\n                try {\n                    final var connection = connectionPool.acquireConnection();\n                    log.info(\"connection acquired = {}\", connection);\n                    Thread.sleep(2000L);\n                    connectionPool.releaseConnection(connection);\n                } catch (InterruptedException e) {\n                    throw new RuntimeException(e);\n                }\n            });\n\n        }\n\n\n        Thread.sleep(15000L);\n\n    }\n}\n```\n```Console\n16:26:59.908 [pool-1-thread-1] INFO com.example.javaconcurrency.lib.ConnectionPool -- acquire connection\n16:26:59.908 [pool-1-thread-2] INFO com.example.javaconcurrency.lib.ConnectionPool -- acquire connection\n16:26:59.912 [pool-1-thread-2] INFO com.example.javaconcurrency.lib.ConnectionPoolTest -- connection acquired = pool1\n16:26:59.911 [pool-1-thread-1] INFO com.example.javaconcurrency.lib.ConnectionPoolTest -- connection acquired = pool0\n16:27:01.918 [pool-1-thread-2] INFO com.example.javaconcurrency.lib.ConnectionPool -- release connection\n16:27:01.918 [pool-1-thread-1] INFO com.example.javaconcurrency.lib.ConnectionPool -- release connection\n16:27:01.919 [pool-1-thread-3] INFO com.example.javaconcurrency.lib.ConnectionPool -- acquire connection\n16:27:01.919 [pool-1-thread-4] INFO com.example.javaconcurrency.lib.ConnectionPool -- acquire connection\n16:27:01.919 [pool-1-thread-3] INFO com.example.javaconcurrency.lib.ConnectionPoolTest -- connection acquired = pool1\n16:27:01.919 [pool-1-thread-4] INFO com.example.javaconcurrency.lib.ConnectionPoolTest -- connection acquired = pool0\n16:27:03.925 [pool-1-thread-3] INFO com.example.javaconcurrency.lib.ConnectionPool -- release connection\n16:27:03.925 [pool-1-thread-4] INFO com.example.javaconcurrency.lib.ConnectionPool -- release connection\n```\n\nsemaphore fair = true 시, 리소스에 락을 획득하려고 하는 스레드가 많을 때 할당되는 방식이다.\n```JAVA\n\n@Test\nvoid semaphore_wait_Test() throws InterruptedException {\n    final var connectionPool = new ConnectionPool(1);\n\n    final var executorService = Executors.newFixedThreadPool(5);\n\n    for (int i=0; i<10; i++){\n        executorService.execute(() -> {\n            try {\n                final var connection = connectionPool.acquireConnection();\n                log.info(\"connection acquired = {}\", connection);\n                Thread.sleep(2000L);\n                connectionPool.releaseConnection(connection);\n            } catch (InterruptedException e) {\n                throw new RuntimeException(e);\n            }\n        });\n\n    }\n\n\n    Thread.sleep(15000L);\n\n}\n```\n\n```Console\n21:00:09.426 [pool-1-thread-1] INFO com.example.javaconcurrency.lib.ConnectionPool -- acquire connection\n21:00:09.427 [pool-1-thread-1] INFO com.example.javaconcurrency.lib.ConnectionPoolTest -- connection acquired = pool0\n21:00:11.432 [pool-1-thread-1] INFO com.example.javaconcurrency.lib.ConnectionPool -- release connection\n21:00:11.432 [pool-1-thread-2] INFO com.example.javaconcurrency.lib.ConnectionPool -- acquire connection\n21:00:11.432 [pool-1-thread-2] INFO com.example.javaconcurrency.lib.ConnectionPoolTest -- connection acquired = pool0\n21:00:13.437 [pool-1-thread-2] INFO com.example.javaconcurrency.lib.ConnectionPool -- release connection\n21:00:13.438 [pool-1-thread-2] INFO com.example.javaconcurrency.lib.ConnectionPool -- acquire connection\n21:00:13.438 [pool-1-thread-2] INFO com.example.javaconcurrency.lib.ConnectionPoolTest -- connection acquired = pool0\n21:00:15.443 [pool-1-thread-2] INFO com.example.javaconcurrency.lib.ConnectionPool -- release connection\n21:00:15.443 [pool-1-thread-3] INFO com.example.javaconcurrency.lib.ConnectionPool -- acquire connection\n21:00:15.443 [pool-1-thread-3] INFO com.example.javaconcurrency.lib.ConnectionPoolTest -- connection acquired = pool0\n21:00:17.448 [pool-1-thread-3] INFO com.example.javaconcurrency.lib.ConnectionPool -- release connection\n21:00:17.449 [pool-1-thread-3] INFO com.example.javaconcurrency.lib.ConnectionPool -- acquire connection\n21:00:17.449 [pool-1-thread-3] INFO com.example.javaconcurrency.lib.ConnectionPoolTest -- connection acquired = pool0\n21:00:19.452 [pool-1-thread-3] INFO com.example.javaconcurrency.lib.ConnectionPool -- release connection\n21:00:19.452 [pool-1-thread-3] INFO com.example.javaconcurrency.lib.ConnectionPool -- acquire connection\n21:00:19.452 [pool-1-thread-3] INFO com.example.javaconcurrency.lib.ConnectionPoolTest -- connection acquired = pool0\n21:00:21.453 [pool-1-thread-3] INFO com.example.javaconcurrency.lib.ConnectionPool -- release connection\n21:00:21.453 [pool-1-thread-4] INFO com.example.javaconcurrency.lib.ConnectionPool -- acquire connection\n21:00:21.453 [pool-1-thread-4] INFO com.example.javaconcurrency.lib.ConnectionPoolTest -- connection acquired = pool0\n21:00:23.457 [pool-1-thread-4] INFO com.example.javaconcurrency.lib.ConnectionPool -- release connection\n21:00:23.458 [pool-1-thread-5] INFO com.example.javaconcurrency.lib.ConnectionPool -- acquire connection\n21:00:23.458 [pool-1-thread-5] INFO com.example.javaconcurrency.lib.ConnectionPoolTest -- connection acquired = pool0\n```\nexecutorService.execute() 로 실행된 스레드 순서별로 (1~5) 락을 공정하게 획득하는 것을 확인할 수 있다.\n\n\n## Latch\nLatch 는 스레드의 실행을 제어하는 유용한 기법이다. 스레드가 태스크#1 -> 태스크#2 -> 태스크#3 순서로 진행되어야 한다면 Latch를\n쓰기에 적합한 경우다.\n\n```JAVA\n\n@Slf4j\npublic class LatchExample implements Runnable {\n\n\tprivate final CountDownLatch latch;\n\n\tpublic LatchExample(final CountDownLatch latch) {\n\t\tthis.latch = latch;\n\t}\n\n\t@Override public void run() {\n\t\tlog.info(\"Do parallel Async Processing\");\n\t\ttry {\n\t\t\tThread.sleep(1000L);\n\t\t} catch (InterruptedException e) {\n\t\t\tthrow new RuntimeException(e);\n\t\t}\n\t\tlatch.countDown();\n\t\ttry {\n\t\t\tlatch.await();\n\t\t} catch (InterruptedException e) {\n\t\t\tthrow new RuntimeException(e);\n\t\t}\n\t\tlog.info(\"Done parallel Async Processing\");\n\n\t}\n}\n```\n```JAVA\n@Test\nvoid latch_test() throws InterruptedException {\n    final var countDownLatch = new CountDownLatch(5);\n\n    final var pool = Executors.newFixedThreadPool(5);\n    for (int i=0; i<5; i++){\n        pool.execute(new LatchExample(countDownLatch));\n    }\n\n    log.info(\"await on main\");\n    countDownLatch.await();\n    log.info(\"done on main\");\n    Thread.sleep(5000L);\n}\n```\n\n```CONSOLE\n21:15:33.891 [pool-1-thread-5] INFO com.example.javaconcurrency.lib.LatchExample -- Do parallel Async Processing\n21:15:33.891 [pool-1-thread-2] INFO com.example.javaconcurrency.lib.LatchExample -- Do parallel Async Processing\n21:15:33.891 [pool-1-thread-1] INFO com.example.javaconcurrency.lib.LatchExample -- Do parallel Async Processing\n21:15:33.891 [main] INFO com.example.javaconcurrency.lib.LatchExampleTest -- await on main\n21:15:33.891 [pool-1-thread-3] INFO com.example.javaconcurrency.lib.LatchExample -- Do parallel Async Processing\n21:15:33.891 [pool-1-thread-4] INFO com.example.javaconcurrency.lib.LatchExample -- Do parallel Async Processing\n21:15:34.898 [pool-1-thread-5] INFO com.example.javaconcurrency.lib.LatchExample -- Done parallel Async Processing\n21:15:34.899 [pool-1-thread-2] INFO com.example.javaconcurrency.lib.LatchExample -- Done parallel Async Processing\n21:15:34.898 [main] INFO com.example.javaconcurrency.lib.LatchExampleTest -- done on main\n21:15:34.898 [pool-1-thread-3] INFO com.example.javaconcurrency.lib.LatchExample -- Done parallel Async Processing\n21:15:34.899 [pool-1-thread-4] INFO com.example.javaconcurrency.lib.LatchExample -- Done parallel Async Processing\n21:15:34.898 [pool-1-thread-1] INFO com.example.javaconcurrency.lib.LatchExample -- Done parallel Async Processing\n```\n\nLatch 카운터가 처음에 5로 세팅하고 countDown()을 호출할 때마다 카운트 값은 1만큼 감소한다.\n카운트가 0이 되면 래치가 열리고 await() 함수 때문에 대기 중이던 스레드는 모두 해제되어 처리를 재개하게 된다.\n래치는 단 한번밖에 사용할 수 없다. 결과가 0이 되면 해당 래치는 두 번 다시 재사용할 수 없다.\n\n## Executor와 태스크 추상화\n저수준의 스레드 문제를 직접 다루려고 하기 보다는 java.util.concurrent 패키지에서 적절한 수준으로 추상화된 동시 프로그래밍 라이브러리를 쓰는 편이 좋다.\nJava에서는 일의 단위를 Task로 추상화하여 개발자는 실제 스레드의 수명주기를 일일히 신경 쓸 필요없이 사용할 수 있도록 하였다.\nExecutorService는 관리되는 스레드 풀에서 태스크 실행 메커니즘을 규정한 인터페이스다.   \nExecutors는 헬퍼 클래스로, 스레드 풀을 생성하는 팩터리 메서드를 제공한다.\n\n- newFixedThreadPool(int nThreads)\n  크기가 고정된 스레드 풀을 지닌 ExecutorService를 생성한다. 스레드는 재사용되며 스레드가 전부 사용 중일 경우, 새 태스크는 큐에 보관한다.\n\n- newCachedThreadPool()\n  필요한 만큼 스레드를 생성하되 가급적 스레드를 재사용한다. 생성된 스레드는 60초 간 유지되며, 그 이후에는 캐시에서 삭제된다.\n  소규모 비동기 태스크의 성능을 향상시킬 수 있다.\n\n- newSingleThreadExecutor()\n  스레드 하나만 가지는 ExecutorService를 생성한다.\n\n- newScheduledThreadPool(int corePoolSize)\n  미래에 태스크를 실행시킬 수 있도록 Callable 과 지연 시간을 전달받는 메서들이 있다.\n\n\n## 포크/조인\n자바 7부터 등장한 포크 조인 프레임워크는 멀티 프로세서 환경에서 효율적으로 작동하는 새로운 API를 제공한다.\n이 프레임워크는 ForkJoinPool 이라는 새로운 ExecutorService 구현체에 기반한다. ForkJoinPool 클래스는 다음과 같은 다음과 같은 특징을 가진다.\n- 하위 분할 태스크를 효율적으로 처리할 수 있다.\n- Work-Stealing(작업 빼앗기) 알고리즘을 구현한다.\n\nWork-Stealing 알고리즘은 어느 스레드가 자신이 할당받은 작업을 모두 마쳤는데 다른 스레드에 아직 배로그가 남아 있으면\n바쁜 스레드의 큐에서 작업을 가져와 실행할 수 있다.\n\n\n## 스트림과 병렬 스트림\n모든 컬렉션은 Collection 인터페이스에 있는 stream() 메서드를 제공해야한다.\nstream()은 스트림을 생성하는 구현체를 내어주는 메서드로 내부에서 ReferencePipeline을 생성한다.\nparallelStream()은 병렬로 데이터를 작업 후 그 결과를 재조합할 수 있다. 내부적ㅇ로 Spliterator를 써서 작업을 분할하고\n공용 포크/조인 풀에서 연산을 수행한다.\n\n## 락-프리 기법\n락-프리 기법은 블로킹 기반의 락 메커니즘이 처리율에 악영향을 미친다는 전제하에 시작되었다.\n스레드 락이 걸리는 상황에서는 스레드를 중단/재개시키는 과정(컨텍스트 스위칭)에 많은 시간이 소요될 수 있으므로 락-프리한 기법보다 훨씬 느릴 수 밖에 없다."},{"excerpt":"Primary Key 설계의 중요성 InnoDB 기준으로 MySQL은 Primary Key를 기준으로 데이터를 클러스터링한다. \n클러스터링이라는 용어는 인접한 키 값이 있는 레코드가 물리적으로도 인접하게 저장된다는 것을 말한다.\n즉, 논리적인 PK 값에 의해 레코드의 물리적인 위치가 결정된다.\nPK값이 변경된다면 해당 레코드의 물리적인 위치도 변경된다는 …","fields":{"slug":"/mysql-primary-key-design/"},"frontmatter":{"date":"August 06, 2023","title":"고성능을 위한 MySQL Primary Key 설계 전략","tags":["데이터베이스"]},"rawMarkdownBody":"\n## Primary Key 설계의 중요성\n\nInnoDB 기준으로 MySQL은 Primary Key를 기준으로 데이터를 클러스터링한다. \n클러스터링이라는 용어는 인접한 키 값이 있는 레코드가 물리적으로도 인접하게 저장된다는 것을 말한다.\n즉, 논리적인 PK 값에 의해 레코드의 물리적인 위치가 결정된다.\nPK값이 변경된다면 해당 레코드의 물리적인 위치도 변경된다는 얘기다.   \n\n모든 데이터베이스가 마찬가지겠지만 MySQL의 PK 설계는 다른 데이터베이스보다 더 중요하다고 볼 수 있다.\n왜냐하면, 일부 데이터베이스에서는 클러스터링할 인덱스를 선택할 수 있지만 MySQL은 기본키로 고정되어 변경할 수 없다. (MySQL 8.x 기준)   \n또한, MySQL은 Secondary Index의 Leaf Node에 오라클과 같이 물리적 위치에 대한 참조(ROWID)가 아닌 PK 값을 저장하고, PK 인덱스를 통해 실제 디스크 블록에 접근한다. 따라서, MySQL에서 PK 는 단순히 데이터를 식별하기 위한 식별자 역할뿐만 아니라 내부 구현에도 관여하기 때문에 그 중요성은 매우 크다고 볼 수 있다.\n\n\n\n## 클러스터형 인덱스\n\n고성능을 위한 Primary Key 를 설계하기 위해서는 Primary Key 의 저장 구조인 클러스터형 인덱스에 대한 이해가 필요하다.\n아래의 그림은 **Secondary Index**(Non-Clusted Index) 와 **Primary Key Index**(Clusted Index) 의 저장 구조를 나타낸다.   \n\n**Secondary Index**(Non-Clusted Index) 그림의 리프 노드를 보면 Index Key 값에 해당 하는 Primary Key 값을 저장하고 있는 것을 볼 수 있다.\nIndex Key 값은 정렬되어 있지만 Index Key 값에 맵핑되는 Primary Key들 사이에는 아무런 순서관계가 없다.\n\n**Primary Key Index**(Clusted Index) 그림의 리프 노드는 Index Key 값 기준으로 정렬되어 있고,\n참조가 아닌 실제 레코드를 저장하는 페이지가 리프노드에 위치해 있다. 페이지 내에서도 Primary Index Key 값 기준으로 레코드가 물리적으로 정렬되어 있다.\n\n<!-- more -->\n![img.png](./img/index-tree.png)\n\nClusted Index는 구조적인 이유로 순차적인 Key 값을 넣을 때, 오버헤드가 가정 적고 가장 빠르다. 단순히 Index 트리 오른쪽 맨끝에 새로운 레코드를 삽입해주기만 하면 된다.    \n반면에 비순차적인 Key 값이 들어오게 되면 상황이 복잡해진다. Key 값이 기존 데이터 중간에 삽입될 수 있으므로 트리 구조를 변경사항에 맞게 갱신해야 한다.   \n또한, 리프 노드의 페이지 안에 있는 데이터의 순서도 조정이 필요하다. 기존 데이터 사이에 새 레코드의 적절한 위치를 찾고 공간을 확보해야 한다. 이로 인해 많은 데이터의 이동이 필요할 수 있고 페이지 분할로 단편화 문제가 발생할 수 있다.\n\n따라서 INSERT 속도가 중요한 테이블이라면 순차적인 값을 Primary Key로 선정하는 것이 유리하다.\n\n\n\n## Primary Key 유형\n### 자동 증가 (Auto Increment) Primary Key\n**장점**\n- Primary Key 채번을 DB에 위임하므로 관리 포인트가 줄어든다.\n\n**단점**\n- 테이블의 대량 INSERT 작업 시, Auto Increament 에서 병목현상이 발생할 수 있다.\n\n\n\n### UID\n클러스터형 인덱스 구조를 이해하면, UUID와 같은 랜덤 값이 Primary Key로 선정될 경우, 레코드 클러스터링에 필요한 오버헤드만 발생하고 크게 이점이 없음을 알 수 있다. \n그러나 랜덤 UID가 아닌 순차적인 UID를 생성하면 Auto Increment의 병목현상과 클러스터링 오버헤드를 모두 피할 수 있다.\n순차적인 UID는 (현재시각 + 일련번호) 또는 (epoch time + 일련번호)와 같은 조합으로 순서를 유지하는 UID를 만들 수 있다.\n\n**장점 (Sequential UID)**\n- 대량 INSERT 작업을 매우 빠르게 처리할 수 있다.\n\n**단점 (Sequential UID)**\n- 클라이언트에서 순차적인 UID를 만들기 위해 관리가 필요하다.\n\n\n### Composite key\n논리 모델링과 물리 모델링의 격차가 적고, 사람이 이해하기 쉽다. 중복키 값이 들어올 수 있으므로 동시성 관리가 필요하다.\n\n**장점**\n- 공간적 지역성(Spatial Locality) 를 활용할 수 있다.\n\n**단점**\n- 클라이언트에서 채번에 대한 동시성 관리가 필요하다.\n\n\n\n## 대리키와 복합키 비교\nAuto increament 와 UID 를 이용한 기본키 유형은 대리키로 일반화할 수 있다. Primary Key를 대리키로 구성한 방식과 복합키로 구성한 방식의 차이점을 비교해본다.\n\n\n### 부모테이블의 기본키를 자식 테이블의 기본키로 쓰지 않고, 외래키로 사용하는 경우 (비식별관계)\n\n![mysql_img_1.png](./img/mysql_img_1.png)\n\nPost, Comment 테이블 둘 다 Auto Increament 기본키를 사용하고, Comment 테이블에 post\\_id FK 를 두어 Post와 연관관계를 맺는 방식이다.\nPost 테이블이 Driving Table이고 Comment 테이블이 Driven Table 인 경우 두 테이블을 조인하게 되면 아래 그림와 같은 방식으로 데이터를 탐색하게 된다.\n\n![mysql_img_2.png](./img/mysql_img_2.png)\n\n조인 연산을 수행하기 위해, Post 테이블의 기본키와 연결된 Comment 테이블의 Post\\_id 값으로 조인이 이루어진다. Comment 테이블의 post_id에는 이미 인덱스가 생성되어 있기 때문에, Index Range Scan을 사용하여 Post 테이블과 Comment 테이블을 맵핑할 수 있다.\n\n그 다음 단계에서는 SELECT 결과를 가져오기 위해 Comment 테이블의 레코드를 검색한다. 이 과정에서 Comment 레코드의 탐색을 위해 Random I/O가 발생하게 된다. Comment 테이블의 POST\\_ID\\_IDX 인덱스는 POST\\_ID별로 정렬되어 있어 같은 POST\\_ID를 가지더라도 COMMENT\\_ID는 멀리 떨어져있는 값을 가질 수 있다.\n\n예를 들어 위의 그림에서, Post 테이블에서 id=3인 레코드를 조회하면, Comment 테이블의 post\\_id와의 조인 결과로 Comment id (100, 200)이 반환된다. 페이지 당 50개 레코드가 저장된다고 가정하면 2개의 Comment 레코드를 가져오기 위해 총 2개의 페이지 읽기 작업이 필요하게 된다.\n\n\n### 부모테이블의 기본키를 자식 테이블 기본키에 포함하는 경우 (식별관계)\n\n![mysql_img_3.png](./img/mysql_img_3.png)\n\n두번째 예에서는 Comment가 POST의 ID를 자신의 기본키에 포함시킨 Composite Key로 PK를 구성한 예이다. 마찬가지로 아래는 Post 테이블이 Driving Table이고 Comment 테이블이 Driven Table 인 경우 두 테이블을 조인할 때, 데이터 탐색 방식이다.\n\n![mysql_img_4.png](./img/mysql_img_4.png)\n\n첫번째 방식과 유사하게, 조인이 발생했을 때 Comment 레코드를 읽어오기 위해 페이지 3을 두 번 참조하게 되지만, 이 경우 페이지 3은 이미 캐싱되어 있으므로 두 번째 참조는 추가적인 I/O를 발생시키지 않는다.\n\n두 방식에서 논리적 페이지 I/O는 2로 동일하지만, 물리적 페이지 I/O(캐시 적용 시)는 각각 2와 1로 다르다. 조인되는 데이터가 많아질수록 두 방식 사이의 물리적 I/O 차이는 더욱 커지게 된다.\n\n이러한 결과는 두 번째 케이스에서 식별관계를 사용해 기본키를 복합키로 구성했기 때문에 발생한다. POST\\_ID를 기준으로 조인을 수행할 때, 공간적 지역성(Spatial Locality)의 원리가 적용되었다고 볼 수 있다. 특정 Post에 속한 Comment 집합은 같은 논리적 영역에 속하는 인스턴스라고 볼 수 있다. POST_ID와 COMMENT_ID로 클러스터링하면, 물리적으로도 POST_ID에 속한 COMMENT 집합이 유사한 영역에 위치하게 되므로 캐싱 확률이 높아지게 된다.\n\n실제로 같은 페이지 번호에 저장되어 있는 레코드를 탐색하기 위해서 몇번의 I/O가 발생했는지 확인하기 위해서는 MySQL에서 제공하는 상태 변수 중 Innodb\\_buffer\\_pool\\_reads 값을 확인하여 물리적 I/O 발생량을 확인할 수 있다. 해당 상태변수는 버퍼풀에서 읽지못하고 디스크에서 직접 읽은 수를 의미하는 변수이다.\n\n\n\n#### 데이터를 읽기 전에 Innodb\\_buffer\\_pool\\_reads 값\n```shell\nmysql> SHOW SESSION STATUS LIKE 'Innodb_buffer_pool_reads%';\n+--------------------------+-------+\n| Variable_name            | Value |\n+--------------------------+-------+\n| Innodb_buffer_pool_reads | 1652  |\n+--------------------------+-------+\n1 row in set (0.03 sec)\n```\n\n\n\n#### 멀리 떨어진 두 개의 Record를 두 건 읽는 경우 (레코드의 페이지가 다른 경우)\n```shell\nmysql> select *\n-> from ORDER\n-> where ORDER.ORDER_NO in (2000,3000);\n\nSHOW SESSION STATUS LIKE 'Innodb_buffer_pool_reads%';\n+--------------------------+-------+\n| Variable_name            | Value |\n+--------------------------+-------+\n| Innodb_buffer_pool_reads | 1654  |\n+--------------------------+-------+\n1 row in set (0.04 sec)\n```\nPK가 2000, 3000 인 레코드 두 건을 읽었을 떄 Innodb\\_buffer\\_pool\\_reads 변수가 1652 → 1654 로 증가된 것을 확인할 수 있다. 2번의 Disk I/O가 발생하였다.\n\n\n#### 클러스터링으로 인접한 Record를 두 건 읽는 경우 (레코드 페이지가 같은 경우)\n\n```shell\nmysql> select *\n-> from `MARKETBOM2_SCHM`.BIZ_SLIP_TRADE\n-> where BIZ_SLIP_TRADE.TRADE_SLIP_NO in (5000,5001);\n\nmysql> SHOW SESSION STATUS LIKE 'Innodb_buffer_pool_reads%';\n+--------------------------+-------+\n| Variable_name            | Value |\n+--------------------------+-------+\n| Innodb_buffer_pool_reads | 1655  |\n+--------------------------+-------+\n1 row in set (0.01 sec)\n```\n\nPK가 5000, 5001 인 레코드를 두 건 읽었을 때 Innodb\\_buffer\\_pool\\_read 변수가 1654 → 1655 로 증가된 것을 확인할 수 있다. 아까와 같이 레코드를 두 건 읽었지만 실제 Disk I/O 발생량은 1번인 것을 확인할 수 있다.\n\n\n## 정리\nMySQL의 고성능 Primary Key 설계를 위해서는 클러스터링 인덱스의 특성을 이해하고 테이블의 주 용도 및 액세스 패턴을 정확히 파악해야 한다.\n\n쓰기 중심의 작업에서는 순차적 ID를 사용하여 성능을 최적화할 수 있다. 이는 쓰기 작업 시 디스크 I/O를 효율적으로 하기 위함이다.\n\n읽기 중심의 작업에서는 Random I/O가 주로 발생한다면 대리키를, Join 많이 걸리거나 업무적으로 연관된 데이터 중심으로 조회가 많이 되는 경우라면 물리적으로 인접할 수 있도록 업무적인 복합키를 구성하는게 유리할 것 이다.\n\n실제 업무 시스템에서는 중요한 테이블(예: 이커머스의 주문 테이블)에 대해서는 쓰기와 읽기 작업 모두 빈번하게 발생한다. 이런 상황에서는 쓰기와 읽기 간의 트레이드 오프를 고려하여 결정해야한다. 대다수의 시스템에서 쓰기 대비 읽기의 비율이 8:2 또는 9:1로 나타나기 때문에, 읽기 작업에 최적화된 설계를 택하는 것이 대체로 유리할 것 이다.\n\n중요한것은 MySQL의 클러스터 인덱스와 세컨더리 인덱스 구조를 이해하고, 그 이해를 바탕으로 시스템 요구 사항에 가장 적합한  Primary Key를 선택할 수 있어야 한다."},{"excerpt":"Spring Boot2 + Ehcache3 Spring Cache Abstract 와 Ehcache3 모듈 설정 방법을 알아본다. Gradle Dependency 설정 캐시 구성 Ehcache3 버전부터는 JSR-107을 자바 표준 인터페이스를 구현하였다.\n캐시에 대한 자바 표준 인터페이스를 JCache 라고 한다.\nJPA 구현체에 Hibernate 와 …","fields":{"slug":"/ehcache3/"},"frontmatter":{"date":"July 24, 2023","title":"Ehcache3 캐시 라이브러리 소개 (with Spring Boot)","tags":["스프링"]},"rawMarkdownBody":"\n\n\n## Spring Boot2 + Ehcache3\n\nSpring Cache Abstract 와 Ehcache3 모듈 설정 방법을 알아본다.\n\n## Gradle Dependency 설정\n\n```\nimplementation(\"org.springframework.boot:spring-boot-starter-cache\")\nimplementation(\"org.ehcache:ehcache:3.9.5\")\nimplementation(\"javax.cache:cache-api:1.1.1\")\n```\n\n## 캐시 구성\n\nEhcache3 버전부터는 JSR-107을 자바 표준 인터페이스를 구현하였다.\n캐시에 대한 자바 표준 인터페이스를 JCache 라고 한다.\nJPA 구현체에 Hibernate 와 EclipseLink 등이 있는 것 처럼 JCache 구현체 중 하나가 Ehcache3 이다.\n\n<!-- more -->\n\n### Ehcache Configuration\n\nEhcache는 Programmatic 과 xml 두 가지 방식으로 설정할 수 있다.\n자세한건 [공식문서](https://www.ehcache.org/documentation/3.9/getting-started.html#configuring-with-java)를 참조하자.\n여기서는 XML 방식이 조금 더 관리하기 쉬울 것 같아 XML 방식으로 설정한다.\n\n```xml\n\n<config\n  xmlns:xsi='http://www.w3.org/2001/XMLSchema-instance'\n  xmlns='http://www.ehcache.org/v3'\n  xmlns:jsr107=\"http://www.ehcache.org/v3/jsr107\"\n  xsi:schemaLocation=\"http://www.ehcache.org/v3 http://www.ehcache.org/schema/ehcache-core.xsd\n        http://www.ehcache.org/v3/jsr107 http://www.ehcache.org/schema/ehcache-107-ext-3.0.xsd\">\n\n  <service>\n    <jsr107:defaults enable-management=\"true\" enable-statistics=\"true\"/>\n  </service>\n\n  <cache-template name=\"default\">\n    <listeners>\n      <listener>\n        <class>com.example.springboot.cache.EhcacheEventListener</class>\n        <event-firing-mode>ASYNCHRONOUS</event-firing-mode>\n        <event-ordering-mode>UNORDERED</event-ordering-mode>\n        <events-to-fire-on>CREATED</events-to-fire-on>\n        <events-to-fire-on>UPDATED</events-to-fire-on>\n        <events-to-fire-on>EXPIRED</events-to-fire-on>\n        <events-to-fire-on>REMOVED</events-to-fire-on>\n        <events-to-fire-on>EVICTED</events-to-fire-on>\n      </listener>\n    </listeners>\n    <resources>\n      <heap>100</heap>\n      <offheap unit=\"MB\">1</offheap>\n    </resources>\n  </cache-template>\n\n\n  <cache alias=\"findByEventGroupId\" uses-template=\"default\">\n    <key-type>java.lang.String</key-type>\n    <value-type>com.marketboro.marketbom2.module.system.domain.entity.applicationmessage.Eventagsgregator</value-type>\n    <expiry>\n      <ttl unit=\"minutes\">10</ttl>\n    </expiry>\n  </cache>\n\n</config>\n```\n\n[공식문서](https://www.ehcache.org/documentation/3.9/xml.html)를 참조하여 XML의 element들을 정리하였다.\n\n### `<config>`\n\nXML 구성의 루트 요소이다. 하나의 `<config>` 요소는 CacheManager에 대한 정의를 제공한다.\n\n### `<persistence>`\n\n영속화 캐시 매니저를 생성할 때 사용되는 요소이다. 여기에는 디스크에 데이터를 저장해야 하는 디렉터리 위치가 필요하다.\n\n### `<cache>`\n\n`<cache>` 요소는 CacheManager에 의해 생성 및 관리될 Cache 인스턴스를 나타낸다.\n`<cache>` 요소는 Alias를 필수적으로 지정해줘야한다. Alias는 네임스페이스 같은 역활을 한다.\nKey 값이 같더라도 Alias(네임스페이스)가 다르면 다른 별개로 저장된다.\n\n`<cache>` 요소는 아래 요소들을 포함할 수 있다.\n\n1. `<key-type>`: 캐시 Key에 해당하는 풀패키지 클래스명\n2. `<value-type>`: 캐시 Value에 해당하는 풀패키지 클래스명\n3. `<expiry>`: 만료 유형에 대한 설정\n4. `<eviction-advisor>`: 캐쉬 만료에 대한 advisor를 설정한다.\n5. `<resource>`: 스토리지 계층과 용량을 설정한다. heap 만 사용할 경우 `<heap>` 으로 대체 가능\n\n스토리지 계층은 다양한 데이터 저장 영역을 사용하도록 Ehcache를 구성할 수 있다.\nEhcache에서 지원하는 데이터 저장소는 다음과 같다.\n계층 구조를 사용하여 다중 계층 설정도 가능하다. 캐시가 On-Heap 계층에 없으면 Off-heap 계층을 참조할 수 있다.\n다중 계층 구조를 사용할 때 주의할점은, 아래 계층 스토리지 할당량보다 윗 계층 스토리지 할달량이 적어야 한다는 것이다.\n\n- On-Heap Store   \n  Java의 온-힙 RAM 메모리를 활용하여 캐시 항목을 저장합니다. 이 계층은 Java 애플리케이션과 동일한 힙 메모리를 사용하며, 모든 힙 메모리는 JVM 가비지 컬렉터에서 스캔해야 합니다. JVM이 사용하는 힙 공간이 많을수록 가비지 수집 일시 중지로 인해 애플리케이션 성능이 더\n  많이 영향을 받습니다. 이 저장소는 매우 빠르지만 일반적으로 가장 제한된 저장소 리소스입니다.\n\n\n- Off-Heap Store   \n  사용 가능한 RAM에 의해서만 크기가 제한됩니다. Java 가비지 컬렉션(GC)의 영향을 받지 않습니다. 매우 빠르지만 데이터를 저장하고 다시 액세스할 때 JVM 힙으로 데이터를 이동해야 하므로 온-힙 스토어보다 느립니다.\n\n\n- Disk Store    \n  디스크 저장소 - 디스크(파일 시스템)를 사용하여 캐시 항목을 저장합니다. 이 유형의 저장소 리소스는 일반적으로 매우 풍부하지만 RAM 기반 저장소보다 훨씬 느립니다. 디스크 스토리지를 사용하는 모든 애플리케이션의 경우 처리량을 최적화하기 위해 빠른 전용 디스크를 사용하는 것이\n  좋습니다.\n\n\n- Clustered Store    \n  이 데이터 저장소는 원격 서버에 있는 캐시입니다. 원격 서버에는 선택적으로 장애 조치 서버가 있어 고가용성을 향상시킬 수 있습니다. 클러스터형 스토리지는 클라이언트/서버 일관성 유지와 네트워크 지연 등의 요인으로 인해 성능이 저하될 수 있으므로 이 계층은 본질적으로 로컬 오프 힙\n  스토리지보다 느립니다.\n  Terracotta 라는 분산 캐시 서버로만 가능한 것 같다.\n\n### `<cache-template>`\n\n`<cache>` 요소가 템플릿을 상속받아 사용할 수 있다. `uses-template` 속성을 통해 cache-template을 참조할 수 있다.\n\n## 캐시 교체 정책\n\nEhcache 2.x 버전에서는 힙 메모리에 대한 캐시 교체 정책`(LRU, LFU, FIFO)`을 지원했다. 그런데 Ehcache 3부터는 3가지 정책이 사라졌는데,\n구글링을 통해 조사해본 결과, 힙 메모리 교체 정책과 다른 계층의 교체 정책이 다를 수 있기 때문에 지원이 중단된 듯 하다.\n그래서 3 버전 기준으로는 다음 세가지 정책을 제공하고 있다.\n\n- no expiry : 캐시 매핑이 만료되지 않음\n- time-to-live : 캐시 매핑이 생성된 후 정해진 기간 후에 만료됨\n- time-to-idle : 캐시 매핑이 마지막으로 액세스한 시간 이후 정해진 기간 후에 만료됨\n\n```xml\n\n<cache alias=\"withExpiry\">\n  <expiry>\n    <ttl unit=\"seconds\">20</ttl>\n  </expiry>\n  <heap>100</heap>\n</cache>\n```\n\n### Custom expiry\n\nEhcache3 은 Custom expiry 정책을 정의할 수 있다. 아래 인터페이스를 구현하는 custom policy 클래스를 구현하면 된다.\n\n```java\npublic interface ExpiryPolicy<K, V> {\n\n\tDuration INFINITE = Duration.ofNanos(Long.MAX_VALUE);\n\tExpiryPolicy<Object, Object> NO_EXPIRY = new ExpiryPolicy<Object, Object>() {\n\t\tpublic String toString() {\n\t\t\treturn \"No Expiry\";\n\t\t}\n\n\t\tpublic Duration getExpiryForCreation(Object key, Object value) {\n\t\t\treturn INFINITE;\n\t\t}\n\n\t\tpublic Duration getExpiryForAccess(Object key, Supplier<?> value) {\n\t\t\treturn null;\n\t\t}\n\n\t\tpublic Duration getExpiryForUpdate(Object key, Supplier<?> oldValue, Object newValue) {\n\t\t\treturn null;\n\t\t}\n\t};\n\n\tDuration getExpiryForCreation(K var1, V var2);\n\n\tDuration getExpiryForAccess(K var1, Supplier<? extends V> var2);\n\n\tDuration getExpiryForUpdate(K var1, Supplier<? extends V> var2, V var3);\n}\n```\n\n```xml\n\n<cache alias=\"withCustomExpiry\">\n  <expiry>\n    <class>com.pany.ehcache.MyExpiry</class>\n  </expiry>\n  <heap>100</heap>\n</cache>\n```\n\n## Springboot Configuration\n\nEhcache3 는 JCache 므로 아래와 같이 설정해줘야 한다.\n\n```yml\nspring:\n  cache:\n    jcache:\n      config: classpath:ehcache.xml\n```\n\nEhcache 2.x 버전은 아래와 같이 설정한다.\n\n```yml\nspring:\n  cache:\n    ehcache:\n      config: classpath:ehcache.xml\n```\n\n그리고 어플리케이션에 `@EnableCaching` 어노테이션을 붙여준다.\n\n```java\n@EnableCaching\n@SpringBootApplication\npublic class ExampleApplication {\n\n}\n```\n\n새 프로젝트로 시작한다면 여기까지만 해도 Springboot 와 Ehcache 설정은 완료된다.\n만약, 프로젝트에 redis를 이미 사용 중이라면 redis가 Ehcache보다 우선순위가 높아 기본 CacheManger를 `RedissonSpringCacheManager`로 설정한다.\n따라서, 따로 Ehcache용 CacheManager를 `@Bean`으로 등록해주어야 한다.\n여기서 중요한것은 `org.springframework.cache.CacheManger` 인터페이스의 구현체로 `org.springframework.cache.ehcache.EhCacheCacheManager` 가 있는데, 이 클래스는 Ehcache2 버전에 사용되는 것이다.\n처음에도 말했듯이 Ehcache3는 JCache의 한 종류로 `JCacheCacheManger로` 등록해줘야한다.\n\n```java\nimport java.io.IOException;\nimport javax.cache.CacheManager;\nimport javax.cache.Caching;\nimport javax.cache.spi.CachingProvider;\nimport org.springframework.cache.jcache.JCacheCacheManager;\nimport org.springframework.context.annotation.Bean;\nimport org.springframework.context.annotation.Configuration;\nimport org.springframework.core.io.ClassPathResource;\n\n@Configuration\npublic class EhcacheConfig {\n\n\t@Bean(name = \"ehCacheManager\")\n\tpublic org.springframework.cache.CacheManager cacheManager() throws IOException {\n\t\tCachingProvider cachingProvider = Caching.getCachingProvider(\"org.ehcache.jsr107.EhcacheCachingProvider\");\n\t\tCacheManager manager = cachingProvider.getCacheManager(\n\t\t\t\tnew ClassPathResource(\"/ehcache.xml\").getURI(),\n\t\t\t\tgetClass().getClassLoader());\n\n\t\treturn new JCacheCacheManager(manager);\n\t}\n}\n```\n\n캐싱을 적용할 메서드에 @Cacheable 어노테이션을 붙여준다.\n\n```java\npublic class CacheService {\n\n\t@Cacheable(cacheManager = \"ehCacheManager\", cacheNames = \"Cache\")\n\tpublic String findById(String id) {\n\t\tlog.info(\"findById = {}\", id);\n\t\treturn id;\n\t}\n\n}\n```\n\nCache 라는 이름으로 메서드 인자인 id 값을 key로, return 값을 value로 결과를 캐싱한다.\n@Cacheable은 다음 매개변수를 사용할 수 있다.\n\n- value / cacheName : 메서드 실행 결과가 저장될 캐시의 이름입니다.\n- key : SpEL(Spring Expression Language) 로 캐시 항목의 키입니다 . 매개변수를 지정하지 않으면 기본적으로 모든 메서드 매개변수에 대해 키가 생성됩니다.\n- keyGenerator : KeyGenerator 인터페이스를 구현하여 사용자 정의 캐시 키 생성을 허용하는 Bean의 이름입니다.\n- condition : 결과를 캐시할 시기를 지정하는 SpEL(Spring Expression Language)로서의 조건입니다.\n- unless : 결과를 캐시하지 않아야 하는 경우를 지정하는 SpEL(Spring Expression Language)로서의 조건입니다.\n\n스프링에서는 @Cacheable 말고도 @CacheEvict, @CachePut, @CacheConfig 어노테이션을 지원한다.\n기본적인 내용은 @Cacheable 과 크게 다르지 않으므로 자세한 내용은 [공식문서](https://docs.spring.io/spring-framework/docs/3.2.x/spring-framework-reference/html/cache.html)를 참조하자.\n\n\n## JSR 107 어노테이션, Spring Cache 어노테이션 비교\n\n| JSR 107 / JCache Annotations | \tSpring Cache Annotations    |\n|------------------------------|------------------------------|\n| @CacheResult                 | @Cacheable                   |\n| @CacheRemove                 | \t@CacheEvict                 |\n| @CacheRemoveAll              | @CacheEvict(allEntries=true) |\n| @CachePut                    | @CachePut                    |\n| @CacheDefaults               | @CacheConfig                 |\n\n\n\n"},{"excerpt":"N+1 쿼리는 무엇을 의마하나? JPA의 한계를 설명하기 위해서는 N+1 쿼리가 발생하는 원초적인 원인에 대해 이해하는 것이 필요하다. JPA를 사용하다보면 N+1 쿼리를 경험할 수 있는데, 기술적인 방법으로 N+1 쿼리를 해결하는 게시물은 많지만, 왜 이러한 쿼리가 발생하는지에 대해 정확히 설명하는 블로그는 찾기 어렵다. 본 포스팅에서는 N+1 쿼리가 …","fields":{"slug":"/jpa-slow-cause/"},"frontmatter":{"date":"July 21, 2023","title":"JPA가 느릴 수 밖에 없는 원초적인 이유","tags":["JPA"]},"rawMarkdownBody":"\n## N+1 쿼리는 무엇을 의마하나?\nJPA의 한계를 설명하기 위해서는 N+1 쿼리가 발생하는 원초적인 원인에 대해 이해하는 것이 필요하다.   \nJPA를 사용하다보면 N+1 쿼리를 경험할 수 있는데, 기술적인 방법으로 N+1 쿼리를 해결하는 게시물은 많지만, 왜 이러한 쿼리가 발생하는지에 대해 정확히 설명하는 블로그는 찾기 어렵다.  \n본 포스팅에서는 N+1 쿼리가 발생하는 원인을 설명하고, 이로 인해 JPA가 성능상 한계에 부딪힐 수밖에 없는 이유에 대해 설명하려고 한다.\n\n<!-- more -->\n```JAVA\n@Entity\npublic class Member {\n\n    @Id @GeneratedValue(strategy = GenerationType.AUTO)\n    private Long id;\n    private String username;\n\n    @ManyToOne\n    @JoinColumn(name = \"team_id\")\n    private Team team;\n}\n```\n```JAVA\n@Entity\npublic class Team {\n\n    @Id @GeneratedValue(strategy = GenerationType.AUTO)\n    private Long id;\n    private String teamName;\n\n    @OneToMany\n    private List<Member> members;\n}\n```\n```JAVA\n@Transactional\n@SpringBootTest\nclass JpaTest{\n\t\n\t@Test\n\tvoid Nplus1테스트() {\n\n\t\tfinal var teams = em.createQuery(\"select team from Team team\", Team.class)\n\t\t\t\t.getResultList();\n\n\t\tfor (final Team team : teams) {\n\t\t\tteam.getMembers().forEach(member -> System.out.println(member.getUsername()));\n\t\t}\n\t}\n}\n```\n위의 테스트 코드를 실행시키면 team 을 조회하는 쿼리(1)와 각 team 별로 자식인 member 조회하는 쿼리(N)이 나가, 결과적으로 N+1 쿼리가 발생한다.\n\n아래는 테스트 코드를 돌렸을 때, 데이터베이스로 호출되는 SQL이다.\n```SQL\nSELECT * FROM team; /-- (1번 쿼리) --/\nSELECT * FROM member where member.team_id = 1; /-- (N 쿼리) --/\nSELECT * FROM member where member.team_id = 2; /-- (N 쿼리) --/\n```\n\n간단한 이유로 N+1 쿼리가 발생하는 이유는 다음과 같다. member와 join 없이 team에 대해서만 select 쿼리를 날렸기 때문이다.\n처음에 (1번) 쿼리에서는 Team만 조회되었기 때문에, 연관된 테이블인 member를 찾기 위해 추가적인 쿼리가 필요하게 된다. 이로 인해 쿼리의 수가 N+1개가 되는 것이다.\n\n아래는 Native SQL로 N+1 쿼리를 발생시키는 코드다. (예시)\n```JAVA\nclass JpaTest {\n\t\n\t@Test\n\tvoid native_sql_Nplus1(){\n\n\t\tfinal var teams = jdbcTemplate.query(\"SELECT * FROM team\", teamRowMapper);\n\n\t\tfor (final Team team : teams) {\n\t\t\tfinal var member = jdbcTemplate.query(\"SELECT * FROM member WHERE member.team_id = \" + team.getId(), memberRowMapper);\n\t\t\tmember.forEach(m -> System.out.println(m.getUsername()));\n\t\t}\n\n\t}\n}\n```\nN+1 쿼리는 JPA 입장에서는 연관 관계 맵핑 정보를 보고 그대로 쿼리를 실행한 결과로 볼 수 있다. JPA는 객체지향적인 관점에서 데이터를 가져오기 위해 연관된 엔티티들을 필요에 따라 추가로 조회하는 것이므로, 이는 JPA의 기능을 잘 수행한 것이다.\n그러나 데이터베이스 입장에서는 N번의 호출로 인해 비효율적인 처리가 발생하였다.\n\nN+1 쿼리를 해결하기 위해 크게 두 가지 방법이 있다.\n\n- member와 team을 join하는 방법.\n- member를 조회할 때 중복을 제거한 team의 id 값들로 batch IN절을 사용해 테이블 각각을 조회 후, 어플리케이션에서 조립하는 방법.\n\nJPA에서는 N+1 쿼리를 해결하기 위해 fetch join, EntityGraph, batch size 조정 등의 방법을 제공하지만, 결국은 위의 두 가지 방법을 사용해야 한다.\n또한, N+1 쿼리는 조회뿐만 아니라 UPDATE, DELETE 쿼리에서도 발생할 수 있다.\n```JAVA\n@Transactional\n@SpringBootTest\nclass JpaTest{\n\t\n\t@Test\n\tvoid Nplus1테스트() {\n\n\t\tfinal var teams = em.createQuery(\"select team from Team team\", Team.class)\n\t\t\t\t.getResultList();\n\n\t\tfor(Team team : teams){\n\t\t  team.setTeamName(\"ABC\");\t\n\t\t}\n\t}\n}\n```\n```SQL\nSELECT * FROM team; /-- (1번 쿼리) --/\nUPDATE team SET team.teamName = 'ABC' WHERE team.id = 1; /-- (N 쿼리) --/\nUPDATE team SET team.teamName = 'ABC' WHERE team.id = 2; /-- (N 쿼리) --/\nUPDATE team SET team.teamName = 'ABC' WHERE team.id = 3; /-- (N 쿼리) --/\n```\n이런 경우에도 쿼리 최적화가 필요하며, 모든 team 을 조회해서 teamName을 'ABC' 로 바꾸기 때문에 아래와 같은 방법으로 해결할 수 있다.\n```SQL\nUPDATE team SET team.teamName = 'ABC'\n```\n특정 team 만 업데이트 하고 싶다면 아래와 같은 방법을 쓸 수 있다.\n```SQL\nUPDATE team SET team.teamName = 'ABC' WHERE team.id (1,2,3);\n```\n\n## 관계형 데이터베이스는 집합이다\n앞에서 본 N+1 쿼리와 그것을 튜닝한 쿼리의 방식에 차이점이 보이는가?\n관계형 데이터 모델은 수학의 집합론을 기반으로 한 데이터베이스 모델로, 관계형 데이터베이스의 데이터 연산은 집합적 연산으로 이루어져 있고 이에 최적화되어 있다.\n(교집합 연산 join, 합집합 연산 union, 부분집합 연산 select 등)    \nN+1 쿼리를 해결하는 방법은 결국 단일 Element에 대한 연산을 여러 개 수행하는 것을 피하고, 대신 집합 연산을 활용하여 효율적으로 처리하는 것이다.\n결과적으로, JPA가 성능상 한계에 부딪힐 수 밖에 없는 이유는 JPA가 엔티티 집합을 다루는 연산에 한계가 있기 때문이라고 볼 수 있다.\n\n물론, JPQL을 사용하면 Native SQL을 사용하는 것 처럼 데이터베이스의 집합연산을 할 수 있다.    \nUPDATE 문의 N+1 쿼리 예제에서 JPQL로 update문을 통해 teamName을 집합적으로 변경하는 로직으로 리팩토링 하면 다음과 같은 형식일 것 이다.\n```java\n/*\nfinal var teams = em.createQuery(\"select team from Team team\", Team.class).getResultList();\n\nfor(Team team : teams){\n  team.setTeamName(\"ABC\");\n} */\nteamRepository.renameAllTeams(\"ABC\"); //renameAllTeams() 는 JPQL로 작성한 집합연산이다.\n```\n성능상의 문제는 해결되었지만, JPA로 객체지향적으로 작성한 원래의 코드가 사라지고,\n데이터베이스 사용에 대한 투명성도 사리지게 되었다. 이는 JPQL을 활용한 최적화된 쿼리가 Native SQL과 거의 동일한 형태로 변환되었기 때문이다.\n또한, 리팩토링된 코드는 JPQL을 네이티브 SQL로 파싱하는 과정만 추가된 것으로, Native SQL에 비해 JPQL이 가지는 장점도 거의 없다.\n\n## 정리\n결국 JPA가 성능적 한계는 집합 연산에 대한 지원이 부족하다는 것으로 요약할 수 있다.\n우리가 어노테이션을 통해 JPA 연관관계에 대한 정보를 정의하지만 이것은 단일 엔티티에 대한 맵핑 정보를 제공하는 것 이다.\n따라서, JPA는 엔티티 집합을 개별 엔티티 각각으로 처리할 수 밖에 없고, 이러한 작업은 집합론을 베이스로 한 관계형 데이터베이스에서\n처리하기에는 느릴 수 밖에 없는 구조가 나오는 것 이다.\n오히려 JPA의 방식은 Key-value 기반 스토리지에 더 적합한 방식이라고 볼 수 있다.   \n이러한 문제점은 객체 패러다임과 관계형 패러다임 간에 쉽게 해결할 수 없는 문제라고 본다.   \n지금 개발하고 있는 서비스는 엔티티의 집합적 연산을 요하는 요구사항이 많아, JPA 기술에 대한 의심이 있었는데   \n이러한 ORM의 한계를 인정하면서 JPA의 객체지향적인 장점과 Native SQL 접근 방식을 균형있게 쓰는 것이 좋을 것 같다.\n\n\n\n\n\n"},{"excerpt":"Redis Keyspace Notifications Redis에는 키 및 값의 변경 사항을 실시간으로 수신할 수 있는 Pub/Sub 기능을 제공한다. Notifications 유형 Redis 데이터 공간에 영향을 미치는 모든 작업에 대해 다음 두 가지 유형의 이벤트가 발생된다.\n예를 들어 키를 삭제하는 명령인  이 실행되면 Redis는 다음 두 가지 명령…","fields":{"slug":"/redis-event-notifications/"},"frontmatter":{"date":"July 19, 2023","title":"Redis Keyspace Notifications에 대해 알아보자","tags":["레디스"]},"rawMarkdownBody":"\n## Redis Keyspace Notifications\nRedis에는 키 및 값의 변경 사항을 실시간으로 수신할 수 있는 Pub/Sub 기능을 제공한다.\n\n\n## Notifications 유형\nRedis 데이터 공간에 영향을 미치는 모든 작업에 대해 다음 두 가지 유형의 이벤트가 발생된다.\n예를 들어 키를 삭제하는 명령인 `del myKey1` 이 실행되면 Redis는 다음 두 가지 명령이 트리거된다.\n```redis\nPUBLISH __keyspace@0__:mykey1 del\nPUBLISH __keyevent@0__:del mykey1\n```\n첫번째 PUBLISH 명령은 Key 중심 이벤트로, `del`이 이벤트의 메시지고\n두번쨰 PUBLISH 명령은 명령 중심 이벤트로, `myKey1`이 이벤트의 메시지이다.\nSub 하는 쪽에서는 Subscribe 패턴 매칭을 통해서 두 가지 유형 중 관심있는 이벤트만 선택해서 알림을 받을 수 있다.\n\n<!-- more -->\n\n## Redis Keyspace Notifications 설정\n기본적으로 Keyspace Notifications은 비활성화되어 있기 때문에, `redis.conf` 또는 `CONFIG SET` 명령어로 `notify-keyspace-events` 옵션을 활성화 할 수 있다.\n옵션에는 다음 값들이 있다.\n이벤트 종류\n- K   Keyspace events, publish prefix \"__keyspace@<db>__:\".\n- E   Keyevent events, publish prefix \"__keyevent@<db>__:\".\n- g   공통 명령: del, expire, rename, ...\n- $   스트링(String) 명령\n- l   리스트(List) 명령\n- s   셋(Set) 명령\n- h   해시(Hash) 명령\n- z   소트 셋(Sorted set) 명령\n- x   만료(Expired) 이벤트 (키가 만료될 때마다 생성되는 이벤트)\n- e   퇴출(Evicted) 이벤트 (최대메모리 정책으로 키가 삭제될 때 생성되는 이벤트)\n- A   모든 이벤트(g$lshzxe), \"AKE\"로 지정하면 모든 이벤트를 받는다.\n\n여기서 K 또는 E는 필수적으로 있어야 하며, 나머지 값들은 선택적으로 설정할 수 있다.\n예를 들어, 어떤 Key가 Expire되는지만 수신하고 싶다면 아래와 같이 설정하면 된다.\n```\nnotify-keyspace-events \"Kx\": 키 이벤트 + 만료 이벤트 발생\n```\n\nRedis 명령에 따른 이벤트 종류를 보고 싶다면 [공식문서](https://redis.io/docs/manual/keyspace-notifications/)를 참조하자.\n\n\n## 성능 측정\nnotify-keyspace-events 옵션을 모두 활성화 했을떄, 비활성화 했을 때 각가 redis-benchmark 를 통해 퍼모먼스를 테스트해보자.\n\n### notify-keyspace-events \"\" 모든 이벤트 비활성화\n```\n# redis-cli config set notify-keyspace-events \"\"\n# redis-benchmark -q \n```\n```\nPING_INLINE: 3670.67 requests per second, p50=12.391 msec\nPING_MBULK: 3668.78 requests per second, p50=12.551 msec\nSET: 4601.72 requests per second, p50=9.087 msec\nGET: 4604.90 requests per second, p50=8.999 msec\nINCR: 4708.98 requests per second, p50=8.847 msec\nLPUSH: 4750.14 requests per second, p50=8.847 msec\nRPUSH: 4620.86 requests per second, p50=8.967 msec\nLPOP: 3531.82 requests per second, p50=13.231 msec\nRPOP: 3863.84 requests per second, p50=12.007 msec\nSADD: 4677.05 requests per second, p50=8.775 msec\nHSET: 4795.01 requests per second, p50=8.743 msec\nSPOP: 3689.49 requests per second, p50=12.087 msec\nZADD: 3968.57 requests per second, p50=10.575 msec\nZPOPMIN: 3116.62 requests per second, p50=15.095 msec\nLPUSH (needed to benchmark LRANGE): 3900.31 requests per second, p50=10.743 msec\nLRANGE_100 (first 100 elements): 4876.86 requests per second, p50=8.343 msec\nLRANGE_300 (first 300 elements): 3725.23 requests per second, p50=12.071 msec\nLRANGE_500 (first 500 elements): 2396.59 requests per second, p50=20.159 msec\nLRANGE_600 (first 600 elements): 2067.31 requests per second, p50=23.663 msec\nMSET (10 keys): 4288.53 requests per second, p50=9.711 msec\n```\n\n### notify-keyspace-events AKE 모든 이벤트 활성화\n```\n# redis-cli config set notify-keyspace-events AKE\n# redis-benchmark -q \n```\n\n```\nPING_INLINE: 3299.57 requests per second, p50=14.319 msec\nPING_MBULK: 3115.85 requests per second, p50=15.039 msec\nSET: 3974.25 requests per second, p50=10.399 msec\nGET: 3828.19 requests per second, p50=10.959 msec\nINCR: 3869.07 requests per second, p50=10.791 msec\nLPUSH: 3835.24 requests per second, p50=11.095 msec\nRPUSH: 4118.96 requests per second, p50=10.247 msec\nLPOP: 3102.89 requests per second, p50=14.991 msec\nRPOP: 3178.03 requests per second, p50=14.895 msec\nSADD: 3834.94 requests per second, p50=10.983 msec\nHSET: 3825.41 requests per second, p50=11.111 msec\nSPOP: 3389.03 requests per second, p50=13.735 msec\nZADD: 3750.94 requests per second, p50=11.207 msec\nZPOPMIN: 3117.69 requests per second, p50=14.855 msec\nLPUSH (needed to benchmark LRANGE): 3835.68 requests per second, p50=11.103 msec\nLRANGE_100 (first 100 elements): 4953.68 requests per second, p50=8.247 msec\nLRANGE_300 (first 300 elements): 3687.04 requests per second, p50=12.079 msec\nLRANGE_500 (first 500 elements): 2410.28 requests per second, p50=20.191 msec\nLRANGE_600 (first 600 elements): 2059.44 requests per second, p50=23.647 msec\nMSET (10 keys): 4043.02 requests per second, p50=10.143 msec\n```\np50 응답시간은 큰 차이가 없지만 초당 request 처리가 100~500 정도 줄어든 것을 볼 수 있다.   \n따라서, 이벤트 수신이 필요없다면 redis의 해당 설정은 비활성화하는 것이 리소스를 효율적으로 쓰는데 도움이 될 것 이다.\n옵션을 활성화하더라도 꼭 필요한 이벤트 유형 옵션만 설정하는 것이 좋다.\n\n\n\n## 스프링 부트 설정\n```java\n@Configuration\npublic class RedisConfig {\n\n\n\t@Bean(name = \"redisMessageTaskExecutor\")\n\tpublic Executor redisMessageTaskExecutor() {\n\t\tThreadPoolTaskExecutor threadPoolTaskExecutor = new ThreadPoolTaskExecutor();\n\t\tthreadPoolTaskExecutor.setCorePoolSize(2); \n\t\tthreadPoolTaskExecutor.setMaxPoolSize(4);\n\t\treturn threadPoolTaskExecutor;\n\t}\n\n\t@Bean\n\tpublic RedisMessageListenerContainer RedisMessageListener(RedisConnectionFactory connectionFactory, RedisMessageListener redisMessageListener) {\n\t\tRedisMessageListenerContainer container = new RedisMessageListenerContainer();\n\t\tcontainer.setConnectionFactory(connectionFactory);\n\t\tcontainer.addMessageListener(redisMessageListener, new PatternTopic(\"*\"));\n\t\tcontainer.setTaskExecutor(asyncThreadTaskExecutor());\n\t\treturn container;\n\t}\n\n\t@Bean\n\tpublic RedisTemplate<String, Object> redisTemplate(RedisConnectionFactory connectionFactory) {\n\t\tRedisTemplate<String, Object> redisTemplate = new RedisTemplate<>();\n\t\tredisTemplate.setConnectionFactory(connectionFactory);\n\t\tredisTemplate.setKeySerializer(new StringRedisSerializer());\n\t\tredisTemplate.setValueSerializer(new StringRedisSerializer());\n\t\treturn redisTemplate;\n\t}\n}\n```\n```java\n@Component\npublic class RedisMessageListener implements MessageListener {\n\n    private final List<CacheManager> cacheManagerList;\n\n    @Override\n    public void onMessage(final Message message, final byte[] pattern) {\n        log.info(\"{}\", message);\n    }\n}\n```\n\nRedisMessageListenerContainer 빈 등록 시, 주의할 점은 setTaskExecutor() 로 스레드풀을 사용하는 Executor를 등록해야 한다.   \nsetTaskExecutor()로 Executor를 등록하지 않으면 RedisMessageListenerContainer는 기본값으로 SimpleAsyncTaskExecutor가 사용되는데,\nSimpleAsyncTaskExecutor 는 사용될 때 마다, 새로운 스레드를 만들어서 run() 하기 때문에 Redis에서 이벤트가 수신될 때 마다 새로운 스레드가 만들어지므로 주의하자.\n"},{"excerpt":"메모리 계층 구조 메모리를 필요에 따라 여러 가지 종류로 나누어 둠을 의미한다. 이떄 필요한 대부분의 경우는 CPU가 메모리에 더 빨리 접근하기 위함이다. 자주 쓰는 데이터는 계속 자주 쓰인다. 자주 쓰이는 데이터는 계속 자주 쓰이고, 자주 쓰이지 않는 데이터는 계속 자주 쓰이지 않는다. 자주 쓰이으는 데이터는 전체 데이터 양에 비해 작은 양이기 때문에,…","fields":{"slug":"/spring-cache-hierarchy/"},"frontmatter":{"date":"July 16, 2023","title":"Spring Cache 로 캐시 계층 구조 사용하기","tags":["스프링"]},"rawMarkdownBody":"\n\n## 메모리 계층 구조\n- 메모리를 필요에 따라 여러 가지 종류로 나누어 둠을 의미한다.\n- 이떄 필요한 대부분의 경우는 CPU가 메모리에 더 빨리 접근하기 위함이다.\n\n## 자주 쓰는 데이터는 계속 자주 쓰인다.\n- 자주 쓰이는 데이터는 계속 자주 쓰이고, 자주 쓰이지 않는 데이터는 계속 자주 쓰이지 않는다.\n- 자주 쓰이으는 데이터는 전체 데이터 양에 비해 작은 양이기 때문에, 캐시는 메모리보다 더 작아도 된다.\n- 컴퓨터 과학에서 증명된 법칙이며, 지역성의 원리라고도 한다.\n<!-- more -->\n\n![img.png](spring-cache-hierachy/img.png)\n\n\n## Spring Cache로 캐시 계층 구조 사용하기\nSpring에서는 Cache 추상화를 통해 다양한 캐시 솔루션을 일관성있게 사용할 수 있게 한다.   \n트랜잭션과 마찬가지로, AOP를 이용해 특정 캐시 기술에 종송되지 않고 캐시 기능을 투명하게 적용할 수 있다.\n\n### CacheManager 구현체\n스프링에서 제공하는 CacheManager 구현체는 아래와 같다.   \n- CaffeineCacheManager\n- CompositeCacheManager\n- ConcurrentMapCacheManager\n- JCacheCacheManager\n- NoOpCacheManager\n- SimpleCacheManager\n\n\n### 의존성 추가\n```shell\nimplementation 'org.springframework.boot:spring-boot-starter-cache'\n```\n\n\n### @EnableCaching 추가\nSpringBoot 에서 Cache 추상화를 사용하기 위해 해당 어노테이션을 추가한다.\n```java\n@EnableCaching\n@SpringBootApplication\npublic class SpringCacheHierarchyApplication {\n\n\tpublic static void main(String[] args) {\n\n\t\tSpringApplication.run(SpringCacheHierarchyApplication.class, args);\n\t}\n\n}\n```\n\n### L1, L2 Cache 추가\n여기서는 캐시 계층 구조가 제대로 동작하기 위해 메모리 기반의 `SimpleCacheManager` 를 확장하여 사용한다.\n메모리 캐시에서 데이터가 get이나 put 될 때, 로그를 남기도록 설정하였다.   \n`ConcurrentMapCache` 캐쉬는 내부적으로 `ConcurrentMap` 을 사용하여 캐시를 관리하는데 `ConcurrentMap` 의 capacity를 고정하기 어려워\nput 할 때 마다, `clear()` 메서드를 호출하였다. capacity가 1이고 FIFO 방식으로 교체하는 캐시라고 생각하면 편하다.\n\n```JAVA\n\n@Slf4j\npublic class L1Cache extends ConcurrentMapCache {\n\n\n\t@Override protected Object lookup(final Object key) {\n\t\tlog.info(\"L1 cache lookup key = {}\", key);\n\t\treturn super.lookup(key);\n\t}\n\t\n\t@Override public void put(final Object key, final Object value) {\n\t\tsuper.clear();\n\t\tlog.info(\"L1 cache put = key:{}, value:{}\", key, value);\n\t\tsuper.put(key, value);\n\t}\n\t\n}\n```\n\n\n```java\npackage com.example.springcachehierarchy.cache;\n\nimport java.util.concurrent.Callable;\nimport java.util.concurrent.ConcurrentMap;\nimport lombok.extern.slf4j.Slf4j;\nimport org.springframework.cache.concurrent.ConcurrentMapCache;\nimport org.springframework.core.serializer.support.SerializationDelegate;\n\n@Slf4j\npublic class L2Cache extends ConcurrentMapCache {\n\n\n\t@Override protected Object lookup(final Object key) {\n\t\tlog.info(\"L2 cache lookup key = {}\", key);\n\t\treturn super.lookup(key);\n\t}\n\t\n\t@Override public void put(final Object key, final Object value) {\n\t\tlog.info(\"L2 cache put = key:{}, value:{}\", key, value);\n\t\tsuper.put(key, value);\n\t}\n}\n```\n\n### L1, L2 Cache Bean 등록\n위에서 만든 L1, L2 Cache 를 `SimpleCacheManager`의 구현체로 @Bean 으로 등록한다.\n\n```java\n@Configuration\npublic class CacheConfig {\n\t\n\t@Primary\n\t@Bean(\"l1CacheManager\")\n\tpublic CacheManager l1CacheManager() {\n\t\tfinal var simpleCacheManager = new SimpleCacheManager();\n\t\tsimpleCacheManager.setCaches(List.of(new L1Cache(\"Cache\")));\n\t\treturn simpleCacheManager;\n\t}\n\n\n\t@Bean(\"l2CacheManager\")\n\tpublic CacheManager l2CacheManager() {\n\t\tfinal var simpleCacheManager = new SimpleCacheManager();\n\t\tsimpleCacheManager.setCaches(List.of(new L2Cache(\"Cache\")));\n\t\treturn simpleCacheManager;\n\t}\n}\n\n```\n\n### CacheService\n\n```JAVA\n@Slf4j\n@Service\npublic class CacheService {\n\n\t@Caching(cacheable =\n        {\n            @Cacheable(cacheManager = \"l1CacheManager\", cacheNames = \"L1Cache\"),\n            @Cacheable(cacheManager = \"l2CacheManager\", cacheNames = \"L2Cache\")\n        }\n\n\t)\n\tpublic String findById(String id) {\n\t\tlog.info(\"findById = {}\", id);\n\t\treturn id;\n\t}\n\t\n}\n```\n\n`@Caching` 어노테이션의 `cacheable` 필드는 `@Cacheable` 어노테이션의 배열을 인자로 받는다.   \n첫번째 `@Cacheable` 어노테이션의 `cacheManager` 는 `l1CacheManager` 로 설정하고   \n두번쨰 `@Cacheable` 어노테이션읜 `cacheManager` 는 `l2CacheManager` 로 설정한다.   \n내가 기대하는 것은 `l1CacheManager` 에 key 값에 캐시가 없다면 `l2CacheManager` 로 값을 탐색하고,   \n`l2CacheManager` 도 없다면 `findById` 메서드가 호출되는 것이다. 테스트 코드로 검증을 해보자.\n\n\n### CacheService 캐시 계층 구조 테스트\n테스트 코드를 짜고, 로그를 통해 동작을 확인해보자.\n```java\n@Slf4j\n@SpringBootTest\nclass CacheServiceTest {\n\n\t@Autowired CacheService cacheService;\n\n\t@Test\n\tvoid CacheService_캐시_동작_테스트(){\n\n\t\tfinal var value1 = cacheService.findById(\"a\");\n\t\tlog.info(\"value1 return\");\n\n\t\tfinal var value2 = cacheService.findById(\"a\");\n\t\tlog.info(\"value2 return\");\n\n\t\tfinal var value3 = cacheService.findById(\"b\");\n\t\tlog.info(\"value3 return\");\n\n\t\tfinal var value4 = cacheService.findById(\"b\");\n\t\tlog.info(\"value4 return\");\n\n\t\tfinal var value5 = cacheService.findById(\"a\");\n\t\tlog.info(\"value5 return\");\n\t}\n\n}\n```\n![img.png](spring-cache-hierachy/log.png)\n1. `findById (id:a)` 호출 시, L1, L2 캐시 모두 Cache Miss 로 서비스 메서드가 호출되었다. 메서드가 호출되고 L1, L2 캐시 모두 호출 결과가 캐싱되었다.\n2. `findById (id:a)` 호출 시, L1 캐시에 id:a 이 있으므로, Cache Hit 되었다.\n3. `findById (id:b)` 호출 시, id:2가 L1, L2 캐시에 없으므로 서비스 메서드가 호출되었다. 결과가 캐싱되고, L1 캐시는 capacity가 1이므로 id:b 가 캐싱되어 있을 것이다.\n4. `findById (id:b)` 호출 시, L1 캐시에 id:b 이 있으므로, Cache Hit 되었다.\n5. `findById (id:a)` 호출 시, L1 캐시에서 Cache Miss로 L2 캐시에서 Cache Hit 되었다.\n\n로그를 통해 내가 의도한대로 동작되는 것을 확인할 수 있다. \n\n\n## Local Cache 와 Redis로 L1, L2 캐시 계층 구성하기\nL1 계층의 캐시는 SimpleCacheManager 그대로 사용하고, L2 계층의 캐시를 Redis로 마이그레이션 한다.\n서버 인스턴스가 여러대 인 경우, L1 계층인 로컬 캐시와 L2 계층의 Redis 캐시가 일관성이 꺠질 수 있으므로 \nRedis pub/sub을 사용하여 로컬 캐시와 Redis 캐시의 일관성을 유지하도록 한다.\n\n\n### Redis 설정\n```JAVA\n@Configuration\npublic class RedisConfig {\n\n\t@Bean\n\tpublic RedisMessageListenerContainer RedisMessageListener(RedisConnectionFactory connectionFactory) {\n\t\tRedisMessageListenerContainer container = new RedisMessageListenerContainer();\n\t\tcontainer.setConnectionFactory(connectionFactory);\n\t\tcontainer.addMessageListener(redisMessageListener, new ChannelTopic(\"Cache\"));\n\t\treturn container;\n\t}\n\t\n\t@Bean\n\tpublic RedisTemplate<String, Object> redisTemplate(RedisConnectionFactory connectionFactory) {\n\t\tRedisTemplate<String, Object> redisTemplate = new RedisTemplate<>();\n\t\tredisTemplate.setConnectionFactory(connectionFactory);\n\t\tredisTemplate.setKeySerializer(new StringRedisSerializer());\n\t\tredisTemplate.setValueSerializer(new StringRedisSerializer());\n\t\treturn redisTemplate;\n\t}\n}\n```\n\n### Redis MessageListener 설정\n```JAVA\n@Slf4j\n@Service\n@RequiredArgsConstructor\npublic class RedisMessageListener implements MessageListener {\n\n\tprivate final List<CacheManager> cacheManagerList;\n\n\t@Override public void onMessage(final Message message, final byte[] pattern) {\n\t\tfinal var evictKey = new String(message.getBody(), StandardCharsets.UTF_8);\n\n\t\tfor (final CacheManager cacheManager : cacheManagerList) {\n\t\t\tcacheManager.getCache(\"Cache\").evict(evictKey);\n\t\t}\n\t}\n}\n```\n\n### Redis CacheManager 설정\n```JAVA\n\n@Configuration\n@RequiredArgsConstructor\npublic class CacheConfig {\n\n\tprivate final RedisConnectionFactory connectionFactory;\n\t\n\t// l2RedisCacheManager bean 추가\n\t@Bean(\"l2RedisCacheManager\")\n\tpublic CacheManager redisCacheManager() {\n\t\tRedisCacheConfiguration redisCacheConfiguration = RedisCacheConfiguration.defaultCacheConfig()\n\t\t\t\t.serializeKeysWith(RedisSerializationContext.SerializationPair.fromSerializer(new StringRedisSerializer()))\n\t\t\t\t.serializeValuesWith(RedisSerializationContext.SerializationPair.fromSerializer(new StringRedisSerializer()));\n\n\t\treturn RedisCacheManager.RedisCacheManagerBuilder\n\t\t\t\t.fromConnectionFactory(connectionFactory)\n\t\t\t\t.cacheDefaults(redisCacheConfiguration)\n\t\t\t\t.build();\n\t}\n}\n\n```\n\n### CacheService @Cacheable 설정변경\n```java\n@Slf4j\n@Service\npublic class CacheService {\n\n\t@Caching(cacheable =\n      {\n            @Cacheable(cacheManager = \"l1CacheManager\", cacheNames = \"Cache\"),\n            @Cacheable(cacheManager = \"l2RedisCacheManager\", cacheNames = \"Cache\")\n      }\n\t)\n\tpublic String findById(String id) {\n\t\tlog.info(\"findById = {}\", id);\n\t\treturn id;\n\t}\n\n}\n```\n\n위의 코드를 추가한 후, 첫번쨰 테스트 코드를 다시 돌려보자.\nredis에 접속해서 `keys *` 명령어로 확인해보면 `Cache::a`, `Cache::b` 키값이 잘 들어가 있는 것을 볼 수 있다.\n\nRedis Pub/Sub 으로 캐시값이 evict되면 로컬캐시와 redis캐시에 잘 반영되는지 테스트 코드로 검증해보자\n\n```JAVA\n@Slf4j\n@SpringBootTest\nclass CacheServiceTest {\n\n\t@Autowired List<CacheManager> cacheManagerList;\n\t@Autowired RedisTemplate<String, Object> redisTemplate;\n\n\t@Test\n\t@DisplayName(\"Reids Topic에 subscribe이 발생하면 해당 키가 l1, l2 캐시에서 evict 된다\")\n\tvoid redis_pub_sub_cache_evict_테스트() throws InterruptedException {\n\n\t\t// given\n\t\tvar topic = \"Cache\";\n\t\tvar key = \"key1\";\n\t\tvar value = \"value1\";\n\n\t\tfor (final CacheManager cacheManager : cacheManagerList) {\n\t\t\tcacheManager.getCache(topic).put(key, value);\n\t\t\tAssertions.assertEquals(value, cacheManager.getCache(topic).get(key).get());\n\t\t}\n\n\t\t// when\n\t\tredisTemplate.convertAndSend(topic, key);\n\t\tThread.sleep(1000L); // 캐시 무효화 메시지가 subscribe 될때까지 기다린다\n\n\t\t// then\n\t\tfor (final CacheManager cacheManager : cacheManagerList) {\n\t\t\tAssertions.assertNull(cacheManager.getCache(topic).get(key));\n\t\t}\n\n\t}\n}\n```\n\n\n### 정리\n여기서는 2차 캐시인 redis에 데이터가 변경된다면 redis pub/sub을 key 값을 이용해서 변경된 데이터를 무효화하였다.\n필요에 따라 pub/sub 시 key,value를 한 메시지에 담아서 보내서 캐시가 새 값으로 교체되는 정책을 적용할 수 도 있다.   \nRedis에 대량의 데이터가 적재되어 로컬 캐시에 모두 담을 수 없는 경우 또는 서버 인스턴스 메모리를 세심하게 관리해야 되는 경우\nEhcache 같은 캐시 라이브러리와 Redis를 함께 사용해서 낮은 레이턴시를 유지하면서도 메모리 관리도 효율적으로 할 수 있을 것 이다.\n다만, 캐시 값이 변경되면 캐시 일관성을 위해 각 계층에 동기화하는 오버헤드가 발생하므로, 자주 변하지 않는 데이터로 캐시 계층을 구성해야 한다.\n"},{"excerpt":"복잡한 Service 계층 Service 계층은 애플리케이션의 핵심 비즈니스 로직을 수행하는 중심적인 역할을 한다.\n이 계층은 데이터 유효성 검증, 복잡한 계산 로직, 데이터베이스 CRUD 연산, 외부 API 통신, 그리고 트랜잭션 관리까지 다양한 책임을 지니고 있다.\n실무에서 코드를 파악할 일이나 유지보수할 일이 생기면 가장 먼저 찾고 코드를 보는데 많…","fields":{"slug":"/java-collection-wrapper/"},"frontmatter":{"date":"June 23, 2023","title":"Collection Wrapper 클래스를 이용한 Service 계층 리팩토링 ","tags":["스프링"]},"rawMarkdownBody":"\n## 복잡한 Service 계층\n\nService 계층은 애플리케이션의 핵심 비즈니스 로직을 수행하는 중심적인 역할을 한다.\n이 계층은 데이터 유효성 검증, 복잡한 계산 로직, 데이터베이스 CRUD 연산, 외부 API 통신, 그리고 트랜잭션 관리까지 다양한 책임을 지니고 있다.\n실무에서 코드를 파악할 일이나 유지보수할 일이 생기면 가장 먼저 찾고 코드를 보는데 많은 시간을 할애하는 부분이 서비스 계층이기도 하다.\n\nService 계층은 애플리케이션의 비즈니스 로직을 수행하는 곳이기 때문에, 여기에 구현 코드가 위치하는 것은 자연스럽다.\n다만, 비지니스 로직이 매우 복잡하고 하나의 Service에서 많은 유스케이스를 처리하게 되면 유지보수가 어려워진다.\n실제로 복잡한 시스템은 Service 로직 하나가 몇 1000줄씩 필요한 경우도 있다.\n\n비즈니스 로직의 실행에 필요한 절차적 논리와 연산은 프로그래밍 패러다임(절차적, 객체지향 등)에 관계없이 동일하다.\n그러나 이러한 로직을 유지보수 가능한 형태로 구성하기 위해서는 객체지향적 설계 원칙을 적용하는 것이 효과적이다.\n\n이 글에서는 Collection Wrapper 클래스를 활용하여 절차적으로 구성된 Service 계층의 코드를 객체지향적으로 리팩토링하는 방법을 소개하려고 한다.\nCollection Wrapper 클래스는 컬렉션에 대한 연산을 캡슐화하여 코드의 가독성과 유지보수성을 향상시킬 수 있다.\n\n## 절차적인 구현과 객체지향적 구현의 비교\n\n```java\n@Getter\n@Entity\npublic class Product {\n\n\t@Id @GeneratedValue(strategy = GenerationType.IDENTITY)\n\tprivate Long id;\n\n\tprivate Integer price;\n\n}\n```\n\n```java\npublic interface ProductJpaRepository extends JpaRepository<Product, Long> {\n\n}\n```\n\n```java\n@Service\npublic class ProductService {\n\n\tprivate final ProductJpaRepository productJpaRepository;\n\n\tpublic Integer getTotalPrice() {\n\n\t\t// 여기에 우리의 핵심 비지니스 로직인 상품 가격의 합계 계산 로직을 구현한다.\n\t}\n}\n\n```\n\n### 전통적인 절차적인 구현\n\n```java\n@Service\npublic class ProductService {\n\n\tpublic Integer getTotalPrice() {\n\n\t\tfinal List<Product> products = productJpaRepository.findAll();\n\n\t\tInteger totalPrice = 0;\n\t\tfor (Product product : Products) {\n\t\t\ttotalPrice += product.getPrice();\n\t\t}\n\n\t\treturn price;\n\t}\n}\n```\n\nDB로부터 상품을 조회해온 뒤, 컬렉션 원소를 돌면서 `totalPrice` 라는 로컬 변수에 상품 가격의 합계금액을 누적한다.\n\n### Stream API를 이용한 함수형 프로그래밍 구현\n\n```java\n@Service\npublic class ProductService {\n\n\tpublic Integer getTotalPrice() {\n\t\tfinal List<Product> products = productJpaRepository.findAll();\n\n\t\treturn products.stream()                  // (1)\n\t\t\t\t.map(Product::getPrice)          // (2)\n\t\t\t\t.reduce(0, Intger::sum);         // (3)\n\t}\n}\n```\n\n- 함수형 프로그래밍 스타일로 구현하였지만, 여전히 코드에서 합계금액을 계산하기 위한 절차를 기술하고 있다.\n    - **(1)** List<Product> products 를 Stream 으로 반환한다. `(레코드를 건건히 처리할 것이다)`\n    - **(2)** Product 타입을 getPrice() 로 Integer 타입으로 변환한다.\n    - **(3)** Integer로 변환된 값을 0부터 누적시켜 합을 구한다.\n\n### 객체지향적인 구현\n\n```java\n@Service\npublic class ProductService {\n\n\tpublic Integer getTotalPrice() {\n\t\tfinal Products products = productJpaRepository.findAll();\n\n\t\treturn products.getTotalPrice();\n\t}\n}\n```\n\n- Products 라는 List<Product> 의 Wrapper 클래스를 만들었다.\n- 서비스 계층에서는 Products 라는 Collection Wrapper 클래스에게 상품의 합계금액을 계산하라는 메시지를 보낸다.\n- 서비그 계층에서는 세부 구현 코드를 숨기고 구현의 대한 추상화를 제공한다.\n\n### Collection Wrapper 클래스 구현\n\n```java\n@RequiredArgsConstructor\npublic class Products implements Iterable<Product> {\n\n\tprivate final Stream<Product> stream;\n\n\t@Override public Iterator<Product> iterator() {\n\t\treturn stream.iterator();\n\t}\n\n\tpublic Integer getTotalPrice() {\n\t\treturn stream\n\t\t\t\t.map(Product::getPrice)\n\t\t\t\t.reduce(0, Integer::sum);\n\t}\n}\n\n```\n\n- `Iterable<Product>` 인터페이스를 구현한 Products 클래스를 정의한다.\n- `Iterable` 은 컬렉션의 구현 방법을 노출시키지 않고, 컬렉션 요소들을 접근할 수 있게 하는 패턴,인터페이스다.\n- `Iterable` 인터페이스를 구현하면 `for-each` 문 사용이 가능해지고, `Iterable` 를 통해 Products 래퍼클래스의 요소들을 순회할 수 있게 하였다.\n\n## 실전 예제로 보는 리팩토링\n\n실무에서 자주 사용되는 upsert 로직을 구현한다고 가정해보자.\n먼저 UserDto 객체를 입력으로 받는다.\n이 입력된 UserDto는 User 엔티티의 ID 값으로 변환된다.\n이 변환된 ID 값을 사용하여 데이터베이스에 조회한다.\n만약 조회 결과 해당 ID를 가진 User 엔티티가 데이터베이스에 없다면 새로운 User를 생성한다.\n반대로 이미 해당 ID를 가진 User 엔티티가 데이터베이스에 존재한다면, 이 엔티티를 업데이트한다.\n\n### 절자적으로 구현된 upsert \n\n```JAVA\n@Service\npublic class UserService {\n\n\t@Autowired\n\tprivate UserRepository userRepository;\n\n\tpublic void upsertUsers(List<UserDto> userDtos) {\n\t\tList<Long> userIds = userDtos.stream()\n\t\t\t\t.map(UserDto::getId)\n\t\t\t\t.collect(Collectors.toList());\n\n\t\tList<User> existingUsers = userRepository.findAllById(userIds);\n\n\t\tMap<Long, User> existingUserMap = existingUsers.stream()\n\t\t\t\t.collect(Collectors.toMap(User::getId, Function.identity()));\n\n\t\tList<User> usersToSave = new ArrayList<>();\n\n\t\tfor (UserDto dto : userDtos) {\n\t\t\tUser user = existingUserMap.get(dto.getId());\n\t\t\tif (user != null) {\n\t\t\t\tuser.updateFromDto(dto);\n\t\t\t} else {\n\t\t\t\tuser = new User(dto);\n\t\t\t}\n\t\t\tusersToSave.add(user);\n\t\t}\n\n\t\tuserRepository.saveAll(usersToSave);\n\t}\n}\n```\n\nService 계층에서는 UserDto를 입력받아, 해당 데이터가 데이터베이스에 이미 존재하면 업데이트하고, 그렇지 않으면 새로 삽입하는 \"upsert\" 로직이 구현되어 있다.\n이러한 접근 방식은 코드의 복잡성을 증가시키며, 특히 Service 계층의 코드가 수천 줄에 이르면 이해와 유지보수가 어려워진다.\n\n또한, Map<Long, User> existingUserMap과 같은 구체적인 자료구조를 private 메서드에 인자로 전달하는 경우가 많다.\n이렇게 되면, Long 타입의 키가 어떤 의미를 가지는지를 코드를 읽는 동안 인지하고 있어야 한다.\n이는 코드의 가독성을 저하시키고, 이해하는 데에 추가적인 노력이 필요하게 된다.\n\n### 개선 후 upsert\n\n```JAVA\npublic class UserCollection {\n\n\tprivate final List<User> users;\n\n\tpublic UserCollection(List<User> users) {\n\t\tthis.users = users;\n\t}\n\n\tpublic UpsertResult upsertFromDtos(List<UserDto> dtos) {\n\t\tMap<Long, User> userMap = users.stream()\n\t\t\t\t.collect(Collectors.toMap(User::getId, Function.identity()));\n\n      List<User> updatedUsers = new ArrayList<>();\n      List<User> insertedUsers = new ArrayList<>();\n\t\t\t\n\t\tfor (UserDto dto : dtos) {\n\t\t\tUser user = userMap.get(dto.getId());\n\t\t\tif (user != null) {\n\t\t\t\tuser.updateFromDto(dto);\n                updatedUsers.add(user);\n\t\t\t} else {\n\t\t\t\tuser = new User(dto);\n                insertedUsers.add(user);\n\t\t\t}\n\t\t}\n\t\treturn new UpsertResult(updatedUsers, insertedUsers);\n\t}\n}\n\npublic class UpsertResult {\n\n\tpublic final List<User> updatedUsers;\n\tpublic final List<User> insertedUsers;\n\n\tpublic UpsertResult(List<User> updatedUsers, List<User> insertedUsers) {\n\t\tthis.updatedUsers = updatedUsers;\n\t\tthis.insertedUsers = insertedUsers;\n\t}\n}\n\n\n@Service\npublic class UserService {\n\n\t@Autowired\n\tprivate UserRepository userRepository;\n\n\tpublic void upsertUsers(List<UserDto> userDtos) {\n\t\tList<User> existingUsers = userRepository.findAllById(\n\t\t\t\tuserDtos.stream()\n\t\t\t\t\t\t.map(UserDto::getId)\n\t\t\t\t\t\t.collect(Collectors.toList())\n\t\t);\n\n\t\tUserCollection userCollection = new UserCollection(existingUsers);\n\t\tUpsertResult result = userCollection.upsertFromDtos(userDtos);\n\n\t\tuserRepository.saveAll(result.updatedUsers);\n\t\tuserRepository.saveAll(result.insertedUsers);\n\t}\n}\n```\n\n리팩토링 후의 코드에서는 UserDto를 데이터베이스에 업데이트할지, 새로 삽입할지 결정하는 로직이 UserCollection 클래스로 이동되었다.\n이로 인해 UserService는 이제 UserCollection에 구체적인 작업을 위임하고, 그 결과만을 데이터베이스에 반영하게 된다.\n추가적으로, 'upsert' 로직에 다른 연산이 필요한 경우에도 UserCollection을 파라미터로 전달하는 방식을 사용할 수 있다.\n이렇게 하면, 구체적인 자료구조 대신 추상화된 UserCollection을 사용하여 더 높은 수준의 추상화와 캡슐화를 달성할 수 있게 된다.\n\n## Spring Data JPA 와의 연동\n\nSpring Data JPA 에서 위와 같은 패턴을 구현하려면 Spring Data JPA에 메서드 이름의 키워드를 보고 자동으로 쿼리 메서드를 만들어주는 Query Method 기능과 연동되어야 한다.\n다행히 Spring Data JPA 에는 Query Method 에서는 여러 반환값을 지원하고 있으며, Streamable 인터페이스를 구현한 클래스를 반환값으로 받을 수 있다.\n\n```java\nimport org.springframework.data.util.Streamable;\n\npublic class Products implements Streamable<Product> {\n\n\tprivate final Streamable<Product> streamable;\n\n\t@Override\n\tpublic Iterator<Product> iterator() {\n\t\treturn streamable.iterator();\n\t}\n\n\n}\n\ninterface ProductJpaRepository implements JpaRepository<Product, Long> {\n\n\tProducts findByPriceGreaterThan(Integer price);\n}\n```\n\n`ProductJpaRepository` 에 반환값이 Streamable 인터페이스를 구현한 `ProductsSCO` 래퍼 클래스 인 것을 볼 수 있다.\n다만, `List<T> findAll()` 과 같은 메서드들은 이미 `JpaRepository`에서 정의되기 때문에 `Products findAll()` 과 같은 형태로 재정의 할 수 없다.\n\n## 참조\n\n[Spring Data JPA - Reference Documentation](https://docs.spring.io/spring-data/jpa/docs/current/reference/html/#repositories.collections-and-iterables.streamable-wrapper)"},{"excerpt":"1. 개요 일반적으로 Spring 환경에서 Amazon SQS 라이브러리로  모듈을 사용합니다.  을 분석하고, 단점을 보완한 모듈을 설계하는 것을 목표로 합니다. 2. Spring Cloud AWS Messaging 모듈  모듈을 사용하면 를 추상화한 API를 사용해 쉽게 와 를 구현할 수 있습니다. 아래와 같이 간단한 설정만으로 Consumer의 경우…","fields":{"slug":"/Spring Cloud AWS Messaging Module Best Practice/"},"frontmatter":{"date":"June 20, 2023","title":"Spring Cloud AWS Messaging 모듈 문제점 및 튜닝","tags":["AWS"]},"rawMarkdownBody":"\n# **1. 개요**\n\n- 일반적으로 Spring 환경에서 Amazon SQS 라이브러리로 `spring-cloud-aws-messaging` 모듈을 사용합니다.\n- `spring-cloud-aws-messaging` 을 분석하고, 단점을 보완한 모듈을 설계하는 것을 목표로 합니다.\n\n<!-- more -->\n# **2. Spring Cloud AWS Messaging 모듈**\n\n- `spring-cloud-aws-messaging` 모듈을 사용하면 `Amazon SQS SDK`를 추상화한 API를 사용해 쉽게 `Producer`와 `Consumer`를 구현할 수 있습니다.\n- 아래와 같이 간단한 설정만으로 Consumer의 경우 Polling Thread Pool을 자동으로 만들어주고, `@SqsListener` 어노테이션을 통해 특정 큐를 구독하여 메시지를 처리할 수 있습니다.\n\n```groovy\n# build.gradle\ndependencies {\n    implementation 'org.springframework.cloud:spring-cloud-aws-autoconfigure:2.2.1.RELEASE'\n    implementation 'org.springframework.cloud:spring-cloud-aws-messaging:2.2.1.RELEASE'\n}\n```\n\n```java\n@Configuration\n@RequiredArgsConstructor\npublic class SqsConfig {\n\n\tprivate final AWSCredentialsProvider awsCredentialsProvider;\n\n\t@Value(\"${cloud.aws.region.static}\")\n\tprivate String region;\n\n\t@Bean\n\t@Primary\n\tpublic AmazonSQSAsync amazonSQSAsync() {\n\t\treturn AmazonSQSAsyncClientBuilder.standard().withCredentials(awsCredentialsProvider)\n\t\t\t\t.withRegion(region)\n\t\t\t\t.build();\n\t}\n\n}\n```\n\n```java\n/**\n* Consumer 설정 클래스\n*/\n@Configration\n@RequiredArgsConstructor\npublic class SqsConsumeConfig {\n\n\tprivate final AmazonSQSAsync amazonSQSAsync;\n\n    /**\n    *  Consumer 에서 SQS Queue로 폴링하는 컨테이너를 설정합니다.\n    **/\n\t@Bean\n\tpublic SimpleMessageListenerContainerFactory simpleMessageListenerContainerFactory() {\n\t\tfinal SimpleMessageListenerContainerFactory factory = new SimpleMessageListenerContainerFactory();\n\t\tfactory.setAmazonSqs(amazonSQSAsync);\n        factory.setMaxNumberOfMessages(10);\n        factory.setWaitTimeOut(10);\n        factory.setBackOffTime(Long.valueOf(60000));\n\t\treturn factory;\n\t}\n\n}\n```\n\nSQS 큐를 Polling 하는 핵심 매커니즘을 `SimpleMessageListenerContainer`를 정의할 수 있습니다.\n\n- **WaitTimeOut** :- 현재 대기열에 메시지가 없는 경우 폴링 요청이 새 메시지가 도착할 때까지 기다리는 대기 시간 제한을 구성합니다. 값이 높을수록 시스템에 대한 폴링 요청이 크게 줄어듭니다.\n- **MaxNumberOfMessage :** Amazon SQS 시스템에 대한 한 번의 폴링 중에 검색해야 하는 최대 메시지 수를 구성합니다. 최대 메시지 수(1–10)\n- **BackOffTime:-** 폴링 스레드가 오류 발생 시 복구를 시도하기 전에 대기해야 하는 밀리초 수입니다. 이렇게 하면 작업자가 용량을 초과하는 요청에 압도당하는 것을 방지할 수 있습니다.\n\n```java\n\n@Component\npublic class SqsMessageListener {\n\n    /**\n    * 폴링 스레드에서 핸들링한 메시지가 @SqsListener 로 넘어옵니다.\n    **/\n\t@SqsListener(value = \"QueueName\", deletionPolicy = SqsMessageDeletionPolicy.NEVER)\n\tpublic void handle(@Payload ApplicationEventMessage message, MessageHeaders messageHeaders, Acknowledgment acknowledgment) {\n        log.info(\" received Message from SQS queue\");\n\t}\n\n}\n\n```\n\n```java\n/**\n* Producer 설정 클래스\n*/\n@Configuration\n@RequiredArgsConstructor\npublic class SqsPublishConfig {\n\n\tprivate final AmazonSQSAsync amazonSQSAsync;\n\tprivate final ObjectMapper objectMapper;\n\n\t@Bean\n\tpublic QueueMessagingTemplate queueMessagingTemplate() {\n\t\treturn new QueueMessagingTemplate(amazonSQSAsync);\n\t}\n\n\t@Bean\n\tpublic StringHttpMessageConverter stringHttpMessageConverter() {\n\t\treturn new StringHttpMessageConverter(StandardCharsets.UTF_8);\n\t}\n}\n\n```\n\n```java\n@Service\npublic class FooService {\n\n  private final QueueMessagingTemplate queueMessagingTemplate;\n\n  public void publih(String message){\n    queueMessageTemplate(\"queueName\", message);\n  }\n\n}\n```\n\n## **1. SimpleMessageListenerContainer**\n\n- `spring-cloud-aws-messaging` 모듈을 사용하면 `SimpleMessageListenerContainer` 라는 클래스가 SQS 큐에서 메시지를 폴링하여 `@SqsHandler` 에게 넘깁니다.\n- `SimpleMessageListenerContainer` 는 Polling 을 위한 스레드풀을 별도로 생성하여 동작합니다.\n- Polling 스레드풀의 스레드 갯수는 아래 공식으로 결정됩니다.\n    - **등록된 큐의 개수 * ( 폴링 시 한번에 받을 수 있는 최대 메시지 수 + 1)**\n        - ex) 등록된 큐의 개수가 1개이고, 폴링 시 한번에 받을 수 있는 최대 메시지 수가 10개이면 `1 * (10 + 1) = 11개`의 폴링 스레드가 생성됩니다.\n\n![Untitled](sqs_best_practice/Untitled.png)\n\n## **2. SimpleMessageListenerContainer 의 문제**\n\n![Untitled](sqs_best_practice/Untitled_1.png)\n\n- `SimpleMessageListnerContainer` 가 동작되는 방식은 아래 코드를 보면 알 수 있습니다.\n- 1번 : `AmazonSQS Client`를 통해 큐로 `Polling Request`를 전송하여 메시지를 응답 받습니다.\n- 2번 : 응답받은 메시지 수 만큼 `CountDownLatch` 객체를 생성합니다.\n- 3번 : 응답받은 각 메시지를 For문으로 돌면서 할당받은 스레드풀에 작업을 등록합니다.\n    - 스레드풀에 전달하는 `SignalExecutingRunnable`객체는 각 메시지가 처리되면 `CountDownLatch` 값을 Down 시킵니다.\n- 5번 : `CountDownLatch` 가 0이 될때 까지 대기합니다.\n\n### 낮은 처리량 문제\n\n`SimpleMessageContainerListener` 의 구현에서의 문제점은 최대 10개 메시지를 수신하여 처리할 수 있고, 이 메시지 모두가 처리되면 다음 `Poilling` 을 시작합니다.  대부분의 스레드가 DB Blocking I/O 작업으로 인해 비효율적인 CPU 사용을 초래할 수 있고, 10개 메시지 중에 처리가 오래걸리는 메시지가 존재한다면 그 메시지가 처리될 때까지 다른  모든 스레드가 대기하게 되므로 Consumer의 처리량이 낮아지게 됩니다.\n\n### 단일 Payload Handling\n\n```java\n\n\t@SqsListener(value = \"async_ff.fifo\", deletionPolicy = SqsMessageDeletionPolicy.NEVER)\n\tpublic void handle1(@Payload ApplicationEventMessage message){\n\t\tlog.info(\"receieved Message {} \" , message);\n\t}\n\n\t@SqsListener(value = \"async_ff.fifo\", deletionPolicy = SqsMessageDeletionPolicy.NEVER)\n\tpublic void handle2(@Payload Message message, MessageHeaders messageHeaders, Acknowledgment acknowledgment) throws InterruptedException {\n\t\tlog.info(\"receieved Message {} \" , message);\n\t}\n\n```\n\n- `async_ff.fifo` 큐에 대해서 `@SqsListener`로 메시지를 구독합니다.\n- 첫번쨰 핸들러의 페이로드 타입은 `ApplicationEventMessage` 이고, 두번째 핸들러 페이로드 타입은 `Message`입니다.\n- 위 코드를 돌려보면 아래와 같이 async_ff_fifo 큐에 중복된 핸들러로 맵핑할 수 없는 예외가 발생합니다.\n\n```\nAmbiguous handler methods mapped for destination 'async_ff.fifo': {public void com.example.awssqspilot.springboot.listener.SqsMessageListener.handle1(com.example.awssqspilot.domain.model.ApplicationEventMessage,org.springframework.messaging.MessageHeaders,org.springframework.cloud.aws.messaging.listener.Acknowledgment) throws java.lang.InterruptedException, public void com.example.awssqspilot.springboot.listener.SqsMessageListener.handle2(org.springframework.messaging.Message,org.springframework.messaging.MessageHeaders,org.springframework.cloud.aws.messaging.listener.Acknowledgment) throws java.lang.InterruptedException}\n```\n\n\n# **3. Solution**\n\n## **1. 처리량 극복**\n\n![Untitled](sqs_best_practice/Untitled_2.png)\n\n- 폴링 스레드에서 메시지를 처리하는 것이 아니라 `MessageHandler`로 메시지 처리를 위임합니다.\n- 폴링 스레드는 `MessageHandler` 에 작업만 전달하고 결과를 기다리지 않고, SQS Queue 로 다음 폴링 요청만 받습니다.\n- MessageHandler는 `EventWorkThreadPool`을 구성하고, 비동기처리로 CPU burst time 을 높입니다.\n\n## **2. 단일 페이로드 극복**\n\n![Untitled](sqs_best_practice/Untitled_3.png)\n\n# **4. Implementation**\n\n## **1. EventWorkPool 설정**\n\n```java\n@Bean(name = \"eventWorkerPool\")\npublic ThreadPoolTaskExecutor eventWorkerPool() {\n\tThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor();\n\texecutor.setMaxPoolSize(100);  // 스레드풀 개수를 설정합니다.\n\texecutor.setQueueCapacity(0);  // 스레드풀 대기큐에 과도한 요청이 들어오는걸 방지하기 위해 대기큐 사이즈를 0으로 설정합니다.\n\treturn executor;\n}\n```\n\n## **2. SqsMessageHandler 구현**\n\n```java\npublic class SqsMessageHandler {\n\n\tprivate final AsyncTaskExecutor eventWorkerPool;\n\tprivate final MessageTypeDispatcher messageTypeDispatcher;\n\tprivate static final Long backOffTime = 5000L;\n\n\tpublic void handle(\n\t\t\tfinal SqsMessage message,\n\t\t\tfinal MessageHeaders messageHeaders,\n\t\t\tfinal Acknowledgment acknowledgment\n\t) {\n\t\ttry {\n\n\t\t\teventWorkerPool.submit(() -> {\n\n\t\t\t\ttry {\n\t\t\t\t\tfinal Object result = messageTypeDispatcher.doDispatch(getMessageType(messageHeaders), message.getPayload());\n\n\t\t\t\t} catch (Exception e) {\n\n\t\t\t\t\tlog.error(\"EventWorkerPool Exception occurred\", e);\n\n\t\t\t\t\ttry {\n\t\t\t\t\t\t// noinspection BusyWait\n\t\t\t\t\t\tThread.sleep(backOffTime);\n\t\t\t\t\t} catch (InterruptedException ie) {\n\t\t\t\t\t\tThread.currentThread().interrupt();\n\t\t\t\t\t}\n\n\t\t\t\t\tthrow new RuntimeException(e);\n\t\t\t\t}\n\n\t\t\t});\n\n\t\t} catch (RejectedExecutionException e) {\n\t\t\tlog.error(\"eventThreadPool Queue is full. {}\", e.getMessage());\n\t\t\tthrow e;\n\t\t}\n\n\t}\n\n\tprivate MessageType getMessageType(final MessageHeaders messageHeaders) {\n\t\treturn new MessageType(messageHeaders.get(SqsMessageHeaders.SQS_EVENT_TYPE).toString());\n\t}\n\n}\n```\n\n## **3. MessageDispatcher 구현**\n\n![Untitled](sqs_best_practice/Untitled_4.png)\n\n- JAVA Reflection 과 Spring Component 스캔을 이용해서 `dynamic dispatch`로 구현\n1. `processor` 객체로 `messageType` 에 해당하는 `advice` 객체를 `get` 합니다.\n2. 반환받은 advice 객체 정보를 이용해서 `target bean` 과 `method`를 가져옵니다.\n3. `target method` 파라미터 타입에 맞게 ObjectMapper로 `json -> Object` 로 맵핑 후, `target method` 를 실행합니다.\n\n## 4. 사용\n\n![Untitled](sqs_best_practice/Untitled_5.png)"},{"excerpt":"대기열 유형 표준 대기열(Standard) 무제한 처리량 : API 작업당 거의 무제한의 TPS를 지원 최소한 한 번 전달(At-least-once delivery) : 메시가 최소한 한 번 전달되고, 가끔 2개 이상의 메시지 복사본이 전달될 수 있다. 순서 보장을 위해 최선의 노력 : 가끔 메시지가 전송된 순서와 다르게 전달될 수 있음.  FIFO 대기…","fields":{"slug":"/Amazon SQS Deep Dive/"},"frontmatter":{"date":"June 19, 2023","title":"Amazon SQS 딥다이브","tags":["AWS"]},"rawMarkdownBody":"\n\n## 대기열 유형\n\n### 표준 대기열(Standard)\n\n- **무제한 처리량** : API 작업당 거의 무제한의 TPS를 지원\n- **최소한 한 번 전달(At-least-once delivery)** : 메시가 최소한 한 번 전달되고, 가끔 2개 이상의 메시지 복사본이 전달될 수 있다.\n- **순서 보장을 위해 최선의 노력** : 가끔 메시지가 전송된 순서와 다르게 전달될 수 있음.\n\n<!-- more -->\n\n![Untitled](sqs_deep_dive/Untitled.png)\n\n\n### FIFO 대기열\n\n- **높은 처리량**: 기본적으로 FIFO 대기열은 초당 최대 300개의 메시지(초당 300개의 전송, 수신 또는 삭제 작업)를 지원합니다. 작업당 최대 10개 메시지를 일괄 처리할 경우, FIFO 대기열은 초당 3000개의 메시지까지 지원할 수 있습니다.\n- **정확히 한 번 처리(Exactly One Processing)** : 메시지가 한 번 전달되고 소비자가 이를 처리 및 삭제할 때까지 유지됩니다. 중복 메시지는 대기열에 올라가지 않습니다.\n- **선입선출 전달**: 메시지가 전송되고 수신되는 순서가 엄격하게 지켜집니다.\n\n![Untitled](sqs_deep_dive/Untitled_1.png)\n\n---\n\n## FIFO 큐란 무엇인가?\n### 일반적인 Queue\n\n![Untitled](sqs_deep_dive/Untitled_2.png)\n\n- Queue에서 선입선출 방식으로 enqueue, dequeue할 수 있다.\n\n### 멀티 스레드 환경에서의 문제점\n\n![Untitled](sqs_deep_dive/Untitled_3.png)\n\n- Producer와 Consumer가 다수(멀티스레드)인 환경에서는 FIFO(First In First Out)동작의 큐는 아무런 의미가 없다.\n    - Producer → Queue 에서의 네트워크 지연 시간\n    - Queue → Consumer 에서의 네트워크 지연 시간\n    - Consumer 에서 실제 메시지를 처리하는 시간\n- 클라이언트가 원하는것은 메시지를 (1,2,3) 을 보내면 (1,2,3) 순서대로 처리하고 싶은 것\n\n### Producer → Queue 로의 순서보장\n\n- Producer 에서 메시지를 전송할 때, Timestamp 를 찍어서 메시지를 전송한다.\n- Queue 에서는 FIFO 큐가 아니라 Timestamp 기준의 우선순위 큐를 구성한다.\n\n### Queue → Consumer 로의 순서보장\n\n- 가장 단순한 방법은 큐에서 Serializable하게 동기식으로 컨슈머에게 메시지를 전달하고 처리한다.\n\n![Untitled](sqs_deep_dive/Untitled_4.png)\n\n- 하지만, 이 방식의 문제점은 컨슈머가 다수더라도 단일 스레드 환경처럼 동작하여 처리량이 낮다.\n\n### SQS FIFO 큐에서 해결한 방식\n\n- SQS에서는 MessageGroup 이라는 개념을 적용하여 메시지를 논리적으로 하나의 그룹으로 묶는다.\n- 같은 그룹에 속하는 메시지는 앞에 메시지가 처리될 때까지 뒤에 들어온 메시지가 Blocking 되어 메시지 처리의 정확한 순서를 보장한다.\n- 같은 그룹이 아닌 메시지는 Blocking 되지 않으며, Consumer에게 큐잉된다.\n- 순서가 상관 없는 메시지는 서로 다른 그룹으로(A,B)로 지정한다.\n- 순서가 상관있는 메시지들끼리는 같은 그룹으로 지정한다.\n\n---\n\n## 분산 시스템에서 메시지 동기화 문제\n\n![Untitled](sqs_deep_dive/Untitled_5.png)\n\n- 시나리오\n    - Producer 가 Queue 메시지를 전송한다.\n    - 큐는 수신된 메시지를 저장하고 확인응답(ack)를 Producer에게 응답한다.\n    - 확인응답(ack)가 유실되어, Producer1는 메시지를 재전송한다.\n    - 결과적으로 메시지 1이 중복되서 큐에 저장이 된다.\n- Producer 에게 Ack 응답을 받으면 Message Commit하면 되지 않을까?\n    - 1. Producer → Queue 메시지 1 전달\n    - 2. Queue → Producer Ack 응답\n    - 3. Producer → Queue Ack 응답\n    - 4. Queue Message Commit\n        - 여기서 장애가 나면?\n            - Producer는 큐가 메시지를 정상적으로 받은 것으로 알고 있지만, 실제 Queue 에는 메시지가 정상적으로 저장되지 않았다. 즉 불일치가 발생한다.\n            - 정확한 동기화를 위해서 무한대의 ack 가 필요하다.\n\n---\n\n## SQS가 메시지 처리를 하는 방법\n\n![Untitled](sqs_deep_dive/Untitled_6.png)\n\n- Consumer 가 메시지를 수신하고 처리완료 후 큐에게 DeleteMessage 호출해야만 큐에서 메시지를 완전히 제거한다.\n- 하지만, 큐에 입장에서 Consumer가 메시지를 수신하고 정상적으로 처리해서 DeleteMessage를 호출한다는 보장이 없기 때문에, SQS는 메시지에 처리 시간 제한을 두었다.\n- 이 시간 제한을 Visibility Timeout 이라고 하며, Consumer가 메시지를 수신 후 Visibility Timeout 시간 동안 Delete Message를 하지 않으면 자동으로 롤백된다.\n    - Consumer 가 메시지를 정상적으로 수신하면, SQS는 메시지를 바로 삭제하는 것이 아니라, 또 다른 Consumer가 해당 메시지를 수신하지 못하도록 막는다.\n    - Consumer 가 메시지를 수신하여, DeleteMessage 까지 한다면 큐에서 완전히 삭제한다.\n    - Consumer 가 Visibility Timeout 동안 DeleteMessage 하지 못한다면 메시지를 다른 컨슈머가 수신받을 수 있도록 원복시킨다.\n\n![Untitled](sqs_deep_dive/Untitled_7.png)\n\n![https://docs.aws.amazon.com/images/AWSSimpleQueueService/latest/SQSDeveloperGuide/images/sqs-visibility-timeout-diagram.png](https://docs.aws.amazon.com/images/AWSSimpleQueueService/latest/SQSDeveloperGuide/images/sqs-visibility-timeout-diagram.png)\n\n---\n\n## At-least-once delivery\n\n- Standard 대기열의 경우 최소한 한 번 전달(At-least-once delivery)를 지원한다.\n- 분산 시스템에서 메시지 동기화 문제 에서도 보았듯이 네트워크 문제로 아래와 같은 경우에 메시지가 두 번 이상 중복 발행될 수 있다.\n    - Producer 가 Queue로 메시지를 전송했지만, Producer가 Ack 응답을 받지 못하여 메시지 전송실패로 알고 재전송 하는 경우\n        - → 큐에 중복된 메시지가 저장되므로 같은 메시지가 두번 발행될 수 있다.\n    - Consumer 가 메시지를 처리하고 DeleteMessage 를 호출하였지만, **SQS 내부의 분산된 저장구조 특성 탓에 몇몇 메시지 복사본이 삭제되지 않고** Consumer에게 재전송되는 경우\n\n## Exactly One Processing\n\n- FIFO 대기열의 경우 정확히 한 번 처리(Exactly One Procession)을 지원한다.\n- FIFO 대기열은 At-least-once delivery 에 엣지 케이스를 어떻게 해결했나?\n\n### Producer 가 Queue로 메시지를 전송했지만, Producer가 Ack 응답을 받지 못하여 메시지 전송실패로 알고 재전송 하는 경우\n- FIFO 대기열은 ContentBasedDeduplication 또는 MessageDeduplicationId 기반으로 메시지 중복 제거를 지원\n- ContentBasedDeduplication 은 메시지 컨텐츠를 SHA-256 으로 해쉬\n- MessageDeduplicationId 은 Producer 가 직접 지정하여 메시지를 전송한다.\n- 둘 중 하나의 방식으로 FIFO 대기열은 전송 중복 제거를 구현한다. 중복된 메시지의 경우 큐에 저장하지 않는다.\n- 중복값은 SQS에서 5분 동안 기억하고 있으며, 5분이 지나면 같은 메시지를 보낼 수 있다.\n\n### Consumer 가 메시지를 처리하고 DeleteMessage 를 호출하였지만, SQS 내부의 분산된 저장구조 특성 탓에 몇몇 메시지 복사본이 삭제되지 않고 Consumer에게 재전송되는 경우\n- 정확한 방법에 대한 이야기는 없지만 해당 케이스는 표준 대기열에서만 발생하는 케이스라고 [공식 문서](https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/standard-queues.html)는 말한다.\n\n---\n\n## Polling\n\n### Short Polling (짧은 폴링)\n\n![Untitled](sqs_deep_dive/Untitled_8.png)\n\n### Long Poliing (긴 폴링)\n\n![Untitled](sqs_deep_dive/Untitled_9.png)\n\n---\n\n## FIFO 큐의 한계\n\n- Producer의 부정확한 시계문제\n- 메시지 중복 5분 시간 제한 문제\n- Visibility Timeout 엣지 케이스\n\n## 참고자료\n\n- [SQS FIFO Queues: Message Ordering and Exactly-Once Processing Guaranteed? | Ably Blog: Data in Motion](https://ably.com/blog/sqs-fifo-queues-message-ordering-and-exactly-once-processing-guaranteed)\n- [https://awstip.com/how-to-efficiently-scale-aws-sqs-to-process-millions-of-messages-concurrently-in-spring-cloud-aws-c2431ed9e828](https://awstip.com/how-to-efficiently-scale-aws-sqs-to-process-millions-of-messages-concurrently-in-spring-cloud-aws-c2431ed9e828)\n- [Dissecting SQS FIFO Queues — Does Ordered and Exactly Once Messaging Really Exist?](https://sookocheff.com/post/messaging/dissecting-sqs-fifo-queues/) \n- [3 surprising facts about AWS SQS FIFO queues](https://tomgregory.com/3-surprising-facts-about-aws-sqs-fifo-queues/)\n- [https://aws.amazon.com/ko/blogs/developer/how-the-amazon-sqs-fifo-api-works/](https://aws.amazon.com/ko/blogs/developer/how-the-amazon-sqs-fifo-api-works/)\n- [What is Amazon Simple Queue Service? - Amazon Simple Queue Service](https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/welcome.html)"},{"excerpt":"카프카 스트림즈란? 사용자가 Kafka에서 데이터를 실시간으로 처리하는 상태 저장 스트림 처리 애플리케이션을 구축할 수 있게 해준다.\nStreams API로 개발된 애플리케이션은 이벤트 시간(즉, 데이터가 실제로 현실 세계에서 생성된 시점)을 기준으로 실시간 스트리밍 데이터를 처리하며, 늦게 도착하는 레코드도 지원한다.\n이를 통해 데이터 처리를 신속하게 …","fields":{"slug":"/\benabling_exactly_once_kafka_streams/"},"frontmatter":{"date":"June 16, 2023","title":"카프카 스트림즈의 정확히 한 번","tags":["카프카"]},"rawMarkdownBody":"\n\n## 카프카 스트림즈란?\n\n사용자가 Kafka에서 데이터를 실시간으로 처리하는 상태 저장 스트림 처리 애플리케이션을 구축할 수 있게 해준다.\nStreams API로 개발된 애플리케이션은 이벤트 시간(즉, 데이터가 실제로 현실 세계에서 생성된 시점)을 기준으로 실시간 스트리밍 데이터를 처리하며, 늦게 도착하는 레코드도 지원한다.\n이를 통해 데이터 처리를 신속하게 할 수 있으며, 탄력적으로 확장하고 분산 처리하며, 내결함성을 보장할 수 있다.\n\n<!-- more -->\n\n\n## 스트림 처리에서 정확히 한 번이란 무엇인가?\n\n스트림 처리 애플리케이션은 연속적인 데이터 스트림을 처리하므로,'정확성'을 보장하는 것은 중요한 문제이다.\n정확성을 보장하기 위해서는 입력 데이터 스트림의 각 레코드가 한 번만 처리되어야 한다는 조건이 항상 충족되어야한다.\n\n이를 구체적으로 설명하자면, 스트림 처리 애플리케이션은 카프카 토픽에서 읽어들인 레코드들을 처리하는데, 각 레코드는 한 번만 처리되어야 한다.\n이를 위해서 처리 로직은 읽기-처리-쓰기 패턴으로 구성되어야 한다.\n각 레코드는 읽혀지고, 처리 로직에 따라 상태가 업데이트되며, 그에 따라 출력 레코드가 생성될 수 있다.\n\n정확히 한 번이란, 입력 레코드의 처리 상태가 적절하게 업데이트되고, 출력 레코드가 정확히 한 번만 성공적으로 생성된 경우를 의미한다.\n즉, 각 레코드는 중복 처리되지 않아야 하며, 정확히 한 번의 결과만 생성되어야 한다.\n\n스트림 처리 애플리케이션이 단일 프로세스에서 실행되는 경우, 정확히 한 번을 유지하는 것은 상대적으로 쉽지만,\n여러 프로세스가 병렬로 실행되는 클러스터 환경에서 이 보장을 유지하는 것은 더 복잡하다.\n이러한 환경에서는 장애 상황이 발생할 가능성이 높아지기 때문에 정확히 한 번을 유지하는 것이 더 어려워진다.\n\n## Exactly once의 어려움\n\n카프카에서 저장된 스트리밍 데이터로 읽기-처리-쓰기 스트림 처리 애플리케이션을 구축하는 일반적인 프로그래밍 패턴은 다음과 같다.\n\n- 입력 카프카 토픽에서 메시지 A를 가져온다 (예: 토픽 TA).\n- 가져온 메시지 A에 대해 처리 함수 F를 실행하여 해당 데이터를 처리하고, 처리 결과를 상태 S에서 S'로 업데이트한다.\n- 출력 메시지 B1부터 Bn까지 생성하여 출력 카프카 토픽으로 보낸다. (단일 토픽 TB로 가정하지만, 여러 토픽으로 쉽게 확장할 수 있다.)\n- 전송된 출력 메시지 B1부터 Bn이 카프카 브로커로부터 승인될 때까지 기다린다.\n- 처리된 메시지 A의 오프셋을 TA에 커밋하여 해당 메시지의 처리가 완료되었음을 나타내고, 커밋의 승인을 기다린다.\n![Untitled](img/stream_1.png)\n\n실제로 4)와 5) 단계는 입력 Kafka 토픽에서 가져온 각 메시지에 대한 루프 반복 내에서 실행되지 않을 수 있다.\n이 단계들은 더 나은 성능을 위해 여러 메시지를 가져와서 처리한 후에만 호출된다.\n\n오류가 발생하지 않는다면, 이 구현 패턴은 각 레코드의 처리 결과(상태 업데이트와 출력 메시지)가 정확히 한 번만 반영되도록 보장할 수 있습니다.\n\n## 실패 시나리오 #1: 중복 쓰기\n\n첫 번째 오류 시나리오는 4) 단계에서 발생한다.\n이 상황에서는 TB 파티션의 리더 복제본을 호스팅하는 Kafka 브로커와 스트림 처리 애플리케이션 간에 네트워크 파티션이 발생한다고 가정한다.\n이로 인해 메시지가 TB 파티션 로그에 성공적으로 추가된 후에도 브로커의 승인 응답이 전송되지 않아 애플리케이션은 응답을 기다리는 시간 초과를 경험하게 된다.\n\n이러한 상황에서 애플리케이션은 네트워크 파티션으로 인해 메시지가 성공적으로 추가되었는지 확인할 수 없기 때문에 일반적으로 메시지 전송을 다시 시도한다(예: Java 생산자 클라이언트를 사용하는 경우, 생산자의 \"재시도\" 구성을 설정하여 이를 수행할 수 있음).\n그러나 네트워크가 복구되면 재전송이 성공하더라도 동일한 출력 메시지가 출력 카프카 토픽에 여러 번 추가되어 \"중복 쓰기\"가 발생할 수 있다.\n\n## 실패 시나리오 #2: 중복 처리\n\n이제 5) 단계에서 메시지 A가 완전히 처리되어 애플리케이션 상태가 업데이트되고 출력 메시지가 성공적으로 전송되고 승인되었다고 해보자.\n그러나 애플리케이션이 메시지 A의 처리 위치를 커밋하기 전에 오류가 발생하여 충돌이 발생하였다.\n\n애플리케이션은 재시작할 때 실패한 지점에서 이전에 기억된 위치, 즉 커밋된 오프셋에서 처리를 다시 시작하려고 한다.\n그러나 애플리케이션이 이전에 처리된 메시지 A의 오프셋을 커밋하지 못했기 때문에 A를 다시 가져오게 된다.\n이렇게 되면 처리 로직이 다시 트리거되어 상태를 두 번 업데이트하고(예: S'에서 S''로) 출력 메시지도 두 번 생성된다.\n결과적으로 애플리케이션 상태가 두 번 업데이트되고 출력 메시지도 두 번 전송되어 토픽 TB에 중복으로 추가된다.\n예를 들어, 애플리케이션이 토픽 TA에 저장된 입력 데이터 스트림에서 실행 횟수를 계산하는 경우, 이 \"중복 처리\" 오류는 애플리케이션에서 잘못된 결과를 초래하는 초과 계산을 의미한다.\n\n현재 많은 스트림 처리 시스템들은 \"정확히 한 번만\" 의미론을 제공한다고 주장하지만,\n실제로는 사용자가 카프카와 같은 기본 소스 및 대상 스트리밍 데이터 저장 계층과 협력해야 한다.\n이 계층은 단순히 블랙박스로 취급되기 때문에 이러한 실패 사례를 처리하지 않기 때문이다. \n따라서 애플리케이션 사용자 코드는 2단계 커밋 메커니즘을 통해 이러한 데이터 시스템과 조율하여 데이터 중복을 방지하거나 위에서 언급한 장애 시나리오에서 생성될 수 있는 중복 레코드를 처리해야 한다.\n\n\n## Kafka Streams가 정확한 1회 처리를 보장하는 방법\n\n카프카를 중심으로 구축된 읽기-처리-쓰기 스트림 처리 애플리케이션은 입력 카프카 토픽에서 읽은 각 메시지 A에 대해 트리거되는 함수 F로 추상화할 수 있다. F는 세 가지 주요 단계로 구성된다.\n\n- 애플리케이션 상태를 S에서 S'로 업데이트한다.\n- 결과 메시지 B1, ... Bn을 출력 카프카 토픽 TB에 쓴다.\n- 입력 카프카 토픽 TA에 처리된 레코드 A의 오프셋을 커밋한다.\n이러한 세 단계가 원자적으로 실행되어 모두 실행되거나 실행되지 않도록 보장하는 것은 일반적으로 스트림 처리 기술에서 어려운 작업이다.\n그러나 카프카를 사용하면 이러한 어려움을 실제로 더 간단한 문제로 해결할 수 있다.\n\n먼저, 아파치 카프카에서는 오프셋 커밋을 기록하기 위해 내부 카프카 토픽(오프셋 토픽)에 메시지를 작성한다.\n따라서 소스 토픽에 대한 오프셋 커밋은 다른 메시지를 해당 카프카 토픽에 쓰는 것으로 직관적으로 이해할 수 있다.\n\n두 번째로, 카프카 스트림에서는 상태 업데이트를 변경 캡처 메시지로 변환할 수 있다.\nKafka Streams 라이브러리는 모든 상태 저장소의 업데이트를 변경 로그 토픽이라는 특수 카프카 토픽으로 캡쳐한다.\n각 저장소는 업데이트를 별도의 변경 로그 토픽에 보관하며, 해당 저장소에 업데이트가 적용될 때마다 변경 로그 토픽에 새로운 레코드로 전송된다.\n이렇게 함으로써 변경 로그 토픽은 로드 밸런싱이나 장애 복구 등에 활용되어 다른 프로세서의 상태 저장소 복제에 사용될 수 있다.\n이를 통해 스냅샷 S에서 S'로의 로컬 상태 저장소의 모든 업데이트는 Kafka 변경 로그에 저장된 상태 변경 메시지 시퀀스(S1, ... Sn)로 캡처된다.\n\n따라서 위의 세 단계를 모두 다른 주제로 전송된 여러 레코드로 변환할 수 있으며, 트랜잭션 API를 활용하여 출력 토픽, 변경 로그 토큽, 오프셋 토픽으로 원자 단위로 전송되도록 보장할 수 있다.\n이렇게 함으로써 카프카 스트림은 정확한 1회 처리를 보장할 수 있다.\n\n보다 구체적으로, processing.guarantee가 정확히_한번으로 구성된 경우, Kafka Streams는 내부 임베디드 생산자 클라이언트에 트랜잭션 ID를 설정하여 idempotence 및 트랜잭션 메시징 기능을 활성화하고,\n소비자 클라이언트를 읽기-커밋 모드로 설정하여 업스트림 생산자로부터 커밋된 트랜잭션의 메시지만 가져온다.\n\n애플리케이션을 시작하면 스트림 작업이 초기화되고 처리를 시작할 준비가 되면 임베디드 트랜잭션 생산자가 첫 번째 트랜잭션을 시작한다.\n그리고 애플리케이션이 현재 처리 상태를 커밋하려고 할 때마다 임베디드 트랜잭션 프로듀서를 사용해 소비자로부터 가져온 포지션 오프셋을 트랜잭션의 일부로 전송한 다음 현재 트랜잭션을 커밋하고 새 트랜잭션을 시작하려고 시도한다.\n\n이제 트랜잭션 내에서 일시적인 네트워크 분할이 발생하여 전송된 레코드 중 하나라도 제시간에 승인을 받지 못한 경우,\n동일한 트랜잭션 ID를 가진 스트림은 데이터를 다시 전송하려고 시도하는 경우가 있다.\n하지만, 프로듀서 구성 enable.idempotence가 true로 설정된 경우 브로커는 중복 메시지를 수신하면 해당 레코드를 무시하고 클라이언트에 DUP 응답을 반환한다.\n\n![Untitled](img/stream_2.png)\n\n\n또한, 정상 처리 중 또는 커밋 단계에서 치명적인 오류가 발생하면 Kafka Streams는 예외를 발생시키기 전에 생산자가 진행 중인 트랜잭션을 중단하도록 허용한다.\n이렇게 함으로써 스트림 애플리케이션 작업이 동일한 트랜잭션 ID로 다시 시작될 경우,\n이 ID의 마지막 트랜잭션이 완료(커밋 또는 중단)되었고 변경 로그 주제, 오프셋 주제 및 출력 주제에 커밋된 모든 메시지가 동일한 트랜잭션(아래 그림에 표시된 황금색 막대)에서 나온 것임을 확신할 수 있다.\n\n![Untitled](img/stream_3.png)\n\n이 변경 로그 메시지 시퀀스를 재생하면 로컬 상태 저장소를 항상 S'까지 복원할 수 있다.\n따라서 프로세서 상태가 복원되고 작업이 처리를 재개할 준비가 되면 해당 상태는 커밋된 오프셋 및 출력 메시지와 일관된 스냅샷이 되므로 정확히 한 번만 의미론이 보장된다.\n\n## 스트림 성능에 미치는 영향\n\n트랜잭션의 쓰기 증폭 비용은 일정하며 파티션 내에 쓰여진 메시지 수와 무관하다.\n따라서 메시지 측면에서 트랜잭션이 클수록 상각 비용은 작아진다.\n그러나 읽기 커밋 모드의 소비자는 트랜잭션이 커밋된 경우에만 트랜잭션의 메시지를 가져올 수 있기 때문에 트랜잭션이 클수록 엔드투엔드 처리 지연 시간도 길어진다.\n\n커밋이 호출될 때마다 새로운 트랜잭션이 생성되기 때문에, 평균 트랜잭션 크기는 커밋 간격에 의해 결정되며,\n동일한 수신 트래픽의 경우 커밋 간격이 짧을수록 트랜잭션이 더 작아진다.\n따라서 사용자는 정확히 한 번을 사용하도록 설정할 때 commit.interval.ms 설정을 조정하여 처리량과 엔드투엔드 처리 지연 시간 간에 적절한 균형을 맞춰야 한다.\n\n\n## 참조\n[https://www.confluent.io/blog/enabling-exactly-once-kafka-streams/](https://www.confluent.io/blog/enabling-exactly-once-kafka-streams/)"},{"excerpt":"왜 트랜잭션인가? 웹 페이지 노출 스트림을 소비하고 웹 페이지당 총 조회 수를 생성하는 애플리케이션은 카운트에서 약간의 오류를 허용할 수 있다.\n그러나 이러한 애플리케이션의 인기와 함께 더 강력한 의미론을 갖춘 스트림 처리 애플리케이션에 대한 수요도 증가했다.\n예를 들어, 일부 금융 기관에서는 스트림 처리 애플리케이션을 사용하여 사용자 계정의 차변 및 대…","fields":{"slug":"/trasaction_in_kafka/"},"frontmatter":{"date":"June 15, 2023","title":"카프카에서의 Transactions","tags":["카프카"]},"rawMarkdownBody":"\n## 왜 트랜잭션인가?\n웹 페이지 노출 스트림을 소비하고 웹 페이지당 총 조회 수를 생성하는 애플리케이션은 카운트에서 약간의 오류를 허용할 수 있다.\n그러나 이러한 애플리케이션의 인기와 함께 더 강력한 의미론을 갖춘 스트림 처리 애플리케이션에 대한 수요도 증가했다.\n예를 들어, 일부 금융 기관에서는 스트림 처리 애플리케이션을 사용하여 사용자 계정의 차변 및 대변을 처리한다.\n이러한 상황에서는 처리 오류에 대한 허용 오차가 없기 때문에 모든 메시지가 예외 없이 정확히 한 번만 처리되어야 한다.\n\n정확히 한 번만 처리한다는 것은 스트림 처리 애플리케이션이 메시지 A를 소비하고 메시지 B를 생성하여 B = F(A)가 되는 경우,\nB가 성공적으로 생성된 경우에만 A가 소비된 것으로 간주하고 그 반대의 경우도 마찬가지라는 뜻이다.\n\n하지만 바닐라 카프카 생산자와 소비자를 사용하여 스트림 처리 애플리케이션을 최소 1회 전송 의미론에 맞게 구성하면 정확히 1회 처리 의미론을 잃을 수 있다.\nproducer.send()는 내부 재시도로 인해 메시지 B에 대한 중복 쓰기를 초래할 수 있으며,\n입력 메시지 A를 재처리하여 출력에 중복된 B 메시지가 작성되어 정확히 한 번만 처리한다는 의미론을 위반할 수 있다.\n또한 분산 환경에서는 애플리케이션이 충돌하거나 더 심각한 경우 시스템의 나머지 부분과의 연결이 일시적으로 끊어져 새로운 인스턴스가 된다.\n이때 여러 인스턴스가 동일한 입력 주제를 처리하고 동일한 출력 주제에 쓰면서 중복 출력이 발생하고 정확히 한 번만 처리하는 시맨틱을 위반할 수 있다.\n이를 \"좀비 인스턴스\" 문제라고 부른다.\n\n## 트랜잭션 의미론\n\n### Atomic multi-partition writes\n\n트랜잭션은 여러 개의 카프카 토픽과 파티션에 원자적 쓰기를 가능하게 한다.\n트랜잭션에 포함된 모든 메시지가 성공적으로 쓰여질 수도 있고 그렇지 않을 수도 있다.\n예를 들어, 처리 중 오류가 발생하면 트랜잭션이 중단될 수 있으며, 이 경우 소비자는 트랜잭션의 어떤 메시지도 읽을 수 없게 된다.\n\n원자적 읽기-처리-쓰기 주기가 활성화되는 방법을 살펴보자.\n이 주기는 애플리케이션이 토픽 파티션 tp0의 오프셋 X에서 메시지 A를 소비하고,\n메시지 A에 대해 처리를 수행한 후 메시지 B를 토픽 파티션 tp1에 쓰는 경우를 한다.\n이 주기는 메시지 A와 B가 함께 성공적으로 소비 및 게시된 것으로 간주되거나 전혀 그렇지 않은 경우에만 원자적이라고 한다.\n\n메시지 A는 오프셋 X가 소비된 것으로 표시된 경우에만 토픽 파티션 tp0에서 소비된 것으로 된다.\n이것을 오프셋 커밋이라고 하며, Kafka는 오프셋 커밋을 내부 Kafka 토픽에 기록한다.\n메시지는 오프셋이 오프셋 토픽에 커밋된 경우에만 소비된 것으로 간주된다.\n\n따라서 여러 토픽과 파티션에 걸친 원자적 쓰기는 오프셋 커밋을 통해 가능해진다.\n오프셋 X를 오프셋 토픽에 커밋하고 메시지 B를 tp1에 쓰는 것은 단일 트랜잭션의 일부가 되므로, 원자적으로 처리한다.\n\n### Zombie fencing\n트랜잭션 생산자는 트랜잭션.id라는 고유 식별자를 할당받아야 한다.\n이 식별자는 프로듀서 인스턴스를 다시 시작할 때 동일한 프로듀서를 식별하는 데 사용된다.\n\n트랜잭션 API는 트랜잭션 생산자의 첫 번째 작업으로 트랜잭션.id를 Kafka 클러스터에 명시적으로 등록해야 한다고 요구한다.\n이렇게 함으로써 Kafka 브로커는 주어진 transactional.id로 열려 있는 트랜잭션을 확인하고 완료할 수 있다.\n또한 트랜잭션.id와 연결된 에포크를 시킨다. 에포크는 모든 트랜잭션.id에 대해 저장되는 내부 메타데이터이다.\n\n에포크가 증가하면 트랜잭션 id가 같고 에포크가 오래된 모든 프로듀서는 좀비로 간주되어 차단되며,\n해당 프로듀서의 향후 트랜잭션 쓰기가 거부된다. 이렇게 함으로써 좀비 인스턴스 문제를 해결할 수 있다.\n\n### 트랜잭션 메시지 읽기\n\n이제 트랜잭션 메시지를 읽을 때 제공되는 보장에 대해 알아보자.\n\nKafka 소비자는 트랜잭션이 실제로 커밋된 경우에만 트랜잭션 메시지를 애플리케이션에 전달한다.\n다시 말해, 소비자는 진행 중인 트랜잭션의 일부인 트랜잭션 메시지를 전달하지 않으며 중단된 트랜잭션의 일부인 메시지도 전달하지 않는다.\n\n이러한 보장은 원자 읽기에는 미치지 못한다는 점에 유의할 필요가 있다.\n특히, 카프카 소비자를 사용하여 토픽의 메시지를 소비할 때, 애플리케이션은 이러한 메시지가 트랜잭션의 일부로 작성되었는지 여부를 알 수 없으므로 트랜잭션이 언제 시작되거나 종료되는지 알 수 없다.\n또한 특정 소비자가 트랜잭션의 일부인 모든 파티션에 가입되어 있다는 보장이 없으며, 이를 발견할 방법이 없기 때문에 단일 트랜잭션의 일부였던 모든 메시지가 결국 단일 소비자에게 소비될 것이라고 보장하기 어렵다.\n\n간단히 말해, 카프카는 소비자가 결국 커밋된 트랜잭션 메시지만 전달하도록 보장한다. 진행 중인 트랜잭션의 메시지는 보류하고 중단된 트랜잭션의 메시지는 필터링한다.\n\n## Java의 트랜잭션 API\n\n트랜잭션 기능은 서버 측 및 프로토콜 수준의 기능으로 주로 사용되며, Kafka의 트랜잭션 API는 이를 지원하는 모든 클라이언트 라이브러리에서 사용할 수 있다.\nJava로 작성된 '읽기-처리-쓰기' 애플리케이션에서 Kafka의 트랜잭션 API를 사용하는 형태는 다음과 같다.\n\n```java\nKafkaProducer producer = createKafkaProducer(\n  “bootstrap.servers”, “localhost:9092”,\n  “transactional.id”, “my-transactional-id”);\n\nproducer.initTransactions();\n\nKafkaConsumer consumer = createKafkaConsumer(\n  “bootstrap.servers”, “localhost:9092”,\n  “group.id”, “my-group-id”,\n  \"isolation.level\", \"read_committed\");\n\nconsumer.subscribe(singleton(“inputTopic”));\n\nwhile (true) {\n  ConsumerRecords records = consumer.poll(Long.MAX_VALUE);\n  producer.beginTransaction();\n  for (ConsumerRecord record : records)\n    producer.send(producerRecord(“outputTopic”, record));\n  producer.sendOffsetsToTransaction(currentOffsets(consumer), group);  \n  producer.commitTransaction();\n}\n```\n1~5행은 구성을 지정하고 이를 initTransactions API에 등록하여 프로듀서를 설정한다.\nproducer.initTransactions()가 반환된 후, 동일한 transactional.id를 가진 다른 프로듀서 인스턴스로 시작된 모든 트랜잭션은 닫히고 펜싱된다.\n\n7-10행은 KafkaConsumer가 입력 토픽에서 비트랜잭션 메시지 또는 커밋된 트랜잭션 메시지만 읽어야 한다고 지정한다.\n스트림 처리 애플리케이션은 일반적으로 여러 읽기-처리-쓰기 단계로 데이터를 처리하며, 각 단계는 이전 단계의 출력을 입력으로 사용한다.\n읽기-커밋 모드를 지정하면 모든 단계에서 정확히 한 번만 처리할 수 있다.\n\n14~21행은 읽기-처리-쓰기 루프의 핵심을 보여준다. 일부 레코드를 소비하고, 트랜잭션을 시작하고, 소비된 레코드를 처리하고, 처리된 레코드를 출력 토픽에 쓰고, 소비된 오프셋을 오프셋 토픽으로 전송하고, 마지막으로 트랜잭션을 커밋하는 것이다.\n위에서 언급한 보증을 통해, 오프셋과 출력 레코드가 원자 단위로 커밋될 것임을 알 수 있다.\n\n\n## 트랜잭션 작동 방식\n\n![Untitled](img/img1.png)\n\n\n## 트랜잭션 코디네이터와 트랜잭션 로그\n\nKafka 0.11.0에서 도입된 트랜잭션 API와 함께의 구성 요소는 다이어그램의 오른쪽에 위치한 트랜잭션 코디네이터와 트랜잭션 로그이다.\n\n트랜잭션 코디네이터는 모든 Kafka 브로커 내에서 실행되는 모듈로, 트랜잭션 처리를 조정한다.\n트랜잭션 로그는 카프카의 내부 토픽으로, 각 코디네이터는 트랜잭션 로그의 일부 파티션을 소유하게 된다.\n이때, 각 transactional.id는 간단한 해싱 함수를 통해 트랜잭션 로그의 특정 파티션에 매핑되어 정확히 하나의 코디네이터가 해당 트랜잭션 아이디를 소유하게 된다.\n\n이런 방식으로 Kafka의 견고한 복제 프로토콜과 리더 선출 프로세스를 활용하여 트랜잭션 코디네이터가 항상 사용 가능하고 모든 트랜잭션 상태가 내구성 있게 저장되도록 보장한다.\n\n트랜잭션 로그에는 트랜잭션의 최신 상태만 저장되며, 트랜잭션의 실제 메시지는 저장되지 않는다.\n메시지는 실제 토픽 파티션에만 저장되고, 트랜잭션은 여러 상태 중 \"진행 중\", \"커밋 준비 중\", \"완료됨\" 등의 상태에 있을 수 있다.\n트랜잭션 로그에는 이러한 상태와 관련된 메타데이터만 저장된다.\n\n## 데이터 흐름\n\n데이터 흐름은 크게 네 가지 유형으로 나눌 수 있다.\n\nA: 생산자와 트랜잭션 코디네이터의 상호작용으로 실행되는 트랜잭션 과정\n\n- initTransactions API를 통해 생산자가 트랜잭션 코디네이터에게 트랜잭션 ID를 등록한다\n이때, 코디네이터는 해당 트랜잭션의 보류 중인 트랜잭션을 모두 종료하고 에포크를 업데이트하여 좀비를 차단한다. 이 작업은 프로듀서 세션당 한 번만 발생한다.\n- 프로듀서가 트랜잭션에서 처음으로 파티션에 데이터를 전송하려고 할 때, 해당 파티션이 코디네이터에 먼저 등록된다.\n- 애플리케이션이 commitTransaction 또는 abortTransaction을 호출하면 코디네이터에게 2단계 커밋 프로토콜을 시작하도록 요청한다.\n\nB: 코디네이터와 트랜잭션 로그가 상호작용하는 트랜잭션 과정에서, 프로듀서는 위의 요청을 통해 코디네이터의 트랜잭션 상태를 업데이트 한다.\n트랜잭션 코디네이터는 자신이 소유한 각 트랜잭션의 상태를 메모리에 보관하고, 트랜잭션 로그에 해당 상태를 기록한다(세 가지 방법으로 복제되므로 내구성이 있음).\n\nC: 대상 토픽 파티션에 데이터를 쓰는 프로듀서는 코디네이터와 트랜잭션에 새 파티션을 등록한 후, 정상적으로 실제 파티션에 데이터를 전송한다.\n이때, 몇 가지 추가 유효성 검사를 통해 생산자가 펜싱되지 않았는지 확인한다.\n\nD: 토픽-파티션 상호작용에 대한 코디네이터 프로듀서의 커밋(또는 중단)이 시작되면, 코디네이터는 2단계 커밋 프로토콜을 시작한다.\n\n첫 번째 단계에서 코디네이터는 내부 상태를 \"prepare_commit\"으로 업데이트하고 트랜잭션 로그에 이 상태를 업데이트한다.\n이 작업이 완료되면 트랜잭션은 무슨 일이 있어도 커밋이 보장된다.\n\n그런 다음 코디네이터는 트랜잭션의 일부인 토픽 파티션에 트랜잭션 커밋 마커를 기록하는 2단계를 시작한다.\n\n이러한 트랜잭션 마커는 애플리케이션에 노출되지는 않지만, 읽기_커밋 모드의 소비자가 중단된 트랜잭션에서 메시지를 필터링하고 열려 있는 트랜잭션의 일부인 메시지(즉, 로그에는 있지만 트랜잭션 마커가 연결되어 있지 않은 메시지)를 반환하지 않기 위해 사용된다.\n\n마커가 작성되면 트랜잭션 코디네이터가 트랜잭션을 \"완료\"로 표시하고 생산자는 다음 트랜잭션을 시작할 수 있다.\n\n## 실제 트랜잭션\n이제 트랜잭션의 의미와 작동 방식을 이해했으므로 트랜잭션을 활용하는 애플리케이션 작성의 실제 측면에 주목해보자.\n\n트랜잭션 ID를 선택하는 방법은 좀비를 차단하는 데 중요한 역할을 한다.\n그러나 프로듀서 세션 전반에서 일관성을 유지하면서 좀비를 적절히 차단하는 식별자를 유지하는 것은 약간 까다로운 작업이다.\n\n좀비를 적절히 차단하기 위한 핵심은 읽기-프로세스-쓰기 주기의 입력 토픽과 파티션이 주어진 트랜잭션 ID에 대해 항상 동일한지 확인하는 것이다.\n그렇지 않으면 일부 메시지가 트랜잭션에서 제공하는 펜싱을 통해 유출될 수 있다.\n\n예를 들어, 분산 스트림 처리 애플리케이션에서 토픽 파티션 tp0이 원래 트랜잭션 ID T0에 의해 처리되었다고 가정해보자.\n나중에 어느 시점에 트랜잭션이 다른 생산자에게 매핑될 수 있다면, T0과 T1 사이에는 펜싱이 존재하지 않게 된다.\n따라서 tp0의 메시지가 재처리되어 정확히 한 번만 처리한다는 보장을 위반할 수 있다.\n\n실제로는 입력 파티션과 트랜잭션 ID 사이의 매핑을 외부 저장소에 저장하거나 정적 인코딩을 해야한다.\nKafka Streams는 이 문제를 해결하기 위해 후자의 접근 방식을 선택한다.\n\n## 트랜잭션의 성능 및 조정 방법\n\n트랜잭션은 적당한 수준의 쓰기 증폭만 유발한다. 추가 쓰기는 다음과 같은 이유 때문이다.\n\n- 각 트랜잭션마다 코디네이터에 파티션을 등록하기 위한 추가 RPC가 필요하다. 이는 일괄 처리되므로 트랜잭션의 파티션 수보다 RPC 수가 적다.\n- 트랜잭션을 완료할 때, 트랜잭션에 참여하는 각 파티션에 하나의 트랜잭션 마커를 기록해야 한다.\n트랜잭션 코디네이터는 동일한 브로커에 바인딩된 모든 마커를 단일 RPC에서 일괄 처리하므로 RPC 오버헤드를 절약할 수 있지만, 트랜잭션의 각 파티션에 대한 추가 쓰기를 피할 수는 없다.\n- 마지막으로 트랜잭션 로그에 상태 변경 사항을 기록합니다.\n여기에는 트랜잭션에 추가된 각 파티션 배치에 대한 쓰기, \"prepare_commit\" 상태, \"complete_commit\" 상태가 포함된다.\n오버헤드는 트랜잭션의 일부로 기록되는 메시지 수와는 무관하다. 따라서 처리량을 높이려면 트랜잭션당 더 많은 수의 메시지를 포함시키는 것이 핵심이다.\n실제로 최대 처리량으로 1KB 레코드를 생성하는 프로듀서의 경우, 100ms마다 메시지를 커밋하면 처리량이 3%만 저하된다.\n더 작은 메시지나 더 짧은 트랜잭션 커밋 간격은 더 심각한 성능 저하를 초래할 수 있다.\n\n트랜잭션 기간을 늘릴 때의 주요 단점은 엔드 투 엔드 지연 시간이 증가한다는 것이다.\n트랜잭션 메시지를 읽는 소비자는 진행 중인 트랜잭션의 일부인 메시지를 전달하지 않는다는 것을 유의하자.\n따라서 커밋 사이의 간격이 길어질수록 소비 애플리케이션이 더 오래 기다려야 하므로 엔드투엔드 지연 시간이 증가한다.\n\n## 트랜잭션 소비자의 성능\n\n트랜잭션 소비자는 생산자보다 훨씬 간단하다.\n\n- 중단된 트랜잭션에 속한 메시지를 필터링한다.\n- 진행 중인 트랜잭션의 일부인 트랜잭션 메시지를 반환하지 않는다.\n\n따라서 트랜잭션 소비자는 read_committed 모드에서 트랜잭션 메시지를 읽을 때 처리량 저하가 나타나지 않는다.\n이 주된 이유는 트랜잭션 메시지를 읽을 때 제로 카피 읽기를 보존하기 때문이다.\n\n또한, 소비자는 트랜잭션이 완료될 때까지 기다리기 위해 버퍼링을 할 필요가 없다.\n대신 브로커는 미체결 트랜잭션이 포함된 오프셋으로 진행하는 것을 허용하지 않는다.\n\n## 결론\n읽기-처리-쓰기 주기를 고려할 때, 이 게시물에서는 주로 읽기 및 쓰기 경로를 다루었으며 처리 자체는 블랙박스에 해당된다.\n사실 처리 단계에서 수행할 수 있는 작업은 매우 많기 때문에 트랜잭션 API만으로는 정확한 1회 처리를 보장할 수 없다.\n예를 들어, 처리가 다른 스토리지 시스템에 부작용을 일으키는 경우, 여기서 다루는 API로는 정확한 1회 처리를 보장하기에 충분하지 않다.\n\n## 참조\n\n[https://www.confluent.io/blog/transactions-apache-kafka/](https://www.confluent.io/blog/transactions-apache-kafka/)"},{"excerpt":"Message Delivery Semantics 분산형 Pub/Sub 메시징 시스템에서는 컴퓨터들이 독립적으로 장애를 일으킬 수 있다.\n예를 들어, 카프카는 개별 브로커 충돌이나 프로듀서가 메시지를 보내는 동안 네트워크 장애로 인해 문제가 발생할 수 있다.\n이러한 장애를 처리하기 위해 프로듀서가 취하는 조치에 따라 다른 의미가 있다. At most onc…","fields":{"slug":"/Exactly_Once_Semantics/"},"frontmatter":{"date":"June 14, 2023","title":"카프카는 어떻게 Exactly-Once Semantics 보장하나?","tags":["카프카"]},"rawMarkdownBody":"\n\n## Message Delivery Semantics\n\n분산형 Pub/Sub 메시징 시스템에서는 컴퓨터들이 독립적으로 장애를 일으킬 수 있다.\n예를 들어, 카프카는 개별 브로커 충돌이나 프로듀서가 메시지를 보내는 동안 네트워크 장애로 인해 문제가 발생할 수 있다.\n이러한 장애를 처리하기 위해 프로듀서가 취하는 조치에 따라 다른 의미가 있다.\n\n- At most once: 생산자가 Kafka 브로커로부터 확인(ack)을 수신하고 acks=all인 경우, 이는 메시지가 Kafka 토픽에 정확히 한 번 쓰여진 것을 의미한다.\n그러나 프로듀서가 시간 초과되거나 오류를 수신하면 메시지가 카프카 토픽에 쓰여지지 않았다고 가정하고 메시지 전송을 다시 시도할 수 있다.\n이로 인해 브로커가 응답을 보내기 직전에 실패했을 경우, 메시지가 이미 성공적으로 쓰여졌음에도 불구하고 메시지가 두 번 쓰여져서 최종 소비자에게 중복 전달될 수 있다. \n\n- At least once: 생산자가 시간 초과나 오류를 반환할 때 재시도하지 않으면 메시지가 카프카 토픽에 기록되지 않아 소비자에게 전달되지 않을 수 있다.\n대부분의 경우 메시지는 전달되지만, 때때로 중복 전달을 피하기 위해 일부 메시지는 전달되지 않을 수도 있다.\n\n- Exactly once: 이 경우 생산자가 메시지 전송을 다시 시도하더라도 최종적으로 메시지는 소비자에게 정확히 한 번만 전달된다.\n이 접근 방식은 가장 바람직한 방법이지만 이해하기 어렵다. 이는 메시징 시스템과 애플리케이션 간의 협력이 필요하기 때문이다.\n예를 들어, 메시지를 소비한 후에 카프카 소비자를 이전 오프셋으로 되돌리면 해당 오프셋에서 최신 메시지까지 모든 메시지를 다시 수신하게 된다.\n이렇게 하면 메시징 시스템과 클라이언트 애플리케이션이 협력하여 정확히 한 번만 메시지가 발생하도록 보장해야 한다.\n<!-- more -->\n\n## Exactly once 의 어려움\n한 개의 프로세스로 동작하는 생산자 소프트웨어 애플리케이션이 'Hello Kafka'라는 단일 파티션 카프카 토픽에 'EoS'라는 메시지를 보낸다.\n이 메시지를 수신하기 위해 반대편에 위치한 단일 인스턴스 소비자 애플리케이션이 동작한다.\n이상적인 경우에는 잘 작동하여 'Hello Kafka' 메시지가 EoS 토픽 파티션에 한 번만 기록된다.\n소비자는 메시지를 가져와서 처리를 완료한 후 메시지 오프셋을 커밋하여 처리를 완료했음을 알린다.\n또한, 소비자 애플리케이션이 실패하고 다시 시작해도 같은 메시지를 중복 수신하지 않는다.\n\n그러나 현실적으로 예상치 못한 실패 시나리오가 항상 발생할 수 있다.\n\n- 브로커는 실패: Kafka는 고가용성, 지속성, 내구성이 뛰어난 시스템으로, 파티션에 기록된 모든 메시지는 일정 횟수 동안 지속 및 복제된다.\n이로 인해 Kafka는 n-1 브로커 장애를 견딜 수 있으며, 적어도 하나 이상의 사용 가능한 브로커가 있으면 파티션을 사용할 수 있다.\n카프카의 복제 프로토콜은 메시지가 리더 복제본에 성공적으로 쓰여질 경우 사용 가능한 모든 복제본에 복제되도록 보장한다.\n\n- 생산자-브로커 간 RPC는 실패: Kafka의 내구성은 브로커로부터 응답을 받는 프로듀서에 따라 달라진다.\n응답을 받지 못했다고 해서 요청 자체가 실패한 것은 아니다.\n브로커는 메시지를 작성한 후 생산자에게 응답을 보내기 전에 충돌할 수 있다.\n또한 토픽에 메시지를 작성하기 전에 크래시될 수도 있다.\n생산자는 실패의 원인을 알 수 없기 때문에 메시지가 성공적으로 작성되지 않았다고 가정하고 재시도할 수 있다.\n때로는 동일한 메시지가 카프카 파티션 로그에 중복되어 최종 소비자가 두 번 이상 수신하는 경우가 생길 수 있다.\n\n- 클라이언트가 실패: 한 번만 메시지를 전송하려면 클라이언트 장애도 고려해야 된다.\n그러나 클라이언트가 브로커에서 일시적으로 파티셔닝되거나 애플리케이션이 일시 중지된 것인지, 아니면 실제로 실패한 것인지를 어떻게 알 수 있을까? \n영구적인 장애와 일시적인 장애를 구분하는 것이 중요하며, 브로커는 '좀비' 생산자가 보낸 메시지를 삭제해야 한다.\n새로운 클라이언트 인스턴스가 시작될 때 실패한 인스턴스가 남긴 상태로부터 복구하여 안전한 지점부터 처리를 시작할 수 있어야 한다.\n즉, 소비된 오프셋은 항상 생산된 출력과 동기화 상태를 유지해야 한다.\n\n### 멱등성: 파티션당 Exactly once 의미론\n- \"enable.idempotence=true\" 옵션을 사용하면, 비동작 연산을 여러 번 수행해도 동일한 결과를 보장한다.\n- 프로듀서 보내기 연산이 비활성화되어도, 오류로 인해 생산자가 메시지를 재시도하는 경우에도 브로커의 Kafka 로그에는 동일한 메시지가 한 번만 기록된다.\n- 단일 파티션의 경우, 멱등한 프로듀서가 메시지를 보내면 프로듀서나 브로커 오류로 인해 메시지가 중복되는 가능성이 없어진다.\n- 이 기능을 사용하여 파티션당 정확히 한 번만 시맨틱을 전송하므로 중복과 데이터 손실 없이 메시지를 순서대로 전송할 수 있다.     \n\n이 기능은 TCP와 유사한 방식으로 작동하며, Kafka로 전송되는 각 메시지 배치에는 중복 전송을 제거하는 데 사용되는 시퀀스 번호가 포함된다.\n이 시퀀스 번호는 복제된 로그에 유지되어 리더가 실패해도 인계받은 모든 브로커가 재전송이 중복 전송인지 여부를 파악할 수 있다.\n이 메커니즘은은 각 메시지 배치에 숫자 필드 몇 개만 추가하면 되기 때문에 성능 오버헤드가 매우 낮다.\n\n> 각 새로운 생산자는 초기화 과정에서 고유한 PID가 할당된다. PID 할당은 사용자에게 완전히 투명하며, 클라이언트에서 노출되지 않는다. \n> 특정 PID에 대해 시퀀스 번호는 0부터 시작하여 Topic Partition당 하나씩 모노토닉하게 증가된다.   \n> \n> 생산자가 보내는 각 메시지마다 시퀀스 번호가 증가한다. 마찬가지로, 브로커는 해당 Topic Partition에 대해 커밋하는 각 메시지마다 PID -> Topic Partition 쌍에 연결된 시퀀스 번호를 증가시킨다.\n> 마지막으로, 브로커는 PID -> 토픽 파티션 쌍에서 마지막으로 커밋된 메시지보다 시퀀스 번호가 정확히 하나 크지 않은 경우 프로듀서로부터의 메시지를 거부한다.   \n>\n> 이를 통해 생산자가 실패 시 요청을 다시 시도해야 할 수 있지만, 모든 메시지가 로그에 정확히 한 번만 지속되도록 보장된다.\n> 또한, 각 새로운 생산자 인스턴스에는 새로운 고유한 PID가 할당되므로 한 번의 생산 세션 내에서만 멱등한 생산을 보장할 수 있다.\n>\n\n## Kafka의 트랜잭션\n\nKafka는 트랜잭션 API를 통해 여러 파티션에 걸친 트랜잭션 연산을 지원한다.\n이를 통해 생산자는 메시지 배치를 여러 파티션에 전송하여 모든 메시지가 최종적으로 모든 소비자에게 표시되거나 아예 표시되지 않도록 할 수 있다.\n또한 이 기능을 사용하면 처리한 데이터와 함께 동일한 트랜잭션에서 소비자 오프셋을 커밋할 수 있어 엔드투엔드로 정확히 한 번만 메시지를 전달할 수 있다.\n\n소비자 측에서는 격리 수준 소비자 구성을 통해 표현되는 트랜잭션 메시지를 읽는 두 가지 옵션이 있다.\n\nread_committed: 트랜잭션의 일부가 아닌 메시지를 읽는 것 외에도 트랜잭션이 커밋된 후 트랜잭션의 일부인 메시지를 읽을 수도 있다.\nread_uncommitted: 트랜잭션이 커밋될 때까지 기다리지 않고 오프셋 순서대로 모든 메시지를 읽는다.\n트랜잭션을 사용하려면, 올바른 격리 수준을 사용하도록 소비자를 구성하고, 새로운 생산자 API를 사용하고, 생산자 구성 트랜잭션.id를 고유 ID로 설정해야 한다. \n이 고유 ID는 애플리케이션 재시작 시 트랜잭션 상태의 연속성을 제공하는 데 필요하다.\n\n## Kafka의 정확히 한 번 스트림 처리\n\n스트림 애플리케이션에서 정확히 한 번의 시맨틱을 보장하려면 \"processing.guarantee=exactly_once\" 구성을 설정하면 된다.\n이렇게 하면 모든 처리 작업과 해당 작업에서 생성된 모든 구체화된 상태가 Kafka에 정확히 한 번만 기록된다.\n\n그러나 정확히 한 번의 의미론은 Kafka 스트림의 내부 처리 범위에서만 보장된다.\n예를 들어, 스트림으로 작성된 이벤트 스트리밍 앱이 원격 저장소를 업데이트하기 위해 RPC 호출을 수행하거나 사용자 정의 클라이언트를 사용하여 카프카 토픽을 직접 읽거나 쓰는 경우, 이러한 외부 요소에 의한 부작용은 정확히 한 번 보장되지 않을 수 있다.\n\n\n> 이것이 바로 Kafka의 Streams API가 제공하는 정확히 한 번 보장이 지금까지 모든 스트림 처리 시스템이 제공한 가장 강력한 보장인 이유입니다. Kafka에서 읽은 데이터, Streams 앱에 의해 Kafka로 구체화된 모든 상태에서 Kafka에 다시 기록된 최종 출력으로 확장되는 스트림 처리 애플리케이션에 대해 종단 간 정확히 한 번 보장을 제공합니다. 상태를 구체화하기 위해 외부 데이터 시스템에만 의존하는 스트림 처리 시스템은 정확히 한 번 스트림 처리에 대한 약한 보장을 지원합니다. 스트림 처리를 위한 소스로 Kafka를 사용하고 오류를 복구해야 하는 경우에도 메시지를 다시 사용하고 재처리하기 위해 Kafka 오프셋을 되감기만 할 수 있지만 외부 시스템에서 연결된 상태를 롤백할 수 없으므로 상태 업데이트가 멱등성이 아닌 경우 잘못된 결과가 발생합니다.\n>\n\n스트림 처리 시스템의 핵심 질문은 \"처리 도중에 인스턴스 중 하나가 충돌하더라도 스트림 처리 애플리케이션이 올바른 결과를 얻을 수 있는가?\" 이다.\n이를 위해 스트림 처리는 카프카 토픽에서 읽기, 처리 및 쓰기 작업으로 이루어진다.\n소비자가 카프카 토픽에서 메시지를 읽어와서 처리 로직에 의해 변환하거나 상태를 수정한 후, 생산자가 결과 메시지를 다른 카프카 토픽에 기록한다.\n정확히 한 번 스트림 처리는 이러한 작업들을 정확히 한 번만 실행하는 기능을 의미한다.\n이것은 입력 메시지의 누락이나 중복된 출력이 발생하지 않도록 하는 것을 의미한다.\n이는 사용자가 스트림 프로세서에 정확히 한 번만 실행되는 동작을 기대하는 것이다.\n\n이것 외에도 고려해야 할 다른 많은 실패 시나리오가 있다.\n\n- 스트림 프로세서는 여러 소스 토픽에서 입력을 받을 수 있으며, 이러한 소스 토픽의 순서는 여러 번 실행할 때 결정적이지 않다. 따라서 여러 소스 토픽에서 입력을 받는 스트림 프로세서를 다시 실행하면 다른 결과가 나올 수 있다..\n- 마찬가지로 스트림 프로세서는 여러 대상 토픽에 대한 출력을 생성할 수 있다. 프로듀서가 여러 토픽에 걸쳐 원자 쓰기를 수행할 수 없는 경우 일부(전부는 아님) 파티션에 대한 쓰기가 실패하면 프로듀서 출력이 올바르지 않을 수 있다.\n- 스트림 프로세서는 스트림 API가 제공하는 관리 상태 기능을 사용하여 여러 입력에 걸쳐 데이터를 집계하거나 조인할 수 있다. 스트림 프로세서의 인스턴스 중 하나에 장애가 발생하면 해당 스트림 프로세서 인스턴스에서 구현된 상태를 롤백할 수 있어야 한다. 인스턴스를 다시 시작할 때 처리를 재개하고 해당 상태를 다시 생성할 수 있어야 한다.\n- 스트림 프로세서는 외부 데이터베이스에서 보강 정보를 조회하거나 대역 외로 업데이트되는 서비스를 호출할 수 있다. 외부 서비스에 의존하면 스트림 프로세서는 근본적으로 비결정적이기 때문에 스트림 프로세서가 두 번 실행되는 사이에 외부 서비스가 내부 상태를 변경하면 다운스트림에서 잘못된 결과를 초래할 수 있다.     \n\n특히 비결정적 연산 및 애플리케이션에서 계산된 영구 상태의 변경과 함께 실패 및 재시작이 발생하면 중복뿐만 아니라 잘못된 결과도 발생할 수 있다.\n예를 들어, 한 처리 단계에서 표시된 이벤트 수를 계산하는 경우, 업스트림 처리 단계에서 중복이 발생하면 다운스트림에서 잘못된 카운트가 발생할 수 있습니다. 따라서 \"정확히 한 번만 스트림 처리\"라는 문구를 한정해야 합니다. 이는 토픽에서 소비하고, 카프카 토픽에서 중간 상태를 구체화하여 하나로 생성하는 것을 의미하지만, 메시지에서 수행되는 모든 가능한 계산이 스트림 API를 사용하는 것은 아니다.\n일부 계산(예: 외부 서비스에 의존하거나 여러 소스 토픽에서 소비하는 경우)은 근본적으로 비결정적이다.\n\n> \"결정론적 연산에 대한 정확한 한 번 스트림 처리 보장을 생각하는 올바른 방법은 읽기-처리-쓰기 작업의 출력이 스트림 프로세서가 각 메시지를 정확히 한 번만 볼 때와 동일한지, 즉 오류가 발생하지 않은 경우와 동일한지를 보장하는 것입니다.”\n> \n\n## 비결정적 연산에서 정확히 한 번이란?\n예를 들어, 들어오는 이벤트의 실행 카운트를 유지하는 동일한 스트림 프로세서가 외부 서비스에서 지정한 조건을 만족하는 이벤트만 카운트하도록 수정되었다고 가정해 봅자.\n기본적으로 이 작업은 외부 조건이 스트림 프로세서를 두 번 실행하는 사이에 변경되어 다운스트림에서 다른 결과를 초래할 수 있기 때문에 본질적으로 결정론적이지 않다.\n그렇다면 이와 같은 결정론적이지 않은 연산에 대한 정확한 1회 보장은 어떻게 생각하는 것이 좋을까?\n\n\"결정론적이지 않은 연산에 대한 정확한 1회 보장을 생각하는 올바른 방법은 읽기-처리-쓰기 스트림 처리 작업의 출력이 결정론적이지 않은 입력의 합법적 값 조합에 의해 생성되는 합법적 출력의 하위 집합에 속하도록 하는 것이다\"\n\n따라서 위의 예제 스트림 프로세서의 경우, 현재 카운트가 31이고 입력 이벤트 값이 2인 경우, \n실패 시 올바른 출력은 {31, 33} 중 하나만 가능하다.\n외부 조건에 따라 입력 이벤트가 버려진 경우 31, 그렇지 않은 경우 33입니다.\n\n## 정리\n\n결과적으로, 카프카의 강력한 기본 요소에 의존하는 단순하면서도 효과적인 디자인 되었다.\n\n트랜잭션 로그는 카프카 토픽이므로 내구성이 보장된다.\n새로 도입된 트랜잭션 코디네이터는 브로커 내에서 실행되며, 장애 처리를 위해 Kafka의 리더 선출 알고리즘을 자연스럽게 활용한다.\nKafka의 Streams API로 구축된 스트림 처리 애플리케이션의 경우, 상태 저장소와 입력 오프셋의 소스가 Kafka 토픽이라는 사실을 활용하여 읽기-처리-쓰기 작업 전반에 걸쳐 정확히 한 번만 보장할 수 있다.\n\n\n## 참조\n[https://www.confluent.io/blog/exactly-once-semantics-are-possible-heres-how-apache-kafka-does-it/](https://www.confluent.io/blog/exactly-once-semantics-are-possible-heres-how-apache-kafka-does-it/)"},{"excerpt":"팩토리 패턴 구상 클래스의 인스턴스 생성 부분을 캡슐화하기 피자 인스턴스를 만드는 구상 클래스를 선택하는 부분이 상황이 변하면 코드를 변경해야 한다. 객체 생성 부분 캡슐화 하기 피자 인스턴스 생성 부분을 SimplePizzaFactory로 넘겼을 때의 장점은? 팩토리를 사용하지 않으면 피자 인스턴스를 생성하는 부분이 많아 생성하는 작업이 변경되었을 때 …","fields":{"slug":"/create/"},"frontmatter":{"date":"April 10, 2022","title":"디자인 패턴 - 생성 패턴","tags":["디자인 패턴"]},"rawMarkdownBody":"\n## 팩토리 패턴\n\n### 구상 클래스의 인스턴스 생성 부분을 캡슐화하기\n\n```java\nPizza orderPizza(String type){\n\tPizza pizz;\n\n\tif(type.equlas(\"cheese\"){\n\t\tpizza = new CheesePizza();\n\t} else if(type.equlas(\"greek\"){\n\t\tpizza = new GreekPizza();\n  } else \tif(type.equlas(\"veggie\"){\n\t\tpizza = new VeggiePizza();\n\t}\n\n\treturn pizza;\n}\n```\n\n- 피자 인스턴스를 만드는 구상 클래스를 선택하는 부분이 상황이 변하면 코드를 변경해야 한다.\n\n<!-- more -->\n\n### 객체 생성 부분 캡슐화 하기\n\n```java\npublic class SimplePizzaFactory {\n\n\tpublic Pizza createPizza(String type){\n\t\tif(type.equlas(\"cheese\"){\n\t\t\tpizza = new CheesePizza();\n\t\t} else if(type.equlas(\"greek\"){\n\t\t\tpizza = new GreekPizza();\n\t  } else \tif(type.equlas(\"veggie\"){\n\t\t\tpizza = new VeggiePizza();\n\t\t}\n\t\n\t\treturn pizza;\n\t}\n}\n```\n\n- 피자 인스턴스 생성 부분을 SimplePizzaFactory로 넘겼을 때의 장점은?\n  - 팩토리를 사용하지 않으면 피자 인스턴스를 생성하는 부분이 많아 생성하는 작업이 변경되었을 때 생성하는 모든 부분을 고쳐줘야 한다.\n\n### 클라이언트 코드 수정\n\n```java\npublic class PizzaStore {\n\n\tSimplePizzaFactory factory;\n\n\t// 생성자\n  ...\n\n\tpublic Pizza orderPizza(String type){\n\t\tPizza pizza;\n\n\t\tpizza = factory.createPizza(type);\n\n\t\tpizza.prepare();\n\t\tpizza.bake();\n\t\tpizza.cut();\n\t\tpizza.box();\n\n\t\treturn pizza;\n\t}\n}\n```\n\n### 팩토리 메서드 패턴\n\n- 요구사항이 바뀌어 피자를 각 지점마다 그 지역의 특성과 입맛을 반영한 다양한 스타일의 피자를 만들어야 된다면?\n- PizzaStore 클래스를 추상 클래스로 변경\n\n```java\npublic abstract class PizzaStore {\n\n\tpublic Pizza orderPizza(String type){\n\t\tPizza pizza;\n\n\t\tpizza = createPizza(type);\n\n\t\tpizza.prepare();\n\t\tpizza.bake();\n\t\tpizza.cut();\n\t\tpizza.box();\n\n\t\treturn pizza;\n\t}\n\nabstract Pizza createPizza(String type);\n\n}\n```\n\n- 각 지점에 맞는 서브클래스를 생성(`NYPizzaStore`, `ChicagoPizzastore`, `CaliforniaPizzaStore`)\n\n```java\npublic class NYPizzaSotre extends PizzaStore {\n\t\n\tpublic Pizza createPizza(String type){\n\t\tif(type.equlas(\"cheese\"){\n\t\t\tpizza = new NYStyleCheesePizza();\n\t\t} else if(type.equlas(\"greek\"){\n\t\t\tpizza = new NYStyleGreekPizza();\n\t  } else \tif(type.equlas(\"veggie\"){\n\t\t\tpizza = new NYStyleVeggiePizza();\n\t\t}\n\t\n\t\treturn pizza;\n\t}\n}\n```\n\n### 팩토리 메서드 패턴의 정의\n\n- 팩토리 메서드 패턴에서는 객체를 생성할 때 필요한 인터페이스를 만든다.\n- 어떤 클래스의 인서턴스를 만들지는 서브클래스에서 결정한다.\n- 팩토리 메서드 패턴을 사용하면 클래스 인스턴스 만드는 일을 서브 클래스에게 맡기게 된다.\n\n![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/76e137c9-a893-4709-9681-52da226edbc0/Untitled.png)\n\n- **Product - 생성될 객체의 인터페이스**\n- **ConcreteProduct - Product 인터페이스를 구현한 구상 클래스.**\n- **Creator - 객체를 생성하는 팩토리 메소드를 가진 인터페이스**\n- **ConcreteCreator - Creator 인터페이스를 구현한 구상 클래스.**\n\n### 의존성 역전 원칙\n\n<aside>\n💡 추상화된 것에 의존하게 만들고 구상 클래스에 의존하지 않게 만든다.\n\n</aside>\n\n- 고수준 구성 요소가 저수준 구성 요소에 의존하면 안되며, 항상 추상화에 의존하게 만들어야 한다.\n  - 변수에 구상 클래스의 레퍼런스를 저장하지 않는다.\n    - new 연산자는 구상 클래스를 사용하게 되므로 팩토리를 써서 방지\n  - 구상 클래스에서 유도된 클래스를 만들지 맙시다.\n    - 인터페이스나 추상 클래스처럼 추상화된 것으로부터 클래스를 만들어야 된다.\n  - 베이스 클래스에 이미 구현되어 있는 메소드를 오버라이드하지 않는다.\n    - 이미 구현되어 있는 메서드를 오버라이드 한다면 베이스 클래스가 제대로 추상화되지 않았다.\n    - 베이스 클래스에서 메서드를 정의할 때는 모든 서브클래스에서 공유할 수 있는 것만 정의해야한다.\n\n\n### 추상 팩토리 패턴의 정의\n\n- 추상 팩토리 패턴은 구상 클래스에 의존하지 않고도 서로 연관되거나 의존적인 객체로 이루어진 제품군을 생산하는 인터페이스를 제공합니다. 구상 클래스는 서브 클래스에서 만듭니다.\n\n![Untitled](img/img_2.png)\n\n### 팩토리 메서드 패턴과 추상 팩토리 패턴의 차이\n\n- 팩터리 메서드 패턴은 하나의 메서드가 여러 객체를 생성한다\n- 추상 팩토리 패턴은 팩터리 자체가 인터페이고 서브 클래스가 여러 객체를 생성한다.\n- 팩터리 메서드 패턴은 클라이언트와 구상 클래스를 분리시켜야할 때 사용한다.\n- 추상 팩터리 패턴은 하나의 제품군을 생성할 때 사용한다.\n  - 뉴욕지점의 제품군(Dough, Sauce, Cheese, Vaggies 등)\n  - 제품군을 합치는 부분은 클라이언트의 책임\n\n\n## 싱글톤 패턴\n\n- 싱글턴 패턴은 클래스 인스턴스를 하나만 만들고, 그 인스턴스로의 전역 접근을 제공\n\n### 고전적인 구현 방식\n\n```java\npublic class Singleton {\n\tprivate static Singleton instance;\n\n\tprivate Singleton() {}\n\n\tpublic static Singleton getInstance() {\n\t\tif(instance == null)\n\t\t\tinstance = new Singleton();\n\n\t\treturn instance;\n\t}\n}\n```\n\n- 멀티스레드 환경에서 두 스레드가 동시에 getInstance를 호출할 때 인스턴스가 2개 만들어질 가능성이 있다.\n\n### 동기화를 이용한 구현\n\n```java\npublic class Singleton {\n\tprivate static Singleton instance;\n\n\tprivate Singleton() {}\n\n\tpublic static synchronized Singleton getInstance() {\n\t\tif(instance == null)\n\t\t\tinstance = new Singleton();\n\n\t\treturn instance;\n\t}\n}\n```\n\n- synchronized 키워드를 추가하면 한 스레드가 메소드 사용을 끝내기 전까지 다른 스레드는 기다리게 된다.\n- 하지만 synchronized 키워드를 사용하면 성능이 저하되고, 객체가 생성할 시점에만 동기화가 필요한데 자원을 낭비하게 된다.\n\n### static initializer 를 이용한 구현\n\n```java\npublic class Singleton {\n\tprivate static Singleton instance = new Singleton;\n\n\tprivate Singleton() {}\n\n\tpublic static Singleton getInstance() {\n\t\treturn instance;\n\t}\n}\n```\n\n- 클래스가 로딩될 때 JVM에서 Singleton이 하나뿐인 인서턴스를 생성해준다.\n- 하지만 생성시점을 JVM에서 관리하기 때문에 lazy loading 처럼 생성시점을 컨트롤할 수가 없다.\n\n### DCL을 이용한 구현\n\n- DCL(Double-Checked Locking)을 사용하면 인스턴스가 생성되어 있는지 확인 한 다음 생성되어 있지 않을 때만 동기화할 수 있다.\n\n```java\npublic class Singleton {\n\tprivate volaile static Singleton instance;\n\n\tprivate Singleton() {}\n\n\tpublic static Singleton getInstance() {\n\t\tif(instance == null){\n\t\t\t\tsynchronized (Singleton.class) {\n\t\t\t\t\tif (instance == null) {\n\t\t\t\t\t\tinstance = new Singleton();\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t}\n\t\treturn instance;\n\t}\n}\n```\n\n### enum 을 사용한 구현\n\n```java\npublic enum Singleton {\n\tUNIQUE_INSTACE;\n}\n\npublic class SinlegonClient {\n\t\tpublic static void main(String[] args){\n\t\t\t\tSingleton singleton = Singleton.UNIQUE.INSTANCE;\n\t\t}\n}\n```"},{"excerpt":"데코레이터 패턴 OCP 살펴보기 클래스는 확장에는 열려 있어야 하지만 변경에는 닫혀 있어야 한다. 기존 코드를 변경하지 않아도 확장할 수 있어야 한다. 옵저버 패턴을 예로 들면 옵저버를 새로 추가하면 주제에 코드를 추가하지 않으면서도 얼마든지 확장이 가능하다. 모든 부분에서 OCP를 준수해야 하는가? 현실적으로도 불가능하고 OCP를 지키다 보면 추상화가 …","fields":{"slug":"/struct/"},"frontmatter":{"date":"April 07, 2022","title":"디자인 패턴 - 구조 패턴","tags":["디자인 패턴"]},"rawMarkdownBody":"\n\n## 데코레이터 패턴\n\n### OCP 살펴보기\n\n- 클래스는 확장에는 열려 있어야 하지만 변경에는 닫혀 있어야 한다.\n  - 기존 코드를 변경하지 않아도 확장할 수 있어야 한다.\n  - 옵저버 패턴을 예로 들면 옵저버를 새로 추가하면 주제에 코드를 추가하지 않으면서도 얼마든지 확장이 가능하다.\n- 모든 부분에서 OCP를 준수해야 하는가?\n  - 현실적으로도 불가능하고 OCP를 지키다 보면 추상화가 필요한데, 추상화를 하다 보면 코드가 복잡해진다.\n  - 그래서 디자인한 것 중에서 가장 바뀔 가능성이 높은 부분을 중심적으로 살펴보고 OCP를 적용하는 방법이 좋다.\n\n<!-- more -->\n\n<aside>\n💡 무조건 OCP를 적용한다면 괜히 쓸데없는 일을 하며 시간을 낭비할 수 있으며, 필요 이상으로 복잡하고 이해하기 힘든 코드를 만들게 되는 부작용이 발생할 수 있다.\n\n</aside>\n\n### 데코레이터 패턴의 정의\n\n- 데코레이터 패턴은 객체에 추가 요소를 동적으로 더할 수 있다.\n- 데코레이터를 사용하면 서브클래스를 만들 때보다 훨씬 유연하게 기능을 확장할 수 있다.\n\n![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/a1d2e1b7-7f8f-4fe6-af62-bc391740ff17/Untitled.png)\n\n- 데코레이터가 컴포넌트를 상속받는 이유\n  - 상속으로 행동을 물려받는 것은 아님\n  - 행동은 기본 구성 요소와는 데코레이터 등을 인스턴스 변수에 저장하여 호출하는 식\n  - 데코레이터로 감싸는 객체와 형식을 맞추기 위해 상속 (원래 있던 구성 요소가 들어갈 자리에 자기가 들어갈 수 있어야 하므로)\n\n### 데코레이터 패턴 구현하기\n\n```java\n// Component 클래스\npublic abstract calss Beverage {\n\tString description = \"제목 없음\";\n\t\n\tpublic String getDescription(){\n\t\treturn description;\n\t}\n\n\tpublic abstract double cost();\n}\n```\n\n```java\n// 데코레이터 클래스(첨가물 클래스)\npublic abstract class CondimentDecorator extends Beverage { // 형식을 맞추기 위해 상속\n\tBeverage beverage; // 데코레이터가 감쌀 음료를 나타냄\n\tpublic abstract String getDescription();\n}\n```\n\n#### 음료 코드 구현\n\n```java\npublic class Espresso extends Beverage {\n\t\n\tpublic Espresso()[\n\t\t\tdescription = \"에스프레소\";\n\t}\n\n\tpublic doublc cost(){\n\t\treturn 1.99;\n\t}\n}\n```\n\n```java\npublic class HouseBlend extends Beverage {\n\t\n\tpublic Espresso()[\n\t\t\tdescription = \"하우스 블렌드\";\n\t}\n\n\tpublic doublc cost(){\n\t\treturn 0.99;\n\t}\n}\n```\n\n#### 첨가물 코드 구현\n\n```java\npublic class Mocha extends CondimentDecorator {\n\n\tpublic Mocha(Beverage beverage){\n\t\tthis.beverage = beverage;\n\t}\n\n\tpublic String getDescription(){\n\t\treturn beverage.getDescription() + \", 모카\";\n\t}\n\n\tpublic double cost(){\n\t\treturn beverage.cost() + 0.2;\n\t}\n}\n```\n\n#### 테스트 코드\n\n```java\n// 하우스 블렌드 커피 + 모카 2샷 + 휩 추가\nBeverage beverage = new HouseBlend();\nbeverage = new Mocha(beverage);\nbeverage = new Mocha(beverage);\nbeverage = new Whip(beverage);\n```\n\n### 정리\n\n- 데코레이터 패턴의 의도는 감싸고 있는 객체에 행동을 추가하는 용도이다.\n- 만약 여러 단계의 데코레이터를 파고 들어가서 어떤 작업을 해야 한다면 데코레이터 패턴이 만들어진 의도와는 어긋난다.\n- 추상 구상 요소(Component) 가 아닌 특정 Concrete Component의 의존하여 어떤 작업을 해야하는 경우에는 데코레이터 패턴의 의도와는 맞지 않기 때문에 패턴 사용을 다시 생각해봐야 한다."},{"excerpt":"디자인 패턴- 행동 패턴 어떤 처리의 책임을 어느 객체에 할당하는 것이 좋은지, 알고리즘은 어느 객체에 정의하는 것이 좋은지 다룹니다. 객체들 간의 교류 방법에 대하여 정의한다. 행동 클래스 패턴 은 클래스 사이에 행동 책임을 분산하기 위해서 상속을 사용합니다. 행동 객체 패턴 은 상속보다는 복합을 통해서 객체 사이에 행동처리의 책임을 분산합니다. 전략 …","fields":{"slug":"/behavior/"},"frontmatter":{"date":"April 02, 2022","title":"디자인 패턴 - 행동 패턴","tags":["디자인 패턴"]},"rawMarkdownBody":"\n## 디자인 패턴- 행동 패턴\n\n- 어떤 처리의 책임을 어느 객체에 할당하는 것이 좋은지, 알고리즘은 어느 객체에 정의하는 것이 좋은지 다룹니다.\n- 객체들 간의 교류 방법에 대하여 정의한다.\n- **행동 클래스 패턴** 은 클래스 사이에 행동 책임을 분산하기 위해서 상속을 사용합니다.\n- **행동 객체 패턴** 은 상속보다는 복합을 통해서 객체 사이에 행동처리의 책임을 분산합니다.\n\n\n<!-- more -->\n\n## 전략 패턴\n\n![Untitled](img/img.png)\n\n- 전략 패턴(Strategy Pattern)은 알고리즘군을 정의하고 캡슐화해서 각각의 알고리즘군을 수정해서 쓸 수 있게 해준다.\n- 전략 패턴을 사용하면 클라이언트로부터 알고리즘을 분리해서 독립적으로 변경할 수 있다.\n\n### 디자인 원칙\n\n- 애플리케이션에서 달라지는 부분을 찾아내고 달라지지 않는 부분과 분리한다.\n    - 달라지는 부분을 찾아서 나머지 코드에 영향을 주지 않도록 캡슐화한다.\n    - Context 달라지지 않는 부분, Strategy 달라지는 부분ㅔ\n- 구현보다는 인터페이스 맞춰서 프로그래밍 한다.\n    - Context의 행동은 인터페이스로 정의되어 구체적으로 구현하지 않는다.\n- 상속보다는 구성을 활용한다.\n    - 전략 패턴을 쓰지 않는다면 상속을 통해 서브 클래스에서 메서드를 오버라이딩 하여 행동을 바꿀 수 있다.\n    - Super 클래스에 의존성이 발생하고 필요하지 않은 부분도 상속해야 되는 문제점이 있다.\n    - 구성(Composition)을 활용하면 시스템의 유연성을 크게 향상시킬 수 있다.\n    - 알고리즘군을 별도의 클래스 집합으로 캡슐화할 수 있으며 구성 요소로 사용하는 객체에서 올바른 행동 인터페이스를 구현하기만 하면 실행 시에 행동을 바꿀 수 있다.\n\n## 옵저버 패턴\n\n- 옵저버 패턴(Observer Pattern)은 한 객체의 상태가 바뀌면 그 객체에 의존하는 다른 객체에게 연락이 가고 자동으로 내용이 갱신되는 방식으로 일대다(One To Many) 의존성을 정의합니다.\n\n![Untitled](img/img_1.png)\n\n- Publish-Subscribe 패턴과는 다르다. Publish-Subscribe 패턴은 구독자가 서로 다른 유형의 메시지에 관심을 가질 수 있고 출판사와 구독자가 더 세세하게 분리할 수 있는 복잡한 패턴이다.\n\n### 느슨한 결합의 위력\n\n- 느슨한 결합(Loose Coupling)은 객체들이 상호작용할 수는 있지만, 서로를 잘 모르는 관계를 의미한다.\n- 주제(Subject)클래스는 옵저버가 특정 인터페이스(Observer 인터페이스)를 구현한다는 사실만 안다.\n  - 옵저버의 구상 클래스가 무엇인지, 옵저버가 무엇을 하는지는 알 필요가 업삳.\n- 옵저버는 언제든지 새로 추가할 수 있다.\n  - 주제는 Observer 인터페이스에만 의존하므로 언제든지 새로운 옵저버를 추가할 수 있다.\n- 새로운 형식의 옵저버를 추가할 때도 변경할 필요가 없다.\n  - 옵저버의 구상 클래스가 새로 생기더라도 주제 클래스는 그것을 신경 쓸 필요가 없다. Observer 인터페이스만 구현한다면 어떤 객체와도 상호작용이 가능하다.\n- 주제와 옵저버는 서로 독립적으로 재사용할 수 있다.\n  - 둘이 서로 단단하게 결합되지 않기 때문이다.\n- 주제나 업저버가 달라져도 서로에게 영향을 미치지 않는다.\n  - 구현에 의존하지 않고 인터페이스 의존하기 때문이다.\n\n<aside>\n💡 디자인 원칙   \n상호작용하는 객체 사이에는 가능하면 느슨한 결합을 사용한다.\n\n</aside>\n\n### 푸시 방식에서 풀 방식으로 바꾸기\n\n- 주제가 옵저버에게 상태를 알리는 방식(푸시)는 Observer의 `update()` 메서드의 파라미터가 변경된다면 모든 구상 옵저버 클래스의 변경이 발생한다.\n- 옵저버가 주제로부터 상태를 끌어오는 방식(풀)로 바꾼다면 옵저버가 필요한 데이터를 골라서 가져올 수 있고 쉽게 확장할 수 있다.\n\n#### 주제에서 알림 보내기\n\n- 옵저버의 update 메서드를 인자없이 호출하도록 주제 클래스의 `notifyObservers()` 메서드를 수정한다.\n\n```java\npublic void nofifyObservers(){\n\tfor (Observer observer : observers) {\n\t\tobserver.update() // 파라미터 없이 호출\n\t}\n}\n```\n\n#### 옵저버에서 알림 받기\n\n- Observer 인터페이스에서 update() 메서드의 매개변수 제거\n\n```java\npublic interface Observer {\n\tvoid update();\n}\n```\n\n- Concreate Observer 클래스의 update 메서드를 주제의 데이터를 가져오도록 수정\n\n```java\npublic void update(){\n\tthis.temperature = weatherData.getTeperature();\n\tthis.humidity = weaterData.getHumidity();\n\tdisplay();\n}\n```\n\n### 디자인 원칙\n\n- 애플리케이션에서 달리지는 부분을 찾아내고 달라지지 않는 부븐과 분리한다.\n  - 옵저버 패턴에서 변하는 것은 주제의 상태와 옵저버의 개수와 형식이다.\n  - 주제를 바꾸지 않고도 주제의 상태에 의존하는 객체들을 바꿀 수 있음\n- 구현보다는 인터페이스에 맞춰서 프로그래밍 한다.\n  - 주제는 Subject 인터페이스로 Observer 인터페이스를 구현하는 객체들의 등록과 탈퇴를 관리하고 그런 객체들에게 상태를 알린다.\n- 상속보다는 구성을 사용한다.\n  - 주제와 옵저버 사이의 관계는 상속이 아니라 구성으로 이루어진다."},{"excerpt":"@EnableAutoConfiguration Spring Boot 애플리케이션이 시작되면 spring-boot-autoconfigure 모듈에 미리 정의된 Configuration 클래스들이 자동으로 구성됩니다. (스프링 부트 자동 구성 목록) Auto Configuration이 실제 실행되는지 여부는 클래스 경로에 종속 클래스가 있는지 여부에 따라 달라…","fields":{"slug":"/spring-autoconfigure/"},"frontmatter":{"date":"March 28, 2022","title":"SpringBoot AutoConfiguration 시작하기","tags":["스프링"]},"rawMarkdownBody":"\n## @EnableAutoConfiguration\n\nSpring Boot 애플리케이션이 시작되면 spring-boot-autoconfigure 모듈에 미리 정의된 Configuration 클래스들이 자동으로 구성됩니다. ([스프링 부트 자동 구성 목록](https://docs.spring.io/spring-boot/docs/current/reference/html/auto-configuration-classes.html#appendix.auto-configuration-classes))\n\nAuto Configuration이 실제 실행되는지 여부는 클래스 경로에 종속 클래스가 있는지 여부에 따라 달라집니다.\n\n예를 들어, `@ConditionalOnClass` 는 클래스 패스에 특정 class가 존재할 때만 조건이 만족됩니다.\n\n<!-- more -->\n\n## Custom AutoConfiguration Starter 만들기\n\n### 1.  [application.properties](http://application.properties) 파일의 사용자 정의 속성\n\n```java\n@Data\n@Component\n@ConfigurationProperties(prefix = \"custom\")\npublic class CustomProperties {\n\tprivate String message;\n\tprivate String url;\n}\n```\n\n@ConfigurationProperties의 접두사와 클래스 필드 이름은 [application.properties](http://application.properties) 와 맵핑됩니다.\n\n```jsx\ncustom.message = hello world\ncustom.url = localhost\n```\n\n### 2.  라이브러리용 빈 만들기\n\n```java\n@Slf4j\n@RequiredArgsConstructor\npublic class CustomService implements InitializingBean {\n\n\tprivate final CustomProperties customProperties;\n\n\t@Override\n\tpublic void afterPropertiesSet() throws Exception {\n\t\tlog.info(\"CustomService init\");\n\t\tlog.info(\"message : {}\", customProperties.getMessage());\n\t\tlog.info(\"url : {}\", customProperties.getUrl());\n\t}\n}\n```\n\n### 3. AutoConfiguration\n\n```java\n@Configuration\n@EnableConfigurationProperties(CustomProperties.class)\npublic class CustomAutoConfiguration {\n\n\t@Bean\n\tpublic CustomService customService(CustomProperties customProperties){\n\t\t\treturn new CustomService(customProperties);\n\t}\n}\n```\n\n### 4. spring.factories 파일 추가\n\n`src/main/resources/META-INF` 경로에 다음 내용을 추가합니다.\n\n```java\norg.springframework.boot.autoconfigure.EnableAutoConfiguration=\\\ncom.example.autoconfigure.configure.CustomAutoConfiguration\n```\n\n### 5. AutoConfiguration 사용\n\n스타터를 사용할 프로젝트를 만들고 pom.xml에 종속성을 추가합니다.\n\n```java\n<dependency>\n      <groupId>com.example</groupId>\n      <artifactId>auto-configure</artifactId>\n      <version>0.0.1-SNAPSHOT</version>\n</dependency>\n```\n\n[application.properties](http://application.properties) 파일에 사용자 정의 속성을 정의하고 프로젝트를 시작하면 다음과 같이 빈이 초기화되는 것을 볼 수 있습니다."},{"excerpt":"1. 기본 방향 프로그램 단위에서 접근하는 경우 아래의 6가지 접근법만 이해하면 여러 성능 개선 항목을 도출할 수 있다. 중복 수행 제거 불필요한 수행 제거 최적 수행 필요 이상으로 많은 데이터 건수를 조회하는가? 조회한 항목은 다 사용하는 값인가? 조회하는 항목은 모두 사용자에게 보여줘야 하는가? 업므 데이터의 성격상 쿼리를 개선할 부분이 있는가? 데이…","fields":{"slug":"/ch7/"},"frontmatter":{"date":"March 16, 2022","title":"7부 - 애플리케이션 입장에서의 SQL 튜닝","tags":["실무로 배우는 시스템 성능 최적화"]},"rawMarkdownBody":"\n## 1. 기본 방향\n\n- 프로그램 단위에서 접근하는 경우 아래의 6가지 접근법만 이해하면 여러 성능 개선 항목을 도출할 수 있다.\n  - 중복 수행 제거\n  - 불필요한 수행 제거\n  - 최적 수행\n    - 필요 이상으로 많은 데이터 건수를 조회하는가?\n    - 조회한 항목은 다 사용하는 값인가?\n    - 조회하는 항목은 모두 사용자에게 보여줘야 하는가?\n    - 업므 데이터의 성격상 쿼리를 개선할 부분이 있는가?\n    - 데이터 검색 범위는 적절한가?\n  - 수행 통합\n    - 주종 관계로 수행되는 쿼리를 한 개의 쿼리로 통합할 수 있는가?\n    - 상관관계는 없으나 DB 호출을 줄이기 위해 쿼리를 합칠 수 있는가?\n  - 집합 처리\n    - 여러 건 처리 시 입력/수정/삭제를 건별로 처리하고 있는가?\n    - 데이터 처리 단위는 적절한가?\n  - 트랜잭션 처리\n\n<!-- more -->\n  \n## 2. 중복 SQL 수행 제거\n\n- CBC(Component Based Developmnet) 기반 개발이 보편화되어 재활용성과 유지보성은 좋아졌지만 기초 정보가 동일한 조건으로 반복적으로 호출되는 경우가 빈번하게 발생한다.\n- **빈번한 유효성 검증**\n  - 컴포넌트 단위로 안정성과 정합성이 유지될 수 있도록 모듈 단위로 입력 값에 검증을 추가로 수행하는 것이 일반화되어 검증이 반복적으로 수행된다.\n- 동일 SQL/모듈의 반복 호출\n  - 상부와 하부 컴포너트 간 호출 빈도나 쓰임새를 고려하지 않고 모든 컴포넌트가 동일한 방식으로 개발되어 SQL/모듈이 한 프로그램 내에서 많게는 수십에서 수천 까지 반복 호출되는 문제를 유발한다.\n- 불필요한 기능 수행\n  - 모듈이 범용화되는 과정을 거치게 되는데, 이로 인해 한 모듈이 여러 서비스에서 필요로 하는 다양한 정보를 제공하려는 경향이 있다.\n\n### 2.1 애플리케이션 캐시의 종류\n\n#### 2.1.1 블록 캐시\n\n- 블록 캐시는 애플리케이션의 특정 블록(함수) 내에서 SQL 중복 수행을 제거하나 처리 결과 중간 값을 저장하는 등의 목적으로 사용하는 캐시다.\n- 데이터 저장소가 함수 내 로컬 변수로 선언되어 해당 블록 내에서만 유효하다는 특징이 있다.\n- 특정 함수 내에서 for/while 문으로 여러 개의 데이터를 처리할 때 유용하다.\n- 저바의 경우 데이터 저장소로 HashMap을 많이 사용한다.\n- 필요할 때마다 건별로 조회하지 않고 필요 데이터를 한 번에 캐시를 만든 후 while이나 for 문 안에서 참조할 때 캐시에서 찾음으로써 DB 호출을 제거한다.\n\n#### 2.1.2 요청 캐시\n\n- 요청 캐시는 사용자 요청 서비스가 시작되어 종료될 때까지 유지되는 캐시다.\n- 서비스 요청이 들어와 애플리케이션이 시작될 때 캐시가 초기화되어 비어 있고 애플리케이션이 종료될 때 캐시가 지워져 사라지는 구조로 사용자 서비스 간에는 데이터가 공유되지 않는다.\n- 자바의 경우 캐시가 ThreadLocal이나 서비스 컨텍스트에 위치하게 한다.\n- 서비스 시작과 종료 시 캐시가 프레임워크에서 자동으로 초기화 및 삭제된다.\n- 고객관리 시스템에서는 고객 기본정보 조회가 한 서비스 내에서 반복 호출되는 경우가 있는데 기존에 조회된 데이터가 없으면 DB를 조회해 캐시한 후 내보내고, 이미 조회된 데이터가 있으면 캐시된 데이터를 내보낸다.\n\n#### 2.1.3 사용자 세션 캐시\n\n- 시스템에 접속한 사용자 세션 단위로 캐시를 가지는 구조로서, 접속한 사용자에 대한 기초 데이터를 보관해서 DB 조회를 최소화하는 방식이다\n\n#### 2.1.4 프로세스 캐시\n\n- WAS 인터턴스 단위 내에서 공유되는 식으로 프로세스 내에서 처리되는 모든 서비스 요청이 캐시를 공유해서 사용한다.\n- 프로세스 단위로 공유되므로 자바의 싱글턴 구조로 구현된다.\n- 빈번하게 사용되는 코드성 테이블에 대한 DB 조회를 최소화하기 위해 많이 사용된다.\n\n#### 2.1.5 프로세스간 공유 캐시\n\n- 프로세스 단위로 캐시를 구성하는 경우 시스템 전체로 봤을 때 동일한 데이터가 여러 개의 프로세스에 캐시되어 메모리 중복 손실이 발생하고, 힙을 대량으로 사용하면 GC에 악영향을 미치게 된다.\n- 자바 메모리의 한계를 극보하기 위해 메모리 캐시 전용 솔류션이 사용되고 있는데 대표적으로 Redis가 있다.\n\n#### 2.1.6 캐시 특성 분류\n\n### 2.2 요청 캐시 구현\n\n### 2.3 캐시 적용\n\n## 3. 불필요한 SQL 수행 제거\n\n- 공통 모듈을 사용하거나 서로 다른 개발자가 개발한 모듈을 사용한 애플리케이션의 경우 로직과 수행 SQL은 최적화가 안되는 경우가 많다.\n  - 특정 컬럼만 조회하면 되지만 공통 모듈의 무거운 쿼리를 사용해서 조회하는 경우\n\n## 4. 최적 수행\n\n### 4.1 Rownum 추가\n\n- DB에는 한 번에 보내는 레코드 건수를 설정할 수 있는데 이를 Fetch 크기라고 한다.\n- Fetch size가 크면 DB와 애플리케이션 간의 턴을 줄일 수 있지만, 필요한 데이터보다 더 많은 데이터를 가져올 수 있다.\n\n### 4.2 파티션 키 추가\n\n- 파티션 테이블은 배치 메인 쿼리의 경우 전체 테이블 탐색 범위를 줄이기 위해 사용하고 입력에서는 부하분산 등 성능 목적으로 사용하며, 대량 데이터를 관리하는 목적으로 주로 사용한다.\n- 파티션 테이블이 글로벌 인덱스를 사용하는 경우 주기적으로 보관연한이 지난 파티션을 제거하게 되면 글로벌 인데그삭 사용불가 상태로 바뀐다.\n- 이 같은 상황을 방지하기 위해 파티션 테이블을 사용할 때는 가급적 로컬 인덱스를 사용하는 것을 기본으로 하고, 단지 로컬 인덱스로 성능 목표를 달성하지 못하는 경우에만 글로벌 인덱스를 사용하는 것을 고려한다.\n- 파티션 키가 Where 조건에 없다면 모든 파티션 테이블을 순차적으로 조회하는 것과 동일한 성능 저하가 발생할 수 있으므로 어떤 식으로든 파티션 키가 Where 조건에 포함될 수 있게 한다.\n\n### 4.3 조회 항목 사용 여부(테이블 조인 제거)\n\n- 공통으로 사용하는 쿼리는 최대한 많은 컬럼을 조회해서 제공하려 한다.\n- 조회하는 컬럼을 줄이는 것도 의미가 있지만 테이블의 조인을 제거하것도 효과적이다.\n\n## 5. 쿼리 통합\n\n- 쿼리 통합은 Select에 대한 집합 처리를 의미한다.\n- 여러 번 수행하는 쿼리를 한 번에 수행해 성능을 개선하는 것이다.\n\n### 5.1 메인/서브 쿼리\n\n### 5.2 병렬 쿼리 통합\n\n- 고객 통합정보 조회 하면을 떠올려 보자.\n  - 기본정보, 결제이력, 카드 보유 개수, 마케팅 대상 등등..\n  - 20~30개의 쿼리가 순차적으로 수행되는 구조가 된다.\n- 이런 경우에는 Union all이나 일대일 조인 형태로 하나의 쿼리로 통합하면 DB 호출 횟수가 줄어들어 성능 개선이 가능하다.\n\n## 6. DB 집합 처리\n\n- 10건의 데이터를 개별적으로 입력한다면 애플리케이션 서버와 DB 서버 간 애플리케이션 턴도 10회 생기고 SQL 실행과 결과도 10회 발생한다.\n- 집합 처리는 애플리케이션 턴 1회에 10건의 데이터를 모두 전송함으로서 성능 개선 효과가 있다.\n  - 단건 처리 (`PreparedStatement.excuteUpdate()`)\n  - 집합 처리 (`PreparedStatement.addBatch()`,`PreparedStatement.executeBatch()`)\n- 집합 처리를 수행할 때 수십만 건씩 처리하면 자바 힙 메모리가 부족해지는 현상이 발생해지므로 최대 만 건 이내로, 일반적으로는 천 건 단위로 수행한다.\n\n## 7. 트랜잭션 처리\n\n- 동일한 레코드를 Update 하는 서비스가 있다고 할 때, Update 문의 위치가 응답시간에 영향을 미친다.\n- 락을 흭득하는 위치가 트랜잭션 중간이면 다른 트랜잭션이 락을 대기하는 시간이 늘어나기 때문에 트랜잭션의 마지막에 위치하는게 좋다.\n\n## 8. 기타\n\n### 8.1 복합적인 기능을 수행하는 쿼리 제거\n\n- 복합 기능 쿼리란 하나의 쿼리에 1개 이상의 기능이 담긴 쿼리를 말한다.\n- 복합 기능 쿼리에서 성능 저하가 발생하는 이유는 DB에서 쿼리가 바인드 변수 값에 따라 실행될 때마다 실행계획을 수립하는 것이 아니라 최초 실행 시 실행계획을 수립하고 이후에는 기존 실행계획을 재사용하기 때문이다.\n- 쿼리 한 개는 한 개의 실행계획만 가지고 있어 다양한 입력 조건에 맞게 실행계획을 수립할 수 없다.\n- Union all 을 이용해서 쿼리를 분리하면 하나의 실행계획으로 안정적인 성능을 기대할 수 있다.\n\n### 8.2 스칼라 서브 쿼리 사용 시 주의사항\n\n- Select 절에 사용된 쿼리를 스칼라 서브 쿼리라고 한다.\n- 스칼라 서브 쿼리를 사용하는 것은 많은 경우에 있어서 나쁜 성능을 보이기 때문에 Where 조건이 분산도가 좋은 인덱스를 사용하고 전체 쿼리 결과가 소량인 경우에만 사용한다.\n\n### 8.3 페이징 처리\n\n- 페이징 처리 시, 다음과 같은 이유로 테이블을 전체 범위 처리함하면 성능 저하게 발생한다.\n  - 전체 건수/페이지 수의 표시 문제\n    - 무의미한 전체 건수 표시 제거\n    - 변경이 적은 목록은 전체 건수 및 페이지 수를 초기에만 생성 후 재사용\n  - Order By 이용한 목록 정렬 문제\n    - Order By 순서와 일치하는 페이징 인덱스를 생성해서 사용\n    - 페이징 인덱스 컬럼 값을 페이지 이동 시 다음 키값으로 사용\n  - 분산도가 좋은 필수 입력항목 부재\n    - 분산도가 좋은 입력항목을 지정하고, 기본값 설정\n\n\n## 9. 배치 성능 개선\n\n- 배치는 DB에서 처리 대상을 추출하는 메인리더 부분과 프로세싱하는 부분, 처리 결과를 DB에 기록하는 부분으로 나뉜다.\n\n### 9.1 전체 테이블 탐색\n\n- 메인리더가 수만 건 내외의 소량건을 조회해서 처리한다면 테이블 인덱스를 사용하는 것이 효과적이지만 수만 건 이상 조회해야 한다면 테이블 전체를 읽어서 조회하는 편이 성능이 좋은 경우가 많다.\n- 인덱스를 사용하면 읽는 블록수가 상대적으로 적어지지만 응답시간이 늦어진다.\n  - 그 이유는 인덱스 탐색은 인덱스를 읽어 조건에 맞는 레코드를 한 건 한건을 순차적으로 읽는 랜덤엑세스가 이뤄지는 반면 전체 테이블 탐색은 멀티블록 읽기 설정에 따라 여러 블록을 한번에 읽어 들일 수 있다.\n\n### 9.2 파티션\n\n- 대량 건을 조회할 때 전체 테이블 탐색이 성능이 우수하다고 하지만 사이즈가 커질 수록 부담스러운 작업이다.\n- 이 같은 상황에서 해결책으로 고려해볼 수 있는것이 파티션이다.\n- Where 조건에 파티션의 범위를 지정한다면 전체 탐색을 하더라도 지정된 파티션 범위 내에서만 전체 탐색이 발생한다.\n\n### 9.3 해시 조인\n\n- 테이블 조인에서 조회하는 건수가 소량이고 모든 테이블에 적절한 인덱스가 존재한다면 내포 조인이 가장 효과적이다.\n- 대량 건을 조회한다면 내포 조인대신 해시 조인을 사용하는 것이 성능상 유리하다.\n\n### 9.5 쿼리 통합\n\n#### 9.5.1 메인리더와 건별 처리 쿼리 통합\n\n- 메인리더에서 읽은 데이터를 기반으로 건별 처리 로직에서 부가 정보를 획득하거나 확인을 위해 추가 쿼리를 수행하는 경우가 많은데 메인리더와 통합하면 성능 개선효과가 있다.\n\n#### 9.5.2 메인리더와 Insert 통합\n\n- 건별로 조회하해 데이터를 처리하는 것이 가장 느리다.\n- 1000건씩 Fetch 하여 집합 처리(batch)를 활용한다면 더 빠를 것 이다.\n- 마지막으로 시도해볼 수 있는 방법은 `Insert ... Select` 구문을 사용하는 것이다.\n- 사실상 애플리케이션으로 처리 데이터가 오지 않고 전부 DB 내부에서 처리하는 것 이다.\n\n#### 9.5.3 Select / Insert / Update 통합\n\n- 오라클에서는 `Merge`를 통해 Select Insert Update 쿼리를 통합할 수 있다.\n- Mysql에서는 `ON DUPLICATE KEY` 로 통합할 수 있다.\n"},{"excerpt":"1. 기본 방향 SQL 튜닝 시 중점적으로 점검할 항목 통계 최적 실행계획이 수립되도록 테이블 통계 정보가 존재하고 주기적으로 갱신되는가? 인덱스 적절한 인덱스를 사용하는가? 인덱스가 있음에도 사용하지 못하는가? 인덱스 수가 많아서 INSERT 처리 시간이 오래걸리는가? 조인 처리하는 데이터 양과 연결 관계에 맞는 조인 방식이 선정됐는가? 조인 관계에서 …","fields":{"slug":"/ch6/"},"frontmatter":{"date":"March 13, 2022","title":"6부 - SQL 최적화","tags":["실무로 배우는 시스템 성능 최적화"]},"rawMarkdownBody":"\n## 1. 기본 방향\n\n- SQL 튜닝 시 중점적으로 점검할 항목\n  - 통계\n    - 최적 실행계획이 수립되도록 테이블 통계 정보가 존재하고 주기적으로 갱신되는가?\n  - 인덱스\n    - 적절한 인덱스를 사용하는가?\n    - 인덱스가 있음에도 사용하지 못하는가?\n    - 인덱스 수가 많아서 INSERT 처리 시간이 오래걸리는가?\n  - 조인\n    - 처리하는 데이터 양과 연결 관계에 맞는 조인 방식이 선정됐는가?\n    - 조인 관계에서 선행 테이블은 적합한가?\n  - 테이블\n    - 데이터 수정과 삭제로 테이블 조각화가 발생해 재구성할 필요는 있는가?\n    - 파티션으로 INSERT 부하를 분산해 성능 개선이 가능한가?\n\n<!-- more -->\n\n## 2. SQL 을 위한 기본 지식\n\n### 2.1 데이터베이스의 기본 구조\n\n- **클라이언트**\n  - 클라이언트는 DB 솔루션에서 제공하는 클라이언트 모듈을 통해 데이터베이스에 저장된 데이터를 조회하거나 수정할 수 있는 기능을 제공한다.\n  - 클라이언트 측면에서 중요 개선 사항\n    - 복구 건의 레코드를 한번의 호출로 집합 처리하거나 두 개 이상의 쿼리를 통합 처리함으로써 DB 호출 수를 줄인다.\n    - JDBC Statement를 캐시하거나 SQL 커서를 오픈한 상태로 유지함으로써 쿼리 소프트 파싱을 회피해 성능을 개선할 수 있다.\n    - 패치 크기(Fetch Size)를 증가시켜 DB 엔진에서 클라이언트로 조회된 데이터를 전송 할 때 한번에 많은 데이터를 전송함으로써 성능을 개선할 수 있다.\n\n- **데이터베이스 엔진**\n  - 엔진은 클라이언트 요청을 받아 파일시스템에 저장된 데이터를 조회하거나 수정하는 기능을 수행한다.\n  - 엔진 내부에는 락 관리와 트랜잭션 관리가 이뤄진다.\n  - 데이터베이스 엔진은 처리 성능 개선을 위해 동작에 필요한 기초 정보와 파일시스템에 저장된 데이터 중 일부를 메모리에 캐시하고 있어 큰 메모리를 필요로 한다.\n\n- **데이터베이스 엔진 메모리의 주요 용도**\n  - 데이터 캐시\n    - 파일시스템에 저장된 데이터가 조회되면 해당 데이터를 메모리 데이터 캐시에 저장해 이후 동일 데이터 조회 시 파일 시스템의 물리적인 입출력이 발생하지 않게 한다.\n  - 실행계획\n    - SQL이 처음 호출되면 대상 데이터를 찾는 방법이 기술돼 있는 실행계획을 만들고 이후 동일한 SQL이 수행되면 기존에 만들어진 실행계획을 재사용한다.\n  - DB 정보\n    - 테이블 구성 정보(메타 정보)와 통계를 저장하고 있으면서 SQL을 검증하고 실행계획을 수립할 때 참조한다.\n  - 복구 로그\n    - 복구 로그는 데이터 변경 전후 내역을 모두 저장해 데이터베이스에 장애가 발생했을 때 데이터를 복구하는 용도로 사용한다.\n\n- **데이터베이스 서버 성능 개선을 위해서는 아래 사항에 유의해야 한다.**\n  - 데이터 캐시는 클수록 성능 개선 효과가 있지만 개선 효과가 메모리 크기에 비례해서 증가하지는 않는다. 어느 수준이상 증가하면 개선 효과가 감소되는 커브 곡선을 그리므로 캐시 적중률을 참고해서 적당한 크기를 찾아야 한다.\n  - 바인드 변수를 사용하지 않으면 SQL의 조회 조건 값이 달리질 때마다 엔진은 서로 다른 SQL로 인식해 새로운 실행계획을 세우는 하드 파싱이 발생한다.\n  - 테이블과 인덱스 전체 블록 개수, 데이터 건수, 항목별 선택도, 인덱스 현황 등 통계 정보를 기반으로 실행계획을 수립하는데 통계 정보가 없거나 오래되어 실제 데이터 분포와 다른 경우 잘못된 실행계획이 수립되어 성능 저하를 유발할 수 있다.\n\n- **파일 시스템(저장)**\n  - 데이터 조회 시 물리적 IO가 발생하므로 데이터베이스 구조에서 가장 느린 부분이다.\n\n\n### 2.2 블록 단위 처리\n\n- 데이터베이스의 저장 구조는 데이터베이스, 테이블스페이스, 세그먼트, 익스텐트, 블록순으로 계층 관계를 이루고 있다.\n- 불록은 데이터 IO의 가장 작은 단위이며, 할당할 수 있는 최소 단위이기도 하다.\n- SELECT를 실행했을 때 읽은 블록이 많다는 것은 레코드를 찾는 과정이 불합리하다는 것을 의미한다.\n- SQL 튜닝을 간단하게 정의하면 읽는 블록 수를 줄여주는 것이다.\n\n### 2.3 캐시 IO 대 물리 IO\n\n- 데이터베이스 구조에서 성능에 가장 영향을 주는 부분은 파일시스템에서 발생하는 물리IO다.\n- 물리 IO가 주로 발생하는 쿼리인데 캐시로 인해 빠르게 조회되어 대상에서 제외될 수도 있다.\n  - 읽은 블록 수가 많다면 줄일 수 있는 방안을 강구하는 것이 먼저다.\n\n## 3. 성능 개선 대상 식별\n\n### 3.1 SQL 수행 통계\n\n### 3.2 실행 중인 세션 상태\n\n### 3.3 수행 중인 SQL의 수행 상태 확인\n\n### 3.4 락 대기\n\n### 3.5 AWR 보고서\n\n### 3.6 StatsPack\n\n## 4. SQL 실행계획\n\n### 4.1 SQL 실행계확과 수행 결과\n\n#### 4.1.1 SQL 실행계획 보기\n\n#### 4.1.2 SQL 수행 결과 확인\n\n### 4.2 실행계획의 이해\n\n- 실행계획이란 옵티마이저가 특정 SQL을 실행하기 위해 수행할 일련의 동작을 트리형식으로 표현한 계획이다.\n\n#### 4.2.1 조인\n\n- 기본 조인 방식으로는 내포 조인, 해시 조인, 병합 조인, 스타 조인이라는 방식이 있다.\n- **내포 조인(Neated loops join)**\n  - 선행 테이블과 후행 테이블을 오가며 반복적으로 탐색해서 원하는 레코드를 찾는다.\n  - 선행 테이블에서 탐색된 레코드 건수만큼 후행 테이블의 랜덤 엑세스 탐색이 일어난다.\n  - 즉, 선행 테이블의 조회 건수가 조인의 전체 작업량을 좌우한다.\n  - 선행 테이블과 연결고리가 되는 후행 테이블의 조인 항목은 꼭 인덱스가 있어야 한다.\n  - 연골고리에 인덱스가 없는데 내포 조인이 사용되면 후행 테이블에 전체 범위 탐색(Full Scan)이 발생한다.\n- **병합 조인(Merge join)**\n  - 조인되는 두 테이블의 연결고리가 되는 항목에 대한 인덱스가 없거나 대량 데이터를 처리하는 경우 내포 조인에서 발생하는 후행 테이블의 랜덤 엑세스를 제거하기 위해 사용하는 조인 방식이다.\n  - 조인되는 두 테이블은 조인에 앞서 대상 데이터를 줄이기 위해 각 테이블에 대한 WHERE 조건으로 레코드를 먼저 모두 조회한 후에 연결고리가 되는 항목을 기준으로 정렬한다.\n  - 양쪽에 정렬된 레코드를 순차적으로 비교해 가면서 연결고리가 일치하는 레코드를 찾는다.\n  - 선후행 테이블 어느 것이 되든 상관없다.\n  - 정렬된 데이터를 조인하는 작업은 효과적이지만 정렬을 해야하는 부담이 있다.\n- **해시 조인(Hash join)**\n  - 선행 테이블에서 조인에 앞어 전체 범위 탐색으로 조인 대상 레코드를 모두 조회해서 연결고리인 항목에 대해 해시 맵을 만든다.\n  - 그리고 후행 테이블은 내부 탐색 조건에 일치하는 레코드를 찾았을 때마다 해시 연산을 통해 해시 맵에 일치하는 레코드가 있는지 비교해서 조인을 수행한다.\n  - 선행 테이블은 한 번에 전체 범위 탐색으로 데이터를 추출하고 후행 테이블은 순차적으로 부분 범위 탐색하므로 부분 범위 처리가 이뤄진다.\n  -\n\n#### 4..2 SQL 실행계획의 동작\n\n### 4.3 인덱스\n\n#### 4.3.1 인덱스 구조\n\n- 인덱스는 루트, 브랜치, 리프 블록으로 구성된다.\n\n#### 4.3.2 인덱스 종류\n\n#### 4.3.3 인덱스 사용 원칙\n\n- **인덱스 생성 원칙**\n  - 1순위는 테이블의 기본 키다. 기본 키는 가장 빈도가 높은 테이블 엑세스 경로다.\n  - 2순위는 테이블 간 연결고리로 사용되는 조인 항목 그룹이다. 온라인 SQL은 대부분 내포 조인을 사용하는데 후행 테이블의 연골고리에 인덱스가 없으면 성능에 치명적이다.\n  - 3순위는 테이블 액세스 경로 상에 빈번하게 관찰되는 항목의 그룹이다. 항목 그룹은 해당 테이블을 조회하는 모든 SQL의 조회 조건에 사용된 항목들의 모임을 나열해서 그룹핑했을 때 가장 빈번하게 나타나느 항목 모임이다.\n  - 인덱스를 만들 때는 선행 항목이 중요하다. 조회 조건에 선행 항목이 없으면 인덱스를 사용하지 못한다.\n  - BETWWEN, < > 등 범위를 지정하는 조건이 주로 주어지는 항목은 결합 인덱스에서 일치(=) 조건 항목 이후에 위치하도록 구성해야 인덱스 탐색 범위를 줄일 수 있다.\n- 조회 조건에 쓰인 항목에 인덱스가 있는데도 아래와 같은 경우는 인덱스를 사용하지 못한다.\n  - 항목 변형 (`SUBSTR`, `VALUE * 10`)\n  - NULL 사용 (`VALUE IS NULL`)\n  - 부정 표현 (`VALUE ≠ null`)\n  - 앞 % 사용 (`VALUE LIKE = ‘%ABC’`)\n  - 내부 형변환 (`NUMBER_VALUE = ‘1000’`)\n\n\n#### 4.3.4 인덱스 탐색 방식\n\n- **인덱스 유일 탐색(Index Unique Scan)**\n  - 인덱스를 구성하는 모든 항목이 WHERE 절에 일치(=) 조건으로 들어왔을 때 레코드 한건을 찾아가는 탐색으로 가장 빠르다.\n- **인덱스 범위 탐색(Index Range Scan)**\n  - 인덱스의 일정한 범위를 읽어내는 인덱스 범위 탐색이다.\n  - 한 개의 항목으로 구성된 일반 단일 인덱스가 있을 때 해당 항목이 WHERE 절에 일치 조건으로 있더라도 인덱스 탐색 방식은 범위 탐색을 수행한다. (유니크 인덱스가 아니기 때문에 동일한 레코드가 있을 수 있다)\n- **인덱스 전체 탐색(Index Full Scan)**\n  - 테이블 전체 탐색과 마찬가지로 인덱스를 순차적으로 처음부터 끝까지 읽어들이는 탐색 방식이다.\n- **인덱스 고속 전체 탐색(Index Fast Full Scan)**\n  - 고속 전체 탐색은 멀티 블록 IO로 순서에 관계없이 인덱스 전체를 탐색한다. 병철 처리를 할 수 있다는 점도 차이점이다.\n- **인덱스 스킵 탐색(Index Skip Scan)**\n  - 일반적으로 결합 인덱스의 선행 항목이 WHERE 절에 없으면 해당 인덱스를 사용하지 않는다.\n  - 그러나 선행 항목의 선택도 값이 커서 유일한 값의 종류가 소수일 때는 인덱스를 사용해 탐색하는 것이 테이블 전체 탐색보다 효율적인 경우가 있다.\n\n\n#### 4.3.5 인덱스 수와 성능\n\n- 인덱스 수가 증가하면 INSERT나 UPDATE 처럼 데이터를 변경하는 DML에는 성능 저하가 발생한다.\n- 데이터 입력이 거의 없는 테이블은 인덱스를 추가하는 데 부담이 없으나 입력이 빈번한 거래 로그나 업무 처리용 테이블은 제약받을 수 밖에 없다.\n\n### 4.4 테이블\n\n- 테이블에서 데이터를 읽는 방식에는 두 가지가 있다.\n  - 인덱스 탐색을 통해 대상 레코드를 바로 찾아가서 읽는 방법\n  - 전체 테이블을 읽어서 대상 레코드를 필터링해서 찾는 방법 (Table Full Scan)\n-\n\n#### 4.4.1 Direct-Path와 Conventional-Path\n\n#### 4.4.2 파티션 테이블\n\n- 대용량 데이터베이스의 경우 한 테이블에 존재하는 레코드가 수십억 건을 저장하기도 한다.\n- 데이터가 분산돼 있어 조회 시 데이터 탐색 범위가 넓어져 성능 저하가 발생한다.\n- 이러한 문제를 해결하기 위해 데이터베이스는 관리와 조회 시에 중요한 역활을 담당하는 특정 컴럼을 기준으로 여러 개의 테이블로 나눠서 레코드를 저장, 관리하는 파티션이라는 기능이 있다.\n- 논리적으로는 하나의 테이블이지만 파티션 키 값에 따라 물리적으로 수 개에서 수천 개에 이르는 테이블을 나눠서 저장하게 된다.\n\n"},{"excerpt":"1. 기본 방향 소스코드 최적화 분석 시 중점적으로 체크할 항목 단순 정보성 로깅을 하는 부분이 있는가? 로깅을 하지 않을 때 로깅을 위한 문자열이나 데이터가 만들어지고 있는가? 전문 파싱이나 환경설정 로딩과 같은 작업이 반복 수행되는가? 락 범위를 최소화하거나 락을 회피할 수 있는가? 집합 데이터에 대한 검색 방식은 적절한가? 문자열 처리에 오버헤드가 …","fields":{"slug":"/ch5/"},"frontmatter":{"date":"February 20, 2022","title":"5부 - 소스코드 최적화","tags":["실무로 배우는 시스템 성능 최적화"]},"rawMarkdownBody":"\n## 1. 기본 방향\n\n- 소스코드 최적화 분석 시 중점적으로 체크할 항목\n  - 단순 정보성 로깅을 하는 부분이 있는가?\n  - 로깅을 하지 않을 때 로깅을 위한 문자열이나 데이터가 만들어지고 있는가?\n  - 전문 파싱이나 환경설정 로딩과 같은 작업이 반복 수행되는가?\n  - 락 범위를 최소화하거나 락을 회피할 수 있는가?\n  - 집합 데이터에 대한 검색 방식은 적절한가?\n  - 문자열 처리에 오버헤드가 존재하는가?\n  - 반복 처리 로직이 존재하는가?\n  - 기능이 단순한 함수이지만 호출 횟수가 많아 성능에 영향을 미치고 있는가?\n  - 영업일, 계정과목, 공통코드 같은 소량 테이블에 빈번한 조회가 발생하는가?\n  - 배치 같은 경우 결과가 한정적인 데이터에 대한 반복조회가 많이 있는가?\n  - 포털 화면에서 보여지는 게시물 목록 같은 것을 캐시할 수 있는가?\n  - 프로그램 흐름상 병목이 존재하는가?\n  - 대량건 조회는 가능한가?\n  - 송수신 전문 포맷과 크기는 시스템 특성과 네트워크 환경에 적합한가?\n  - 한 서비스 내에서 연계 시스템과 빈번하게 통신하는가?\n\n<!-- more -->\n\n## 2. 불필요한 작업 제거\n\n### 2.1 로깅\n\n- 로그는 시스템 관리자와 개발자에게 수행된 프로그램에 대한 추가 정보를 제공하기 위해 있는 것이지 로그가 있느냐 여부가 핵심 기능에 영향을 주는 것은 아니다.\n\n#### 2.1.1 잘못 사용된 로깅 수준\n\n- Log4J의 경우 `전체(ALL)`, `추적(Trace)`, `디버그(Debug)`, `정보(info)`, `경고(Warn)`, `에러(Error)`, `심각(Fatal)`, `끄기(Off)`라는 8가지 수준이 제공된다.\n- 운영 시에는 경고, 에러 수준으로 로깅을 설정한다.\n  - 운영 시스템의 로그 수준이 디버그로 낮게 설정돼 있으면 로깅을 위한 오버헤드 코드와 파일 입출력 병목으로 응답시간이 느려질 수 있다.\n- 추적이나 디버그, 정보 성격의 로그를 에러나 심각으로 남기지 않는다.\n\n#### 2.1.2 로깅을 위한 불필요한 메시지 생성\n\n```bash\n// CASE 1\nfor (int i=0; i<n; i++){\n\tLog.debug.println(\"파일 서버에 전송할 입력 매개변수 + \" + output);\n}\n\n// CASE 2\nfor (int i=0; i<n; i++){\n\tif(Log.debug.isEnabled()){\n\t\tLog.debug.println(\"파일 서버에 전송할 입력 매개변수 + \" + output);\n\t}\n}\n```\n\n- `CASE 1`은 println 내부에서 디버그에 대한 로깅 여부를 확인해 출력하지 않아도 자바에서는 `“String” + Object.toString()` 문자열을 만드는 작업이 수행된다.\n- `CASE 2`는 `if(Log.debug.isEnabled())` 조건문으로 로깅 코드를 감싸서 로깅 수준이 비활성화 상태면 문자열을 만드는 작업이 수행되지 않는다.\n\n#### 2.1.3 로깅을 효율적으로 하기 위한 개선\n\n- 개발 서버에 로깅하는 양이 너무 많아 원하는 로그를 찾는데 시간이 걸리고 성능 저하가 발생한다면 개발 서버도 기본 로그 수준을 경고로 설정하고, 테스트하는 구간만 디버그 수준으로 설정할 수 있다.\n- 서비스 요청 단위로 로깅을 관리하면 특정 서비스 요청만 디버그 수준으로 설정해 해당 서비스 전체의 성능 저하 없이 셀제 운영환경에서 디버그를 수행할 수 있다.\n\n#### 2.1.4 트랜잭션 저널 로그\n\n### 2.2 불필요한 로직\n\n- 불필요한 로직은 공통 모듈을 사용할 때 주로 나타난다.\n  - 대체로 공통 모듈은 다양한 경우에 대비해 여러 가지 값을 제공한다.\n  - 어떤 로직에서는 필요하지 않은 정보도 함께 읽어오게 된다.\n- 이를 방지하기 위해 포괄적인 정보 외에 사용 패턴을 고려해 세분화된 정보를 제공하는 함수도 다양하게 제공해야 한다.\n\n### 2.3 반복 로직\n\n- 성능에 영향을 주는 부분이 반복 작업으로 분석됐다면 맨 처음에 수행된 결괏값을 저장해 뒀다가 재사용할 수 있게 변수나 캐시를 둠으로써 성능 저하를 해결할 수 있다.\n- 반복의 예\n  - 통신전문에서 동일한 항목을 읽어내는 것임에도 파싱 작업을 한다.\n  - `for`, `while` 문 안에서 매번 동일한 값으로 동일한 계산식을 수행하는 부분이 있다.\n  - 외부 인터페이스를 호출할 때마다 관련 환경설정 파일을 매번 읽어 들인다.\n\n### 2.4 불필요한 초기화 과정\n\n- 내부적으로 초기화 과정이 복잡하고 시간이 오래 걸리는 작업임에도 개발자 입장에서 코드를 작성하는 부분은 너무 단순해 모르고 넘어가는 경우가 있다.\n  - 자바의 JAXB와 스프링 프레임워크의 RestTemplate등 이 있다.\n- 스레드 안전한 클래스라면 싱글톤으로 선언하여 재사용할 수 있다.\n- 스레드 안전하지 않다면 ThreadLocal 같은 기능을 사용해 스레드별로 만들어 사용할 수도 있다.\n\n## 3. 로직 최적화\n\n### 3.1 락 최소화\n\n- 애플리케이션에서도 여러 프로세스나 스레드가 동일 데이터에 접근함으로써 발생할 수 있는 오류를 방지하기 위해 락을 사용한다.\n- C/C++는 세마포어, 뮤텍스, 크리티컬 섹션 등으로 락을 제공\n- 자바는 synchronized, wait/nofity 등 제어 구문 외에도 동시성을 제어하는 클래스를 제공한다.\n\n#### 3.1.1 락 범위 최소화\n\n- 캐시를 구성할 때 보통 데이터 종류별로 하나의 메모리 구조로 설계하는 것이 일반적이다.\n- 이 경우 해당 메모리 전체에 대해서 싱글포인트락이 존재하는 경우 동시 대량 처리 시 락 경합이 발생할 수 있으므로 복수 개의 메모리 구조로 쪼개서 락 경합을 분산할 수 있다.\n\n#### 3.1.2 락 제거\n\n### 3.2 문자열 처리 개선\n\n#### 3.2.1 String.format 메서드\n\n- StringBuilder 로 처리하는 것에 비해 String.format이 10배정도 느리다.\n\n#### 3.2.2 String.replaceAll 메서드\n\n- replaceAll 내부는 정규 표현식을 사용하는 형태로 구현돼 있어서 복잡하다.\n\n#### 3.2.3 문자열 합치기\n\n- 자바 초기에는 “String” + 변수 + “String” 형태로 문자열을 처리하면 합치는 횟수만큼 객체가 생성되어 성능이 좋지 않았다.\n- 하지만 자바 버전이 올라가면서 컴파일러가 코드 최적화를 통해 StringBuilder로 대체하므로 개선 대상으로 고려하지 않아도 된다.\n\n### 3.3 리플렉션 호출 제거\n\n- 리플렉션 호출은 프로그램에 유연성과 확장성을 제공하지만 이를 구현하기 위해 객체를 생성하고 메서드를 호출하기 위한 준비 작업 하나하나가 직접 메서드를 호출하는 것과 맞먹는 비용이 든다.\n\n### 3.4 채번\n\n- 애플리케이션 코드 내에서 채번이 이뤄지는 경우에는 성능에 큰 영향이 없으나 DB 내에서 채번이 이뤄지는 경우에는 성능 저하의 원인이 되는 경우가 많다.\n- DB 내 채번 방식\n  - 기존 최대값 조회 MAX+1\n    - 동시에 채번이 이뤄지는 경우 동일한 번호가 채번되어 후속 작업에서 에러가 발생할 수 있다.\n  - 채번 테이블\n    - 채번 테이블에 유형별 레코드로 채번 번호를 관리하는 방식\n  - DB 채번 기능\n    - DB에서 재공하는 채번 기능을 사용하는 것으로 세 가지 방식 중 가장 성능이 우수하다.\n- 매번 DB에서 채번하게 되면 10,000번 채번에 DB 호출이 10,000번 수행되어야 한다.\n- 하지만 채번 테이블의 채번 캐시 크기를  예를 10,00 단위로 사용하게 되면 10,000번 채번 1번당 DB 채번이 이뤄지므로 성능이 훨등히 개선된다.\n\n### 3.5 날짜 연산\n\n### 3.6 시간 문자열 처리\n\n### 3.7 순차 검색 제거\n\n### 3.8 파일 입출력 단위\n\n- 파일 처리는 입출력 단위가 큰 것이 성능에 유리하다.\n- 버퍼를 가지고 있는 입출력 클래스를 사용해 버퍼 단위로 입출력이 발생하게 하는 편이 우수한 성능을 발휘한다.\n- `BufferedOutpuStream`, `BufferedInputStream`\n\n### 3.9 SQL\n\n- **SQL 바인드 변수 처리**\n  - SQL을 수행할 때는 PreparedStatement 객체를 사용하여 바인드 변수 처리하는 것이 기본 원칙이다.\n    - SQL 캐시효과, 하드 파싱, 공유 풀 경합 등\n    - 바인드 변수를 사용하지 않으면 필요 이상으로 많은 SQL이 공유 풀에 저장되어 메모리 사용량이 증가한다.\n- **자원 반납**\n  - SQL을 수행한 후 사용한 JDBC 자원을 반납하지 않으면 성능 저하나 장애가 유발된다.\n  - Statement를 반납하지 않으면 DB 프로세스 당 할당된 최대 커서 수에 도달해 더는 SQL을 처리할 수 없는 상황이 되고, 자바 메모리 누수 또한 발생한다.\n  - 자원 반납은 ResultSet, Statement, Connection 순으로 수행한다.\n- **DB 연결 풀 사용**\n  - DB는 새로운 연결을 맺을 때 많은 비용이 드므로 일반적으로 연결 풀을 사용한다.\n  - 평상시 부하는 연결을 늘리지 않고도 처리할 수 있을 정도로 최소 연결 풀 개수를 유지한다.\n  - 더미 쿼리를 사용해 주기적으로 연결을 테스트함으로써 DB 연결이 방화벽이나 운영체제 설정에 의해 끊어지지 않게 한다.\n\n### 3.10 BigDecimal\n\n- float 이나 double 숫자 타입은 정확성이 아닌 성능 위주로 설계된 부동 소수 형식을 사용하기 때문에 일부 값이 정확하지 않고 근사값으로 표현된다.\n- BigDecimal을 생성할 때 new BigDecimal(double) 보다는 new BigDecimal(String)을 사용한다.\n- double로 변환해야 하는 경우에는 BigDecimal.valueOf(double) 메서드를 사용한다.\n\n### 3.11 비대기 입출력 사용\n\n- 논블럭킹 I/O 를 사용하면 읽어내고자 하는 야보다 데이터가 적거나 전혀 없더라도 현재 있는 데이터 양만큼 읽고 나온다.\n\n### 3.12 엑셀 처리\n\n- 엑셀 포맷을 다룰 때 일반적으로 아파치의 POI를 사용한다.\n- POI는 엑셀 파일을 다룰 때 크게 스트리밍과 인 메모리 트리라는 두 가지 방식을 사용한다.\n  - 인메모리 트리는 문서 내용 전체를 메모리에 유지하므로 메모리 사용량이 크고, 스트리밍에 비해 속도가 느리다.\n- 버퍼드 스트리밍은 전체 데이터를 메모리에 가지고 있지 않고 일정 건수가 되면 디스크로 내리기 때문에 메모리 제약이 없어 큰 용량의 데이터 처리가 가능하다.\n\n### 3.13 기타 성능 개선\n\n### 3.14 코드 성능 측정\n\n## 4. 적극적인 캐시 사용\n\n- 성능 튜닝의 한 축은 서비스 간이나 서비스 내에서 반복되는 로직을 제거하는 것 이다.\n- 기존에 작업한 결과를 저장해 뒀다아 이후에 다시 동일한 작업이 수행됐을 때 결과를 재사용하면 반복되는 로직을 제거할 수 있다.\n1. 브라우저\n  1. 도메인명에 대한 주소 캐시\n  2. 콘텐츠 캐시\n2. 웹 서버\n  1. 환경설정 캐시\n  2. 콘텐츠 캐시\n3. WAS\n  1. 환경설정 캐시\n  2. 프로그램 모듈 캐시\n4. 애플리케이션\n  1. 적극적인 사용이 요구되는 부분\n5. 프레임 워크\n  1. 환경설정 캐시\n  2. 서비스와 프로그램 구성 캐시\n  3. 송수신 전문 구조 캐시\n  4. SQL 캐시\n  5. 애플리케이션을 위한 캐시 제공\n6. DBMS\n  1. 환경설정 캐시\n  2. 테이블, 인덱스, 권한 등 구성정보 캐시\n  3. SQL 실행계획 캐시\n  4. 데이터 캐시\n\n## 5. 효율적인 아키텍처 구성\n\n### 5.1 병렬 처리\n\n- 웹 기반 시스템은 각 구성 서버마다 병렬 처리를 설정할 수 있다.\n- 웹 서버는 사용자의 모든 서비스 요청을 받아들이는 곳으로, 한 사용자가 6개 이상의 병렬 스레드를 사용할 수도 있다.\n- 그러나 요청이 WAS 까지 도달하면 스레드를 한두 개 사용한다.\n- DB 동시 작업은 애플리케이션 처리시간과 DB 연결 사용시간이 거의 일치하면 스레드 풀 설정과 거의 동등한 수준으로 DB 연결 풀을 사용한다.\n- 아키텍처를 스레드 병렬 구조로 만들 때는 반드시 앞쪽에 큐를 둬서 스레드가 작압 단위 간에 쉼 없이 연속해서 처리할 수 있도록 해야한다.\n\n### 5.2 통신전문\n\n- XML의 경우에는 메모리 사용량과 전문 크기가 많다.\n- 이를 개선하기 위해 컬럼명을 레코드 첫 부분에 한번만 기술하고 이후 반복되는 레코드에서 컬럼명을 생략하고 데이터만 기술하는 변형된 형태의 JSON을 적용했다.\n- 따라서 고성능 시스템이 필요하거나 사용자가 원격지에 있어 데이터 전송량을 줄여 속도를 개선해야 하는 경우에는 다른 형식의 전문을 고려해야 한다.\n\n### 5.3 고객정보 조회 이력 로깅과 마스킹\n\n### 5.4 대량 조회 프레임워크 구성\n\n- 데이터를 대량으로 조회하다보면 메모리 부족으로 애플리케이션 서버가 다운되는 문제를 경함하게 된다.\n- 아래와 같은 방안으로 대량건 조회를 대처할 수 있다.\n  - 프레임워크 DAO에서 일정건이상 조회하면 예외를 발생시킨다.\n  - 대량건 조회는 페이징 처리를 통해 메모리에 무리가 없는 단위로 나눠서 처리한다.\n  - 대량 조회가 이뤄지지 않도록 조회 건수를 줄이는 필수 조건을 입력하도록 유도한다.\n  - 일반 온라인 업무에 영향을 주지 않도록 대량 조회 전용 WAS 인스턴스를 구성한다.\n  - 배치 같은 별도 프로세스에서 대량 건을 파일로 생성한 다음 파일을 다운로드하게 한다.\n- 프레임워크에서 대량건 조회를 지원하기 위해서는 자바의 경우 JDBC ResultSet과 전문 생성 부분을 바로 연결해야 한다.\n\n### 5.5 내부 연계시스템\n\n### 5.6 수직확장과 수평확장\n\n- 성능 저하가 발생하면 서버를 늘리는 수평확장보다 CPU나 메모리를 증설하는 수직확장을 선호해 왔다.\n  - 수평확장은 서버간 동기화로 인한 성능 저하가 발생할 수 있기 때문에\n- 수평확장이 가능하도록 아키텍처를 구성하려면 다음과 같은 사항을 고려해야 한다.\n1. 데이터베이스 샤딩\n  1. 샤딩은 여러 DB에 데이터를 나눠서 저장하는 기술이다.\n  2. 파티션은 한 DB에 분산 저장하는 것이고, 샤딩은 복수 DB에 분산 저장한다.\n  3. 샤딩은 DBMS가 제공하는 기능이 아니므로 애플리케이션에서 로직으로 구현해서 적용한다.\n  4. DB 샤딩에서 수평확장이 용이하게 하려면 초기 샤딩 아키텍처를 설계할 때 온라인 상태에서 DB 서버를 늘리고 데이터를 옮길 수 있는 방안을 마련해야 한다.\n  5. DB 서버가 4대에서 6대로 증가할 때 샤딩된 기존 저장된 DB서버를 찾아가고 증가된 DB수에 따라 데이터 재배치가 이뤄질 수 있어야 한다.\n  6. DB 샤딩의 한계는 구축하기가 어렵고, 샤딩된 데이터로 인해 테이블 간에 조인이 제한적이거나 불가능하다는 것이다.\n  7. 대량의 데이터 처리를 고려할 때 데이터 저장 솔루션으로 고려하는 것이 NoSQL 이다.\n  8. NoSQL을 이용하면 자동분할과 노드 추가 시 자동 재분배, 이중화에 의한 장애 대응까지 솔류션이 지원하므로 유연한 수평확장이 가능하다.\n2. StatelessProcessing\n  1. WAS에서 세션을 통해 사용자 인증 정보를 관리하는 경우가 많다.\n  2. 여러 대의 WAS 서버를 사용하는 경우 세션 클러스터링 기술을 사용한다.\n  3. 그런데 서버 수가 많아지면 이마저도 성능 저하 요인이 된다.\n  4. 시스템을 Stateless 아키텍처로 만들어지면 사용자 서비스 요청이 어떤 애플리케이션 서버에서도 처리할 수 있다.\n3. 인메모리 데이터 그리드\n  1. 인메모리 데이터 그리드는 키캆 형식의 데이터 캐시 솔류션이다.\n  2. DBMS에 저장된 데이터나 사용자 서비스 호출 간에 공유할 데이터를 캐시해서 성능을 개선할 목적으로 사용한다.\n  3. 상대적으로 데이터의 생명주기가 짧고 변경이 발생하지 않는 데이터에 대해 캐시하는 것이다."},{"excerpt":"4부 - 프로세스 이해하기 1. 기본 방향 애플리케이션 최적화를 하기 위해서 프로세스의 동작 방식을 이해해야 한다. 프로세스 이해에 필요한 기본 지식으로 다음 세 가지가 있다. 수행 중인 코드 : 프로세스가 현재 어떤 함수를 수행하고 있는가? 통신/파일 상태 : 프로세스가 통신으로 연계된 서버는 어디고, 어떤 파일을 열고 있는가? 통신/파일 간 동작 상태…","fields":{"slug":"/ch4/"},"frontmatter":{"date":"February 08, 2022","title":"4부 - 프로세스 이해하기","tags":["실무로 배우는 시스템 성능 최적화"]},"rawMarkdownBody":"\n## 4부 - 프로세스 이해하기\n\n## 1. 기본 방향\n\n- 애플리케이션 최적화를 하기 위해서 프로세스의 동작 방식을 이해해야 한다.\n- 프로세스 이해에 필요한 기본 지식으로 다음 세 가지가 있다.\n  - **수행 중인 코드** : 프로세스가 현재 어떤 함수를 수행하고 있는가?\n  - **통신/파일 상태** : 프로세스가 통신으로 연계된 서버는 어디고, 어떤 파일을 열고 있는가?\n  - **통신/파일 간 동작 상태** : 연계 서버 또는 파일에 입출력이 얼마나 자주 그리고 오래 이루어지는가?\n- 이번 장에서는 운영체제에서 제공하는 분석 명령어를 바탕으로 프로세스의 현재 상태와 동작을 이해하는 법과 개선 하는 방법을 습득한다.\n\n<!-- more -->\n\n\n## 2. 수행 중인 코드\n\n### 2.1 스택에 대한 이해\n\n- 현재 수행 중인 프로그램이 코드 중 어디를 수행하고 있는지 알고 싶을 때는 해당 프로그램의 스택 정보를 획득하면 알 수 있다.\n\n```bash\nleegisu> jstack 12341\n\nFull thread dump OpenJDK 64-Bit Server VM (11.0.12+7-LTS mixed mode):\n\n\"http-nio-8080-Acceptor\" #28 daemon prio=5 os_prio=31 cpu=0.55ms elapsed=23.70s tid=0x00007ff0a3232000 nid=0x14b03 runnable  [0x000000030b22f000]\n   java.lang.Thread.State: RUNNABLE\n        at sun.nio.ch.ServerSocketChannelImpl.accept0(java.base@11.0.12/Native Method)\n        at sun.nio.ch.ServerSocketChannelImpl.accept(java.base@11.0.12/ServerSocketChannelImpl.java:533)\n        at sun.nio.ch.ServerSocketChannelImpl.accept(java.base@11.0.12/ServerSocketChannelImpl.java:285)\n        at org.apache.tomcat.util.net.NioEndpoint.serverSocketAccept(NioEndpoint.java:540)\n        at org.apache.tomcat.util.net.NioEndpoint.serverSocketAccept(NioEndpoint.java:78)\n        at org.apache.tomcat.util.net.Acceptor.run(Acceptor.java:129)\n        at java.lang.Thread.run(java.base@11.0.12/Thread.java:829)\n```\n\n### 2.2 스택 정보를 이용한 성능 분석\n\n- 스택 정보는 성능 저하나 멈춤 상태에서 프로세스를 분석하는 핵심 정보다.\n\n#### 2.2.1 스택 대기 분석\n\n- `- locked` 면 락을 잡았다는 의미\n- `- waiting to lock` 은 다른 스레드가 사용할 락을 잡고 있어 대기하고 있다는 의미\n\n#### 2.2.2 교착상태\n\n#### 2.2.3 스택 성능 분석\n\n### 2.3 스택 수집\n\n- 자바 프로그램의 스택 정보 수집\n\n```bash\njstack [pid] // [JDK HOME]/bin 디렉터리에 있음\nkill -3 [pid] // 표준 출력으로 스레드 덤프를 출력\n```\n\n- 자바 힙 덤프 설정\n  - 자바 프로세스에서 아래와 같이 설정이 추가돼 있으면 `kill -3` 시그널에서 힙 덤프가 생성된다.\n\n```bash\n-XX:+HeapDumpOnCtrlBreak\n```\n\n### 2.4 프로세스 스택 분석 도구\n\n#### 2.4.1 환경설정\n\n#### 2.4.2 주요 기능 설명\n\n#### 2.4.3 SDPA를 이용한 성능 분석\n\n## 3. 통신/파일 상태\n\n### 3.1 파일 지시자의 이해\n\n![](ch4/img.png)\n\n![](ch4/img_1.png)\n\n- 유닉스와 리눅스는 소켓이나 파일을 사용할 때 파일 지시자(FD)라는 것을 사용한다.\n- 유닉스에서 파일 지시자는 파일 뿐만 아니라 디렉토리, 디바이스, 파이프, 네트워크 소켓, 유닉스 도메인 소켓 등에 접근할 떄도 사용된다.\n- 유닉스 프로세스 FD 상태 정보는 pfiles ,lsof 명령을 통해 조회할 수 있다.\n\n### 3.2 연계 통신/파일 상태 정보를 수집하는 방법\n\n- `lsof -p [pid]` 로 대상 프로세스의 상태를 조회할 수 있다.\n\n## 4. 통신/파일 간 동작\n\n### 4.1 시스템 콜에 대한 이해\n\n- 스택 정보와 통신/파일 상태 정보는 시점 정보이기 때문에 파일을 계속 열고 있지 않고 순간적으로 여닫는 경우는 잡히지 않을 수도 있다.\n- 이러한 정보를 얻기 위해서는 시스템 콜을 모니터링 해야 한다.\n- 유닉스나 리눅스는 C언어를 기반으로 개발되어 시스템 콜에 보이는 함수가 C로 개발된 시스템 라이브러리에서 제공되는 함수이다.\n\n### 4.2 통신/파일 상태와 동작 연계 분석\n\n### 4.3 스택 정보와 통신/파일 간 동작 연계 분석\n\n### 4.4 통신/파일 간 동작 모니터링 방법\n\n## 5. 기타\n\n### 5.1 프로그램 소스코드 보기\n\n### 5.2 바이너리 코어 덤프에서 자바 스택이나 힙 정보를 추출하는 방법\n\n### 5.3 프로세스의 현재 작업 디렉터리를 확인하는 법\n\n### 5.4 프로르램에서 사용하는 공유 라이브러리 확인\n\n### 5.5 프로세스 생성 관계 보기\n\n### 5.6 프로세스의 수행 환경 확인"},{"excerpt":"1. 기본 방향 2. HTTP의 이해 2.1 프로토콜 구조 기본적으로 클라이언트 서버 간에 요청과 응답이 1:1 구조를 띠고 있다. HTTP 요청/응답 모두 헤더와 본문으로 구성돼 있다. 2.2 HTTP 요청 요청은 헤더와 본문으로 나뉘고, 헤더는 다시 요청 라인과 MIME 헤더로 나뉜다. 요청 헤더 요청 방식으로는 8가지가 있다. , , , , , , …","fields":{"slug":"/ch3/"},"frontmatter":{"date":"February 05, 2022","title":"3부 - 화면 응답시간 분석","tags":["실무로 배우는 시스템 성능 최적화"]},"rawMarkdownBody":"\n## 1. 기본 방향\n\n## 2. HTTP의 이해\n\n### 2.1 프로토콜 구조\n\n- 기본적으로 클라이언트 서버 간에 요청과 응답이 1:1 구조를 띠고 있다.\n- HTTP 요청/응답 모두 헤더와 본문으로 구성돼 있다.\n\n<!-- more -->\n\n### 2.2 HTTP 요청\n\n- 요청은 헤더와 본문으로 나뉘고, 헤더는 다시 요청 라인과 MIME 헤더로 나뉜다.\n- **요청 헤더**\n\n```jsx\n// 요청 라인\nPOST /board/new.jsp HTTP1.1\n\n// MIME 헤더\nAccept: image/jpeg, \nAccept-Language: ko-KR\nUser-Agent: Mozilla/4.0\nAccept-Encoding: gzip, deflate\nConnetion: Keep-Alive\nHost: www.lgcns.com\nCookie: .lgcns.eh.......\n```\n\n- 요청 방식으로는 8가지가 있다.\n  - `GET`, `POST`, `HEAD`, `DELETE`, `TRACE`, `OPTIONS`, `PUT`, `CONNECT`\n- 요청 라인에는 URI 정보가 들어있다. `(/board/new.jsp)`\n  - URI는 웹 서버에서 대상을 유일하게 인식할 수 있는 주소로서 콘텐츠의 위치와 명칭을 가르킨다.\n- HTTP 버전으로는 `1.1`, `1.0` 등이 있다.\n\n#### MIME 헤더\n\n- 원래 전자우편의 인코딩 방식을 설명하는 표준 포맷이다.\n- MIME 헤더 정보는 `“명칭: 값”` 형태로 이루어져 있다.\n- HTTP 공통 MIME 헤더\n\n| 헤더 | 설명 |\n| --- | --- |\n| Cache-Control | 캐시가 동작하는 조건을 지정하는 지시문이다. |\n| Connection | 클라이언트 웹 서버 간 네트워크 연결 시에 대한 Keepalive 여부를 지정한다. |\n| Date | 현재의 날짜와 시간을 표시 |\n| Progma | 프락시에 대한 지시문으로 웹 서버에서는 무시된다. |\n\n- HTTP 요청 전용 MIME 헤더\n\n| 헤더 | 설명 |\n| --- | --- |\n| Accept | 응답으로 받을 수 있는 MIME 타입을 지정한다. */*는 모든 타입이 가능하다는 것을 의미 |\n| Accept-Encoding | 클라이언트가 받을 수 있는 본문 인코딩 형태를 지정 |\n| Accept-Language | 클라이언트가 우선적으로 지원하는 언어를 지정 |\n| Authorization | URI에 클라이언트가 데이터에 접근할 수 있는 권한을 제공한다.\n| Cookie | 서버에서 설정한 소량 데이터가 사용자 PC에 저장되어 요청 간에도 해당 데이터를 서버 측면에서 공유할 수 있는 기능을 수행한다. |\n| Host | 호스트명과 URI의 포트 번호로 구성된다. |\n| If-Modified-Since | URI가 이미 클라이언트 캐시에 있는 경우 해당 콘텐츠의 수정 시간을 서버에 보내서 웹 서버에서 클라이언트 캐시에 있는 콘텐츠 사용 여부를 판단할 수 있게 한다. |\n| If-Unmodified_Since | If-Modified-Since와 반대로 동작한다. |\n| If-Match | 존거부로 요청하는 것을 의미하며, 특정 Entity tags와 매치되게 한다. |\n| If-None-Match | If-Match와 반대로 동작한다. |\n| Referer | 요청된 URI를 참조하는 문서의 URI를 전달한다. |\n| Range | 요청된 URI에 해당하는 콘텐츠 전체를 받지 않고 범위를 지정해 일부분만 받을 때 사용한다. |\n| User-Agent | 클라이언트 브라우저에 대한 식별 정보를 전송한다. |\n\n- 본문\n\n```bash\nboard_id=12&op=list&index=1\n```\n\n### 2.3 HTTP 응답\n\n- HTTP 응답은 헤더와 본문으로 나뉘고, 헤더는 다시 응답 라인과 MIME 헤더로 나뉜다.\n\n### 2.4 데이터 송수신\n\n- HTTP에서는 요청/응답에 본문이 없는 경우 `CRLF`가 2번 연속 반복될 때까지 전문을 읽으면 된다.\n- 본문이 있는 경우에는 `Context-Length`나 `Chunked` 방식에 따라 본문 크기를 확인하고 데이터를 읽어낸다.\n\n#### Context-Length 방식\n\n- 헤더인 `Context-Length`에 본문의 크기를 바이트 단위로 기록해서 수신 측에서 본문의 크기를 알 수 있게 하는 방식이다.\n- HTTP 헤더 정보를 만드는 시점에 본문 전체 크기를 알 수 있을 때 사용한다.\n\n```bash\nContent-Encoding: gzip\nContent-Length: 14949 // 본문의 크기는 14949 바이트\n```\n\n#### Chunked 방식\n\n- Chunked 방식은 HTTP 헤더인 Transfer-Encoding이 Chunked 값을 가지고 있다.\n- HTTP 헤더 생성 시점에 본문의 크기를 알 수 없을 때 사용하는 방식이다.\n\n```bash\n// 헤더\nTransfer-Encoding: chunked\n\n// 본문\n27B // 서브 블록 크기\n{\"status\": N .... }\n2B0 // 서브 블록 크기\n....\n0 // 블록의 마지막\n```\n\n## 3. 화면 응답시간 모니터링\n\n### 3.1 화면 응답시간 모니터링 도구\n\n- Fiddler, Dynatrace AJAX Edition, HttpWatch, FireBug, IE 개발자 도구, 크롬 개발자 도구 등\n\n### 3.2 인터넷 익스플로러 프로파일링\n\n### 3.3 피들러\n\n### 3.4 HTTP 분석 접근\n\n- 화면 응답시간이 Timeline 내에서 표시된 요청의 처리시간과 일치하는지 확인한다.\n- Timeline 중 특별히 처리시간이 긴 요청이 존재하는지 확인한다.\n- 각 요청에 대한 처리시간은 짧지만 요청 수 자체가 많아서 응답시간이 오래 걸리는지 확인한다.\n- Timeline 상에서 요청 처리 중간 중간 처리가 없이 비어있는 긴 시간이 있는지 확인한다.\n  - 중간의 빈 부분은 자바스크립트를 로딩하거나 수행하는 시간일 확률이 높다.\n- 요청 목록에서 응답 코드가 200인지 304 Not Modified인지 확인해 캐시가 정상적으로 동작하는지 확인한다.\n- 전체가 200 OK일 때의 전체 페이지 크기와 개별 요청의 콘텐츠 크기를 확인한다.\n\n## 4. 웹 기반 시스템 성능 개선\n\n### 4.1 화면 콘텐츠 구성\n\n- 웹도 동적 컨텐츠나 서블릿 같은 애플리케이션 처리시간이 느린 경우가 많지만 이미지나 자바스크립트, CSS 같은 정적 콘텐츠 수가 많거나 크기나 커서 느린 경우도 있다.\n- 화면 콘텐츠 구성 측면에서 접근하는 성능 개선은 크게 두 가지로 나뉜다.\n  - 화면을 좀 더 간경하게 구성하거나 콘텐츠를 통합함으로써 콘텐츠 수를 줄인다.\n  - 콘텐츠 크기를 줄임으로써 네트워크 전송시간을 개선하고 화면이 빠르게 로딩될 수 있게 한다.\n\n#### 4.1.1 콘텐츠 수 축소\n\n- 화면을 구성하는 콘텐츠 수가 많을수록 브라우저와 서버 간에 순차적으로 다운로드 하는 애플리케이션 턴이 많이 발생하여 성능 저하를 유발한다.\n- 화면별 요청 수가 많을수록 응답 시간이 느리다.\n  - 이미지를 이용한 화면 구성 최소화\n    - 이미지 대신 CSS를 활용한다.\n  - 맵을 이용한 URL 구성\n    - 메뉴마다 개별 이미지를 사용하는 대신 한 개의 통합 이미지를 사용한다.\n  - 이미지 스프라이트\n    - 한 이미지 파일에 있는 여러 이미지를 개별 이미지 형태로 사용한다.\n  - 자바 스크립트 통합\n    - 자바스크립트 파일을 통합해 파일의 수를 줄임으로써 성능을 개선한다.\n  - 사용하지 않는 콘텐츠 제거\n    - CSS나 자바스크립트에서 화면마다 사용되지 않는 부분은 제거하여 최적화한다.\n\n#### 4.1.2 크기별 이미지 준비\n\n- 큰 이미지를 작은 이미지로 변환하는 오버헤드로 CPU 자원과 시간이 소요된다.\n- 사진 목록 처럼 작은 이미지를 보여줄ㄷ 때는 해당 크기에 맞는 섬네일을 별로도 준비한다.\n\n#### 4.1.3 이미지 콘텐츠 파일의 크기 축소\n\n- 파일 크기가 큰 이미지를 사용하기보다 품질을 조정해서 크기를 줄일 이미지를 사용한다.\n\n#### 4.1.4 CDN 사용\n\n- CDN은 웹 서비스 제공자가 웹 서버에 있는 정적 컨텐츠를 인터넷 서비스 제공자 측에 설치된 CDN 서버에 미리 저장해두고 사용자에게 최적 경로로 컨텐츠를 제공하는 기술이다.\n- 예를 들어, 사용자가 어떤 이미지를 다운로드 하기위해서는 서버 도메인명으로 IP 주소를 조회해 해당 서버로 접속하는 네트워크 연결이 선행돼야 한다.\n- CDN을 이용하면 IP 주소 조회 서비스를 제공하는 대신 DNS 서버가 사용자가 위치한 지역에 가장 근접한 CDN 서버의 IP 주소를 보내준다.\n- 동적 컨텐츠 역시 동일한 도메인을 사용하게 되면 CDN을 경유하게 되므로 동적 컨텐츠, 정적 컨텐츠 도메인을 분리해야 한다.\n\n#### 4.1.5 텍스트 콘텐츠의 크기 축소\n\n- 자바스크립트나 CSS 같은 텍스트 컨텐츠를 정리해서 크기를 줄여주는 도구를 사용한다.\n\n#### 4.1.6 압축 적용\n\n- 압축은 CPU 위주의 작업이기 때문에 웹 서버 자원에 여유가 있고 전체 응답시간에서 네트워크가 자치하는 비중이 높은 경우에 사용하는 것이 바람직하다.\n- 압축 동작은 브라우저가 처리할 수 있는 압축 방식을 요청 헤더에 `Accept-Encoding: gzip, deflate`와 같이 담아서 서버로 전송한다.\n- 아파치, nginx 등 범용 웹 서버에서는 모두 지원한다.\n\n#### 4.1.7 웹 가속기\n\n- 웹 가속기는 웹 서버 앞에 위치해 사용자 브라우저와의 통신을 최적화하는 역활을 수행한다.\n  - 콘텐츠 압축\n  - 콘텐츠 캐시\n  - 네트워크 연결 관리\n  - SSL 가속\n\n\n### 4.2 캐시 동작\n\n#### 4.2.1 브라우저 캐시\n\n- 브라우저 캐시는 HTTP 응답 크기를 줄이는 방식과 HTTP 요청 수를 줄이는 방식이 있다.\n\n#### HTTP 응답 크기를 줄이는 캐시 방식\n\n![Untitled](ch3/img.png)\n\n- 정적 콘텐츠에 대해 HTTP 요청을 하면 웹 서버는 응답시 `Last-modified` 헤더 속성에 콘텐츠의 변경일자를 내려보낸다.\n- 이후 동일한 콘텐츠에 대해 브라우저가 HTTP 요청을 할 때는 브라우저 캐시에 저장된 해당 콘텐츠의 변경일자 정보를 `If-Modified-Since` 속성에 붙여서 웹 서버로 보낸다.\n- 웹 서버는 콘텐츠의 변경일자와 브라우저에 있는 콘텐츠 변경일자를 비교해 동일한 콘텐츠이면 브라우저 캐시를 사용하고 그렇지 않으면 새 콘텐츠를 다운로드 한다.\n\n#### HTTP 요청 수를 줄이는 캐시 방식\n\n![Untitled](ch3/img_1.png)\n\n- HTTP 요청 수를 줄이는 방식은 `Cache-Control` 속성을 이용해 HTTP 요청 자체를 하지 않도록 줄이는 방식이다.\n- `Cache-Control` 의 max-age 설정을 통해 응답디 내려간 이후 일정 시간(max-age:초) 동안 서버에 HTTP 요청 자체를 하지 않게 할 수 있다.\n- HTTP 요청 수 자체를 줄여서 성능 개선 효과는 크지만 해당 콘텐츠가 변경되더라도 일정 시간 동안은 갱신할 수 없다는 문제가 있다.\n\n### 4.3 병렬/비동기 처리\n\n#### 4.3.1 네트워크 연결 증가\n\n- 브라우저는 한 페이지 내에서 한 도메인에 대해 네트워크 연결 개수가 제한돼 있다.\n- 따라서 콘텐츠를 동시에 내려받을 수 있는 병렬 처리 갯수에 한계가 있다.\n- 동일한 웹 서버에 대해 2개의 도메인을 구성하면 두 배까지 열 수 있다.\n- 하지만 웹 서버 내 작업 스레드를 증가시켜 스레드 부족을 유발할 수 있으므로 스레드 수 설정을 증가시킬 필요가 있다.\n\n#### 4.3.2 AJAX와 DOM을 이용한 비동기 처리\n\n- AJAX와 DOM을 효과적으로 이용하면 서버 부하 감소뿐 아니라 클라이언트 측면의 성능 개선도 가능하다.\n- **화면 내 일부분을 비동기 처리**\n  - 통계 정보처럼 서버 처리시간이 길어지면 화면 전체가 늦게 완성됨으로써 성능 저하가 발생한다.\n  - 해당 부분을 AJAX로 별도로 분리해서 비동기적으로 처리하면 응답 시간 개선에 도움이 된다.\n- **트랜잭션의 비동기 분리**\n  - 예전에는 목록 화면에서 한 건을 삭제하거나 새로 입력하면 목록 전체를 다시 조회해서 변경내역을 확인하는 것이 일반적\n  - 현재는 입력, 수정, 삭제 같은 데이터 변경은 AJAX 로 처리하고, 목록에 변경하는 작업은 DOM 처리를 통해 수정한다.\n\n### 4.4 기타 성능 개선\n\n- CSS와 자바스크립트는 병렬 처리를 고려해서 배치한다.\n- CSS는 HEAD 태그에 기술한다.\n  - 스타일시트가 BODY에 있으면 모든 CSS가 다운로드될 때까지 브라우저는 렌더링을 미룬다.\n- HTTP 요청은 하나의 패킷으로 처리한다.\n- HTML 안의 CSS와 자바스크립트는 개별 파일로 처리한다.\n  - HTML 렌더잉을 지연시켜 성능 저하가 유발된다.\n- 이미지는 HTML에 크기를 명시한다.\n- HTML의 일부 내용은 먼저 전송되도록 처리한다.\n  - 애플리케이션이 완료되기 전에 응답 일부를 HEAD에 CSS나 자바스크립트를 포함시킬 수 있다.\n- 애플리케이션 응답시간이 긴 경우 진행표시줄을 사용한다.\n- CSS에 `@import`를 사용하지 않는다.\n\n### 4.5 웹 서버 설정\n\n#### 4.5.1 최대 병렬 처리수\n\n- 애플리케이션 서버는 작업 스레드 풀을 필요 이상으로 크게 설정하면 DB 부하가 증가하고 애플리케이션 서버가 낼 수 있는 최대 성능을 넘어서는 동시 처리 요청이 들어오면 TPS는 증가하지 않으면서 응답시간만 증가한다.\n- 반면 웹 서버는 CPU 자원에 대한 사용량보다는 네트워크 자원에 의존도가 높다.\n  - 네트워크가 허용한다면 작업 스레드 수를 다소 높게 설정하는 편이 안정적이다.\n- 웹 서버 스레드 풀 수를 설정할 때는 사용자 당 사용하는 스레드가 1개가 아니라는 점을 고려해야 한다.\n- 콘텐츠 수가 많으면 한번에 2~4개까지 웹 서버와 연결을 맺을 수 있다.\n\n#### 4.5.2 Keepalive\n\n- Keepalive 설정을 활성화하면 한 번 연 네트워크 연결을 반복 사용해 콘텐츠를 내려받을 수 있다.\n- 대부분 웹 서버에서는 기본적으로 Keepalive 가 활성화돼 있으며, nginx는 75초가 기본값이다.\n- Keepalive는 성능 개선 요소지만 경우에 따라 성능을 악화시키는 요소로 작용하기도 한다.\n- 아파치 웹 서버의 경우에는 Keepalive된 네트워크 연결 1개당 작업 스레드 1개씩 배정해서 작업한다.\n  - 사용자가 다양하고 많은 환경에서 Keepalive를 높게 설정하면 웹 서비스를 처리 중인 스레드 수가 적더라도 Keepalive에 의해 여유 스레드 전체가 특정 사용자에 대해 대기하고 있는 상태가 될 수 있다.\n  - 스레드풀에서 놀고 있는 스레드가 많더라도 해당 스레드 모두가 각기 담당하는 사용자 요청을 대기하고 있어 작업 배정이 안될 수 있다.\n- Nginx는 이벤트 드리븐 아키텍처로 논블럭킹 입출력을 사용하기 때문에 더 적은 프로세스로도 더 많은 사용자를 처리할 수 있다.\n\n## 5. 웹 서버 모니터링\n\n### 5.1 웹 요청 응답시간 모니터링\n\n- 애플리케이션 서버에 문제가 있었다면 해당 서버에서 서비스하는 URI에 집중적으로 성능 저하나 5xx HTTP 응답 코드가 타난다.\n- 웹 서버 마다 처리시간을 액세스 로그에 남기는 방법이 있다."},{"excerpt":"1장. 기본 자세 적극적이고 도전적인 자세를 갖춰라 다른 사람의 설명과 의견에 귀 기울여라 종합적인 시각을 가져라 실행하고 비교하라 2장. 성능 분석 시작하기 클라이언트부터 시작해 웹 서버, 애플리케이션 서버, DB 서버 등 여러 서버를 거쳐서 동작한다. 이런 구성에서 성능 저하가 발생했을 땐 네트워크를 기준으로 각 서버가 전체 응답시간에서 차지하는 비중…","fields":{"slug":"/ch2/"},"frontmatter":{"date":"February 04, 2022","title":"2부 - 성능 개선","tags":["실무로 배우는 시스템 성능 최적화"]},"rawMarkdownBody":"\n## 1장. 기본 자세\n\n- 적극적이고 도전적인 자세를 갖춰라\n- 다른 사람의 설명과 의견에 귀 기울여라\n- 종합적인 시각을 가져라\n- 실행하고 비교하라\n\n<!-- more -->\n\n## 2장. 성능 분석 시작하기\n\n- 클라이언트부터 시작해 웹 서버, 애플리케이션 서버, DB 서버 등 여러 서버를 거쳐서 동작한다.\n- 이런 구성에서 성능 저하가 발생했을 땐 네트워크를 기준으로 각 서버가 전체 응답시간에서 차지하는 비중을 분석해 영향도가 큰 집중 분석 대상을 선정하는 것 이다.\n- 성능이 저하됐을 때 처리 지연이 발생한 위치가 대부분 시스템 내부인 경우가 많기 때문에 내부 처리시간이 사용자 체감 응답시간과 차이가 있는지 확인하는 것이 우선이다.\n\n### 2.1 애플리케이션 서버 응답시간 분석\n\n- 애플리케이션 서버 내부에서 세분화된 응답시간을 얻는 방법에는 세 가지가 있다.\n  - **APM**\n    - 가장 손쉽게 직관적인 데이터 수집이 가능, 단 프로파일링 설정이 많으면 APM 자체가 성능 저하의 원인이 되기도 한다.\n  - **스택 수집**\n    - 주기적으로 스택을 수십 회 이상 수집해서 분석하는 방법\n    - 현재 통신 소켓을 읽거나 쓰고 있는 스택 하위에 있는 연계 인터페이스 메서드를 식별해 각 구성 요소 응답시간 비중을 분석할 수 있다.\n  - **프레임워크 로깅**\n    - 프레임워크 내부에서 각 구성 요소에서 소요된 처리시간을 서비스 요청 단위로 로깅하는 기능을 포함시키는 것이다.\n\n\n### 2.2 클라이언트 응답시간 분석\n\n- 클라이언트단 단에서 사용자 응답시간을 분석할 때 다음과 같이 나눠서 분석한다.\n  - **클라이언트 처리시간, 네트워크 처리시간, 서버 처리시간 (+ DNS 룩업시간)**\n\n## 3장. 상황별 분석 단계\n\n### 3.1 화면 응답시간 저하\n\n![](ch2/img.png)\n\n1. **클라이언트의 자원 사용량 확인**\n  - 클라이언트 PC의 주요 자원이 화면을 테스트하는 데 영향을 줄 가능성이 있는지 확인한다.\n  - 프로세스, 프로세스해커 등\n2. **사용자 접점 서버단 패킷 수집**\n  - 성능 저하가 특정 사용자에게 발생하지만 사용자 PC에서 직접 모니터링이 불가능한 경우 서버단에서 클라이언트 응답시간을 분석하기 위해 패킷을 수집한다.\n  - tcpdump, 와이어샤크 등\n3. **클라이언트 응답시간 분석**\n  - 클라이언트 응답시간을 클라이언트, 네트워크, 서버 세 구간으로 나눠서 분석한다.\n4. **클라이언트 원인 분석**\n  - 클라이언트에서 소요되는 시간이 많은 경우 원인을 분석한다.\n  - 클라이언트 스크립트 로직과 렌더링을 구분해서 분석\n  - 콘텐츠 유형과 응답시간 상관관계 분석\n  - 화면 처리 흐름으로 인한 애플리케이션 턴 수\n  - HTML 내 자바스크립트와 CSS에 의한 렌더링 영향도 분석\n  - 클라이언트 로킹 영향도 확인\n  - 클라이언트 캐시 동작 여부 확인\n  - 콘텐츠 구성 방식과 크기\n5. **네트워크 원인 분석**\n  - 전체 응답시간 중 네트워크에서 소요되는 시간이 많을 때 원인을 분석한다.\n  - 전송 데이터 : 전송 데이터 크기, 콘텐츠 수, 전문 형태, 압축 여부\n  - 통신 방식 : 프로토콜 네트워크 연결 유지 및 연결 수, 네트워크 턴 수\n  - 통신 품질 : 패킷 왕복시간, 재전송, 전송 대역폭\n\n\n### 3.2 시스템 내 응답시간 저하\n\n![](ch2/img_1.png)\n\n1. **애플리케이션 서버 응답시간 분석**\n  - 서버 내 애플리케이션 프로세스를 대상으로 스택을 분석한다.\n  - 예를 들어 사용자 요청을 처리 중인 스택이 총 100개이고 그중 64개가 SQL을 수행 중이고, 20개가 로그 라면 SQL은 65%, 로깅은 20% 비중을 차지하고 있다고 불 수 있다.\n  - 클라이언트 응답이 느린데 애플리케이션 서버 응답이 빠르다면 채널단이나 웹 서버가 느린것으로 판단할 수 있다.\n2. **채널/웹 서버 원인 분석**\n  - 웹 서버에서 애플리케이션 서버로 작업을 즉시 넘기지 못하는 원인을 찾는다.\n  - 서비스 스레드 부족 같은 병목 발생 여부를 확인하고, 웹 서버와 애플리케이션 서버 간 인터페이스 항목과 방식에 대해 분석을 진행한다.\n    - 병목발생 : 큐잉 여부, 작업 중인 스레드 수, 접속 클라이언트 수, 웹 KeepAlive 여부와 설정 시간\n    - 인터페이스 : 웹 서버와 애플리케이션 서버 간 동작 분석, 콘텐츠 유형별 서비스 담당 서버 확인, 일부 애플리케이션 서버가 비정상적으로 동작할 경우 웹 서버 서비스 분해 확인\n  - netstat, jstack, pstack 등\n3. **DB 원인 분석**\n  - SQL 응답시간이 느린 원인을 분석한다.\n  - 락 대기 유무, 실행계획, 수행 통계를 바탕으로 원인 분석\n  - 동작 중인 세션 : 현재 SQL을 수행 중인 세션의 상태(대기 이벤트)\n  - 락 대기 : 수행 중인 SQL 간 락 영향도를 확인(락 트리)\n  - 실행계획 : 저성능 SQL의 실행계획 및 실행 통계 확인\n  - 수행 통계 : DB 운영 통계\n4. **연계 서버 원인 분석**\n  - 타 시스템 서비스를 호출하므로 이를 내부와 외부로 구분해 처리시간을 측정하는 것\n5. **애플리케이션 내부 원인 분석**\n  - 애플리케이션 내부 코드에서 발생한 성능 저하 원인을 분석할 때는 수집된 스택이 핵심 자료다.\n  - 병목 빌셍 : 스레드 풀, DB 연결 풀 상태(부족 여부 확인)\n  - 불필요한 작업 : 로깅과 모니터링, 환경 반복 로딩 등\n  - 비효율적인 로직 : 업무 로직, 탐색 로직, 날짜/수치 연산 로직, 문자열 처리 로직\n  - SQL 수행 패턴 분석 : 서비스당 SQL 수행 유형과 횟수, 바인딩 변수를 기준으로 한 반복 수행 여부 분석\n  - SQL 수행로그, jstack, pstack, SDPA(분석)\n\n\n### 3.3 서비스 멈춤 현상\n\n![](ch2/img_2.png)\n\n- 프로세스가 멈춘 상태로 더 이상 사용자 요청을 처리하지 못하는 경우에도 자원 부족 여부를 먼저 확인한 후 애플리케이션 상태를 확인한다.\n- 서버 자원은 CPU 사용량과 메모리 스와핑 여부를 확인한다.\n- DB 서버는 데이터 캐시 영역이 스왑 영역으로 내라가면 급격한 성능 저하가 발생한다.\n- 자바 프로세스는 연속 Full GC로 인해 멈춤 상태에 있을 수도 있으므로 GC 상태를 모니터링해야 한다.\n- 자원에 문제가 없다면 애플리케이션 스택을 분석한다.\n  - 락 영향도와 현재 수행중인 기능\n  - 작업 스레드 소진 등\n\n\n### 3.4 시스템 전반에 걸친 성능 개선\n\n- 전체 수행시간이 긴 애플리케이션과 SQL이 시스템 자원을 가장 많이 사용한다고 볼 수 있기에 개선 효과도 크게 나ㅏ난다.\n- 애플리케이션과 SQL 모두 수행 빈도와 총 수행시간이라는 두 가지 측면에서 비중이 가장 높은 것부터 개선 가능성을 검토한다.\n  - 응용 수행시간 총합 Top 10\n  - 응숑 수행 횟수 Top 10\n  - SQL CPU 사용 총합 Top 10\n  - SQL 수행시간 총합 Top 10\n\n### 3.5 서버 자원 사용량 확인\n\n![](ch2/img_3.png)\n\n### 3.6 CPU 과다 사용 분석\n\n![](ch2/img_4.png)\n\n1. **특정 프로세스 CPU 과다 사용 작업 분석**\n  - 특정 프로세스가 CPU를 많이 사용하게 만드는 기능과 소스코드를 식별해 개선 가능성을 검토한다.\n2. **시스템 CPU 과다 사용 작업 분석**\n  - CPU를 조금씩 사용하는 프로세스가 많이 모여서 CPU 사용률이 높은 경우에는 perf, caliper 와 같은 CPU 프로파일링 도구를 사용해 시스템 전반적으로 CPU를 많이 사용하는 라이브러리 함수를 식별할 수 있다.\n3. **SQL 개선 가능성 검토**\n  - SQL 튜닝 : 실행계획 검토(사용 블록 감소), 통계 생성\n  - DB 튜닝 : DB 캐시, 테이블 입출력 분산, 동시 트랜잭션 확대\n  - 애플리케이션 튜닝 : 불필요한 수행 제거, 조회 결과 캐시, SQL 통합\n  - 오렌지 같은 SQL 튜닝 도구\n\n### 3.7 메모리 과다 사용 분석\n\n![](ch2/img_5.png)\n\n### 3.8 디스크 과다 사용 분석\n\n![](ch2/img_6.png)\n\n## 4.개선 방향성\n\n- 병렬/분산 처리\n- 비동기 처리\n- 캐시\n- 집합 처리\n- 오버헤드 제거\n- 경합 제거\n- SQL 개선\n- 송수신 효율화\n- 자원 사용 효율화\n- 물리적인 자원 증설"},{"excerpt":"1. 성능이란? 고객의 특정 업무를 대상으로 운영환경하에서 고객이 수긍할 수 있는 응답시간 내에 처리할 수 있는 거래량이라고 정의할 수 있다. 1.1 동시 사용자 성능 테스트나 운영 시 시스템에 발생하는 부하의 의미로 많이 사용되는 용어가 바로 동시 사용자다. 동시 사용자에 대한 정의는 개발자와 업무담당자간에 다르게 해석할 수 있다. 동시에 시스템에 트랜…","fields":{"slug":"/ch1/"},"frontmatter":{"date":"February 03, 2022","title":"1부 - 성능 기초","tags":["실무로 배우는 시스템 성능 최적화"]},"rawMarkdownBody":"\n## 1. 성능이란?\n\n- 고객의 특정 업무를 대상으로 운영환경하에서 고객이 수긍할 수 있는 응답시간 내에 처리할 수 있는 거래량이라고 정의할 수 있다.\n\n<!-- more -->\n### 1.1 동시 사용자\n\n- 성능 테스트나 운영 시 시스템에 발생하는 부하의 의미로 많이 사용되는 용어가 바로 동시 사용자다.\n- 동시 사용자에 대한 정의는 개발자와 업무담당자간에 다르게 해석할 수 있다.\n  - 동시에 시스템에 트랜잭션을 유발시키는 사용자\n  - 시스템과 접속을 유지하고 있는 사용자 수\n- 동시 사용자 수 = 요청 사용자 수 + 비요청 사용자 수\n\n### 1.2 처리량\n\n- 처리량은 서버가 일정 시간 내에 처리한 트랜잭션의 양이다.\n- 서버가 인식하는 트랜잭션 양과 사용자가 인식하는 트랜젹션 양은 다르다.\n  - 고객 입장에서는 화면 조회라는 1개의 트랜잭션을 보낸다.\n  - 서버 입장에서는 API, DB, 웹 등 여러 쿼리 호출이 발생한다.\n- 성능에서 중요한건 고객의 업무를 얼마나 빨리 처리할 수 있는가다.\n- 따라서 처리량의 평가 단위로서 TPS(Transaction Per Second)의 T는 고객의 업무 처리 건수가 되는 것이 의사소통이나 평가 하는데 적합하다.\n\n### 1.3 응답시간\n\n- 응답시간은 요청한 후부터 응답을 받을 때까지 소요된 시간으로 츠겆ㅇ하는 위치에 따라 여러 유형으로 나뉜다.\n  - 클라이언트 응답 시간\n    - 사용자가 요청한 후 부터 화면에 응답이 나타날 때까지 경과된 시간, 클라이언트 내부 처리시간도 포함된다.\n  - 네트워크 응답 시간\n    - 클라이언트에서 요청이 네트워크로 전송된 후부터 응답이 클라이언트 네트워크에 도착하는 데까지 경과되는 시간을 으미한다.\n  - 서버 응답 시간\n    - 서버가 사용자 요청을 받은 후 부터 처리 결과를 내보는는 데까지 경과된 응답시간이다. APM 기반으로 측정하는 경우가 여기에 해당된다.\n  - 연계 응답 시간\n    - 서버 처리 중 외부 시스템과 연계해서 처리할 경우 연계 서버에 요청을 보내 응답을 받기까지 경과된 시간이다.\n- 응답시간을 산술 평균으로 계산한다면 정확한 분석이 어려워 보통 백분율 응답시간을 사용한다.\n  - 측정시간 동안 200개의 트랜잭션이 발생했고, 가장 응답시간이 빠른 것부터 줄세워 180등을 기록한 트랜잭션의 응답시간이 3.5였다면, 해당 업무의 90% 응답시간은 3.5초가 된다. `p90`\n\n\n### 1.4 자원\n\n- 서버의 CPU, 메모리, 디스크, 네트워크, WAS의 스레드 풀, DB연결 풀, 힙 메모리, 프로세스 수, 오픈 가능한 커서 수, 공유 캐시 메모리 등 물리적인 자원부터 소프트웨어 설정값까지 다양한 자원이 있다.\n- 성능 측면에서 자원은 한정된 값을 가진 시스템 구성 요소 중 애플리케이션이 동작할 때 사용하며, `부족한 경우\n  나 사용량 변화에 따라 성능에 영향을 미치는 요소`를 의미한다.\n\n#### 1.4.1 적정성\n\n- 자원 사용량에 대한 목표 달성과 부족 여부를 확인하는 것이다.\n- 자원이 부족한 경우 경함과 대기가 발생해 성능이 저하되므로 늘려줘야 하지만 다른 자원에 악영향을 주어 개선 효과를 보지 못할 수도 있다.\n\n#### 1.4.2 효율성\n\n- 동일한 TPS를 기준으로 할 때 CPU나 메모리를 적게 사용하는 시스템이 효율적으로 작업을 수행한 것 이다.\n- DB 사용량을 줄이고 애플리케이션 코드의 수행시간을 줄여 시스템 자원을 더 적게 사용하도록 개선함으로써 효율성을 높인다.\n\n#### 1.4.3 안정성\n\n- 시스템 운영시간이 지남에 따라 성능이 저하되거나 장애가 발생하는 등의 문제가 발생하지 않아야 한다.\n\n#### 1.4.4 가용성\n\n- 일정 기간 동안 시스템이 정상적으로 서비스된 시간 비율을 의미한다.\n- 카드 승인 시스템 같은 시스템은 장애는 사업 기회의 손실로 이어지므로 100%에 가까운 가용성을 유지해야 한다.\n\n#### 1.4.5 확장성\n\n- 확장성은 향후 시스템 사용량 증가에 따라 시스템 증설이 필요할 때 각 자원이 얼마나 용이하게 증설될 수 있는가를 평가하는 것 이다.\n\n## 2. 성능 특성\n\n### 2.1 성능 곡선\n\n### 2.2 성능에 대한 이해\n\n- 성능은 업무와 시스템 특성에 따라 다르게 나타난다.\n  - 시스템에 A,B 두 업무가 있다고 가정할 때 각 업무의 비중이 10%,90% 일 때와 90%,10% 일 때 시스템의 최대 성능과 응답시간이 다를 것이다.\n  - 따라서 시스템의 성능을 이야기할 때는 업무의 고유한 특성과 시나리오하에서만 논의할 수 있다.\n- 모든 시스템에 일괄 적용할 수 있는 응답시간 기준은 없고 100% 만족시킬 수도 없다.\n  - 화면 구성이 비슷하더라도 업무의 성격에 따라 처리하는 데이터의 양과 로직의 복잡도가 달라진다.\n- 동시 사용자 수가 시스템 성능을 의미하는 것은 아니다.\n  - 웹 기반 시스템에서는 동시 사용자(접속자) 수 보다 초당 들어오는 요청의 수, 웹 서버에 물리적으로 맺어진 네트워크 연결 수가 성능에 더 큰 영향을 준다.\n- 시스템 성능은 비용과 수익으로 평가할 수도 있다.\n  - 시스템 자원 부족으로 서버를 추가 도입하거나 부족한 자원을 증설하기 위해서는 비용이 든다.\n\n## 3. 성능 이론\n\n### 3.1 기초 성능 이론\n\n### 3.2 사용률 이론\n\n### 3.3 비율 분석\n\n## 4. 성능 테스트\n\n### 4.1. 성능 테스트 유형\n\n### 4.2 성능 테스트 구성 요소\n\n### 4.3 성능 테스트 시 주의사항\n\n- 성능 테스트는 통상 제약된 환경에서 테스트하므로 실제 운영 시스템 대상으로 테스트를 진행했더라도 운영에 들어가면 예상치 못한 장애가 발생하기도 한다.\n\n#### 4.3.1 테스트 데이터\n\n- 테스트 데이터에 따라 확연히 다른 결과가 나오는 경우도 많기 때문에 성능 테스트 시에는 테스트 데이터에 대해 다음과 같은 사항을 고려해야 한다.\n  - **시스템 데이터(데이터 대상 DB)**\n    - 통상 전체 성능의 70% 이상이 DB에 자우되는데, 테스트 대상이 되는 테이블의 데이터 양이나 패턴이 다르면 쿼리의 실행계획이 달라져 성능이 다르게 나타난다.\n    - 데이터가 소량이면 실제 디스크 입출력이 일어나야 하는데 모두 메모리에 로드되어 성능이 빠른 것으로 착각할 수 있다.\n    - 원칙적으로 성능 테스트는 실 데이터가 전환된 데이터베이스를 대상으로 수행해야 한다.\n  - **스크립트 데이터(입력용 데이터)**\n    - 소량의 스크립트 데이터를 사용한 경우 테스트 초기 입력 데이터가 DB에 메모리에 캐시됨으로써 성능이 좋게 나올 수 있다.\n  - **초기 데이터 제로 테이블**\n    - 시스템을 오픈할 때 비어있는 테이블은 시간이 지나면서 성능 문제를 일으키는 경우가 많다.\n    - 초기 건수가 0이지만 운영하면서 건수가 큰 폭으로 증가하는 테이블은 데이터가 쌓여있을 때의 통계정보로 테이블 통계정보를 변경해 달라고 요청해야 한다.\n\n#### 4.3.2 화면 처리시간\n\n- 대부분의 성능 테스트 도구는 클라이언트 측 네트워크 시간을 기준으로 응답시간을 측정한다.\n- 클라이언트마다 PC 환경이 다르고, 테스트 환경에서는 클라이언트에서 수행되는 로직이 동작할 경우 CPU 등 자원부족으로 성능 측정이 부정확하게 되기 때문이다.\n- 중요 화면에 대해서는 화면 응답시간을 측정해 성능 기준 만족 여부를 평가하고, 서버 처리시간과 비교 분석해 클라이언트 성능 개선이 필요한지 여부를 판단한다.\n\n#### 4.3.3 네트워크\n\n- 성능 테스트 시 부하 발생기가 연결돼 있는 스위치를 바로 백본 스위치에 연결해 테스트를 수행하는 경우가 많다.\n- 이는 내부 네트워크와 서버 중심으로 처리시간을 측정하고, 외부 네트워크는 제외하는 것 이다.\n- 서버 문제가 없음에도 네트워크 지연으로 애플리케이션 종료가 지연되어 작업 프로세스나 스레드 풀이 소진되어 큐잉이 발생함으로써 전체 사용자가 성능 저하를 경함할 수 있다.\n\n#### 4.3.4 가상 사용자 특성\n\n- 실사용자라면 응답이 20~30초씩만 늦어져도 기다리지 못하고 다시 반복요청한다.\n- 즉 성능 테스트하에서는 특정 가상 사용자 수 이상 큐잉이 발생할 가능성은 낮지만 운영 환경에서는 동일 사용자에 의한 서비스 반복 요청이 이뤄져 대량의 큐잉이 발생할 수 있다.\n- 테스트 환경에서만 발생하는 패턴임에도 실제 환경에서도 발생하는 패턴으로 인식해버릴 수도 있다.\n\n#### 4.3.5 업무 시나리오\n\n- 각 테스트 대상 업무에서 부수적인 서비스 호출을 제외하고 중요 서비스 호출만 시나리오에 포함시키면 운영 시 측정한 성능과 테스트 시 측정한 성능이 달라질 수 있다.\n- 부하 발생기가 일으키는 서비스 요청 이외에 백엔드에서 수행되는 배치나 후속 작업들을 생략하는 것이다.\n- 성능 측정 대상으로서 중요성은 떨어지더라도 정상적인 운영 시 시스템 백엔드에서 일정하게 발생하는 부하가 있다면 성능 테스트 시나리오에 포함해야 한다.\n\n#### 4.3.6 대상 업무와 성능 개선\n\n- 자바 기반 애플리케이션의 경우 한 개의 업무에서 발생한 메모리 누수나 대량 데이터 조회 문제로도 전체 업무에 성능 저하와 장애가 발생할 수 있다.\n- 성능 테스트에서 목표를 만족한 것은 시스템 오픈을 위한 최소한의 기준일 뿐, 안정적으로 운영될 것이라고 담보하지는 못한다."},{"excerpt":"분산 시스템을 다루는 것은 한 컴퓨터에서 실행되는 소프트웨어를 작성하는 일과는 다르다. 뭔가 잘못될 수 있고 새롭고 흥미진진한 방법이 많다는 점이다. 이번장은 분산 시스템에서 잘못될지도 모르는 것에 관한 개요이다. 결함과 부분 장애 단일 컴퓨터에서 실행되는 소프트웨어는 하드웨어가 올바르게 동작하면 같은 연산은 항상 같은 결과를 낸다. 좋은 소프트웨어가 설…","fields":{"slug":"/ch8/"},"frontmatter":{"date":"February 02, 2022","title":"8장 - 분산 시스템의 골칫거리","tags":["데이터 중심 애플리케이션 설계"]},"rawMarkdownBody":"\n- 분산 시스템을 다루는 것은 한 컴퓨터에서 실행되는 소프트웨어를 작성하는 일과는 다르다.\n    - 뭔가 잘못될 수 있고 새롭고 흥미진진한 방법이 많다는 점이다.\n- 이번장은 분산 시스템에서 잘못될지도 모르는 것에 관한 개요이다.\n\n<!-- more -->\n\n## 결함과 부분 장애\n\n- 단일 컴퓨터에서 실행되는 소프트웨어는 하드웨어가 올바르게 동작하면 같은 연산은 항상 같은 결과를 낸다.\n- 좋은 소프트웨어가 설치된 각각의 컴퓨터는 보통 완전하게 동작하거나 전체 장애가 발생하지 그 중간 상태가 되지는 않는다.\n- 네트워크로 연결된 여러 컴퓨터에서 실행되는 소프트웨어를 작성할 때는 근본적으로 상황이 다르다.\n- 분산 시스템에서는 시스템의 어떤 부분은 잘 동작하지만 다른 부분은 예측할 수 없는 방식으로 고장난다. 이를 `부분 장애(partial failure)`라고 한다. `부분 장애는 비결정적이라서 어렵다.`\n- 비결정성과 부분 장애 가능성이 분산 시스템을 다루게 어렵게 한다.\n\n<aside>\n💡  신뢰성 없는 구성 요서를 사용해 신뢰성 있는 시스템 구축하기 \n\n네트워크의 오류 수정 코드, TCP 프로토콜이 대표적인 예이다.\n \n오류 수정 코드는 무선 네트워크에서 발생하는 전파 장애 등의 이유로 일부 비트가 잘못되는 통신 채널을 통해 디지털 데이터를 정확히 전송할 수 있게 한다.\n\nTCP는 신뢰성이 없는 IP 계층 위에서 손실된 패킷을 재전송하고 중복된 것은 제거하여 패킷을 보낸 수넛에 맞춰 재조립되도록 보장해준다.\n\n</aside>\n\n## 신뢰성 없는 네트워크\n\n- 분산 시스템을 구축하는 유일한 방법은 아니지만 몇 가지 이유로 인터넷 서비스로 구축하는 방법이 주된 방법이 됐다.\n- 인터넷과 데이터센터 내부 네트워크 대부분은 비동기 패킷 네트워크다.\n- 노드에서 다른 노드로 패킷을 보낼 수 있지만 네트워크는 패킷이 언제 도착할지 혹은 메시지가 도착하기는 할 것인지 보장하지 않는다.\n- 요청을 보내고 응답을 기다릴 때 여러가지가 잘못될 수 있다.\n    - 요청이 손실됐을 수 있다.\n    - 요청이 큐에서 대기하다 나중에 전송될 수 있다.\n    - 원격 노드의 장애\n    - 원격 노드의 일시적인 중지\n    - 원격 노드 응답의 손실\n    - 원격 노드 응답의 지연\n- 이런 문제를 다루는 흔한 방법은 `타임아웃`이다. 얼마 간의 시간이 지나면 응답 대기를 멈추고 응답이 도착하지 않는다고 가정한다.\n\n#### 현실의 네트워크 결함\n\n- 아직 신뢰성 있는 네트워크를 만드는데 성공하지 못했다.\n- 네트워크 중단의 주요 원인인 인적 오류로부터 보호해주지 못하기 때문이다.\n- 네트워크 결함이 드물더라도 **일어날 수 있고** 소프트웨어가 이를 처리할 수 있어야 한다.\n- 반드시 네트워크 결함을 견뎌내도록 처리할 필요는 없다.\n- 네트워크가 평상시에는 상당히 믿을 만하다면 네트워크에 문제가 있을 때 그냥 사용자에게 오류 메시지를 보여주는 것도 타당한 방법이다.\n\n#### 결함 감지\n\n- 많은 시스템은 결함 있는 노드를 자동으로 감지할 수 있어야 한다.\n    - 로드 밸런서는 죽은 노드로 요청을 그만 보내야 한다.\n    - 단일 리더 복제를 사용한다면 분산 데이터베이스에서 리더에 장애가 나면 팔로워 중 하나가 리더로 승격돼야 한다.\n- 하지만 네트워크에 관한 불확실성 때문에 노드가 동작 중인지 아닌지 구별하기 어렵다.\n- 뭔가 동작하지 않는다고 명시적으로 알려주는 피드백을 받을 수 있다.\n\n### 타임아웃과 기약 없는 지연\n\n- 타임아웃만이 결함을 감지하는 확실한 수단이라면 타임아웃은 얼마나 길어야 될까?\n- 타임아웃이 길면 노드가 죽었다고 선언될 때까지 기다리는 시간이 길어진다.\n- 타임아웃이 짧으면 노드가 일시적으로 느려졌을 뿐인데도 죽었다고 잘못 선언할 위험이 높아진다.\n    - 노드가 죽었다고 선언되면 그 노드의 책무를 다른 노드로 전달돼야 해서 다른 노드와 네트워크에 추가적인 부하를 준다.\n- 비동기 네트워크는 패킷을 가능한 빨리 보내려고 하지만 패킷이 도착하는 데 걸리는 시간에 상한치는 없다.\n- 서버 구현은 대부분 어떤 최대 시간 내에 요청을 처리한다고 보장할 수 없다.\n\n#### 네트워크 혼잡과 큐 대기\n\n- 자동차를 운전할 때 코통 체증 때문에 이동 시간이 달리지는 것 처럼 컴퓨터 네트워크에서 패킷 지연의 변동성은 큐 대기 때문인 경우가 많다.\n- 여러 장비가 같은 목적지로 네트워크 트래픽을 보내면 스위치 큐가 가득찰 수 있다.\n- TCP는 타임아웃 안에 확인 응답을 받지 않으면 패킷이 손실됐다고 간주하고 손실된 패킷은 자동으로 재전송한다.\n    - 애플리케이션에서는 패킷 손실이나 재전송이 보이지 않지만 그 결과로 생기는 지연은 보인다.\n- 지연의 변동성이 얼마나 되는지 알아내는 방법은 어렵다.\n- 더 좋은 방법으로는 고정된 타임아웃을 설정하는 대신 시스템이 지속적으로 응답 시간과 그들의 변동성을 측정하고 관찰된 응답 시간 분포에 따라 타임아웃을 자동으로 조절하게 하는 것이다. 카산드라가 사용한다.\n\n<aside>\n💡 화상 회의나 인터넷 전화처럼 지연 시간에 민간함 애플리케이션은 TCP 대신 UDP를 사용한다.\n신뢰성과 지연 변동성 사이에 트레이드오프 관계가 있다. UDP는 흐름 제어를 하지 않고 손실된 패킷을 재전송하지 않으므로 네트워크 지연이 크게 변하게 하는 원인 중 일부를 제거한다.\n\n</aside>\n\n### 동기 네트워크 대 비동기 네트워크\n\n- 동기식 네트워크가 대표적인 예는 고정 회선 전화 네트워크다.\n    - 전화 네트워크는 극단적인 신뢰성을 지닌다.\n    - 음성 프레임이 지연되거나 통화가 유실되는 일은 매우 드물다.\n    - 통화를 할 때 회선(circuit)이 만들어지고 통화를 하는 두 명 사이에 있는 전체 경로를 따라서 그 통화에 대해 고정되고 보장된 양의 대역폭이 만들어진다.\n    - 데이터가 여러 라우터를 거치더라도 큐 대기 문제를 겪지 않는다.\n- 회선은 만들어져 있는 동안 다른 누구도 사용할 수 없는 고정된 양의 예약된 대역폭이지만 TCP 연결의 패킷은 가용한 네트워크 대역폭을 기회주의적으로 사용한다.\n- 인터넷 네트워크는 회선 교환 방식으로 패킷을 교환한다.\n    - 이들은 순간적으로 몰리는 트래픽에 최적화됐기 때문이다.\n    - 통화는 초당 비트 개수가 고정돼지만 웹 페이지 요청은 가능하면 빨리 완료되기만 하면 된다.\n    - 순간적으로 몰리는 데이터 전송에 전용 회선을 쓰면 네트워크 용량을 낭비하고 전송이 불필요하게 느려진다.\n    - TCP는 가용한 네트워크 용량에 맞춰 데이터 전송률을 동적으로 조절한다.\n    \n\n## 신뢰성 없는 시계\n\n- 네트워크에 있는 개별 장비는 자신의 시계를 갖고 있다.\n- 이 장치는 정확하지 않아서 각 장비는 자신만의 시간 개념이 있으며 이는 다른 장비보다 약간 빠를 수도 느릴 수도 있다.\n\n### 단조 시계 대 일 기준 시계\n\n- 컴퓨터는 최소 두 가지 종류의 시계를 갖고 있다.\n    - **일 기준 시계(time-of-day clock)**\n    - **단조 시계(monotonic clock)**\n\n#### **일 기준 시계(time-of-day clock)**\n\n- 일 기준 시계는 현재 날짜와 시간을 반환한다.\n    - 예를 들어 자바의 `System.currentTimeMillis()`는 `에포크(epoch`) 이래로 흐른 밀리초를 반환한다.\n    - 에포크(epoch)란 UTC(협정세계시) 1970년 1월 1일 자정을 가르킨다.\n- 일 기준 시계는 보통 NTP로 동기화 된다.\n- 로컬 시계가 NTP 서버 보다 너무 앞서면 강제로 리셋되어 과거 시점으로 거꾸로 뛰는 것처럼 보일 수 있다.\n\n#### **단조 시계(monotonic clock)**\n\n- 단조 시계는 타임아웃이나 서비스 응답 시간 같은 시간 구간을 재는 데 적합하다.\n    - 자바의 `System.nanoTime()` 이 있다.\n- 단조 시계란 이름은 항상 앞으로 흐른다는 사실에서 나왔다.\n    - 일 기준 시계는 시간이 거꾸로 뛸 수도 있다.\n\n### 시계 동기화와 정확도\n\n- 단조 시계는 동기화가 필요 없지만 일 기준 시계는 NTP서버로 동기화되어야 한다.\n- 하드웨어 시계나 NTP 서버는 시계 정확도에 오차가 생길 수 있다.\n- 충돌 해소 전략 중 하나인 `최종 쓰기 승리(last write wins, LWW)` 는 이런 시간의 오차로 문제가 발생할 수 도 있다.\n    - 따라서 가장 최근 값을 유지하고 다른 것들을 버림으로써 충돌을 해소하고 싶어도 **최근**의 정의는 로컬 일 기준 시계에 의존하며 그 시계는 틀릴 수 있다는 것을 아는게 중요하다.\n\n## 지식, 진실, 그리고 거짓말\n\n- 분산 시스템에는 공유 메모리가 없고 지연 변동이 큰 신뢰할 수 없는 네트워크를 통해 메시지를 보낼 수 있을 뿐이며 부분 장애, 신뢰성 없는 시계, 프로세스 중단에 시달릴 수 있다.\n- 원격 노드가 응답하지 않으면 그 노드가 어떤 상태에 있는지 알 방법은 없다.\n- 분산 시스템에서 우리는 동작에 관해 정한 가정을 명시하고, 이런 가정을 만족시키는 방식으로 실제 시스템을 설계 할 수 있다.\n- 이번 장의 나머지 부분에서 분산 시스템의 지식과 진실에 관한  개념을 살펴본다.\n\n### 진실은 다수결로 결정된다\n\n- 분산 시스템은 한 노드에만 의존할 수는 없다. 노드에 언제든 장애가 나서 잠재적으로 시스템이 멈추고 복구할 수 없게 될 수 있기 때문이다.\n- 여러 분산 알고리즘은 정족수, 즉 노드들 사이의 투표에 의존한다.\n    - 특정한 노드 하나에 대한 의존을 줄이기 위해 결정을 하려면 여러 노드로부터 어떤 최소 개수의 투표를 받아야 한다.\n\n#### 리더와 잠금\n\n- 분산 시스템에서 어떤 노드를 선택하는 행위`(파티션의 리더, 잠금을 획득한 자, 사용자명을 차지는데 성공한 사용자의 요청)`는 주의해야한다.\n- 어떤 노드가 이전에 리더였더라도 시간이 흐른 사이에 다른 노드들이 그 노드가 죽었다고 선언하면 그 노드는 강등되고 다른 리더가 이미 선출됐을지도 모르기 때문이다.\n- 분산 잠금을 잘못 구현 : 클라이언트 1은 임차권이 마료됐는데도 여전히 유효하다고 생각해서 저장소에 있는 파일을 오염시킨다.\n\n#### 펜싱 토큰\n\n- 위의 분산 잠금 문제를 해결하기 위해서는 자신이 `선택된 자`라고 잘못 믿고 있는 노드가 나머지 시스템을 방해할 수 없도록 보장해야 한다.\n- 이 목적을 달성하는 기법으로 `펜싱(fencing)`이 있다.\n- 잠금 서버가 잠금이나 임차권을 승인할 때마다 `펜싱 토큰`도 반환하도록 한다.\n    - 펜싱 토큰은 잠금이 될 때마다 증가하는 숫자다.\n    - 클라이언트가 쓰기 요청을 할 때 이 펜싱 토큰을 함께 보내 현재 알고 있는 펜싱 토큰값과 비교하여 선택된 자를 식별할 수 있다.\n- 이 메커니즘은 오래된 토큰을 사용해서 쓰는 것을 거부함으로써 토큰을 확인 역활을 한다.\n\n### 비잔틴 결함\n\n- 노드가 거짓말(임의의 결함이 있거나 오염된 응답을 보냄)을 할지도 모른다는 위험이 있다면 훨씬 더 어려워진다.\n    - 펜신 토큰에서 클라이언트는 고의로 가짜 펜신 토큰을 보내면 시스템의 보장을 무너뜨릴 수 있다.\n- 어떤 노드가 실제로는 받지 않은 메시지를 받았다고 주장할 수 있는데 이런 동작을 `비잔틴 결함(Byzantine fault)`라고 한다.\n- 이렇게 신뢰할 수 없는 환경에서 합의에 도달하는 문제를 `비잔틴 장군 문제`라고 한다.\n- 일부 노드가 오동작하고 프로토콜을 준수하지 않거나 악의적인 공격자가 네트워크를 방해하더라도 시스템에 계속 올바르게 동작한다면 `비잔틴 내결함성을 지닌다`라고 한다.\n- 웹 애플리케이션은 웹브라우저 같은 클라이언트 행동이 임의적이고 악의적이라고 예상해야 한다. 이는 입력 확인, 변환, 출력 이스케이핑이 중요한 이유다.\n    - 예를 들어 SQL 인젝션이나 XSS 같은 해킹을 막아야 한다.\n- 대부분의 비잔틴 내결함성 알고리즘은 노드의 2/3 이상의 다수가 올바르게 동작하기를 요구한다.\n\n### 정리\n\n- 분산 시스템에서 나타날 수 있는 문제는 광범위하다.\n    - 네트워크 결함\n    - 노드 간 시계의 오차\n    - 원격노드의 상태를 알 수 없는 문제\n- 대부분의 분산 알고리즘은 원격 노드를 아직 쓸 수 있는지 결정하기 위해 타임아웃을 사용한다.\n- 분산 시스템에선 한 노드에만 의존할 수 없으므로 정족수를 이용하는 프로토콜이 필요하다."},{"excerpt":"애매모호한 트랜잭션의 개념 ACID의 의미 트랜잭션이 제공하는 안정성 보장은 원자성(Atomicity), 일관성(Consistency), 격리성(Isolation), 지속성(Durability) 을 의미하는  로 잘 알려져 있다. 그러나 현실에서는 데이터베이스마다 ACID 구현이 재각각이다. 시스템에서 실제로 어떤 것을 기대할 수 있는지 분명하지 않다. …","fields":{"slug":"/ch7/"},"frontmatter":{"date":"February 01, 2022","title":"7장 - 트랜잭션","tags":["데이터 중심 애플리케이션 설계"]},"rawMarkdownBody":"\n## 애매모호한 트랜잭션의 개념\n\n### ACID의 의미\n\n- 트랜잭션이 제공하는 안정성 보장은 **원자성(Atomicity), 일관성(Consistency), 격리성(Isolation), 지속성(Durability)** 을 의미하는 `ACID` 로 잘 알려져 있다.\n- 그러나 현실에서는 데이터베이스마다 ACID 구현이 재각각이다. 시스템에서 실제로 어떤 것을 기대할 수 있는지 분명하지 않다.\n\n<!-- more -->\n\n#### 원자성\n\n- 원장성은 클라이언트가 쓰기 작업 몇 개를 실행하려고 하는데 그 중 일부만 처리된 후 결함이 생기면 무슨 일이 생기는지 설명한다.\n- 여러 쓰기 작업이 하나의 원자적 단위인 트랜잭션으로 묶여 있는데 결함 때문에 커밋될 수 없다면 어보트되고 지금까지 실행한 쓰기를 무시하거나 취소해야하 한다.\n- 원자성은 여러 프로세스가 동시에 같은 데이터에 접근하려고 할 때 무슨 일이 생기는지 설명하지 않는다.\n- 오류가 생겼을 때 트랜잭션을 어보트하고 해당 트랜잭션에서 기록한 모든 내용을 취소하는 `어보트 능력(abortability)` 능력이 원자성의 결정적 특징이다.\n\n#### 일관성\n\n- 일관성이란 단어는 굉장히 여러 의미로 쓰인다.\n    - 복제 일관성과 비동기식 복제되는 시스템에서 발생하는 최종적 일관성 문제\n    - 일관성 해싱은 어떤 시스템들에서 재균형화를 위해 사용하는 파티셔닝 방법\n    - CAP 정리에서 일관성은 선형성을 의미한다.\n    - ACID 맥락에서 일관성은 데이터베이스가 “좋은 상태”에 있어야 한다는 애플리케이션에 특화된 개념을 가르킨다.\n- 일관성의의 아이디어는 데이터에 관한 어떤 불변식이 항상 진실이어야 한다는 것이다.\n- 트랜잭션이 이런 불변식이 유요한 데이터베이스에서 시작하고 트랜잭션에서 실행된 모든 쓰기가 유효성을 보존한다면 불변식이 항상 만족된다고 확신할 수 있다.\n- 일관성의 아이디어는 애플리케이션의 불변식 개념에 의존하고, 일관성을 유지하도록 트랜잭션을 올바르게 정의하는 것은 애플리케이션의 책임이다.\n- 데이터베이스 불변식을 위반하는 잘못된 데이터를 쓰지 못하도록 막을 수 없다\n    - 외래 키, 기본키 제약 조건같은 특정 종류의 불변식을 지원하지만 일반적으로 애플리케이션에서 데이터가 유효한지 아닌지를 정의하고 데이터베이스는 데이터를 저장할 뿐이다.\n\n#### 격리성\n\n- 클라리언트들이 동일한 데이터베이스 레코드에 접근하면 동시성 문제가 발생한다.\n- 여러 트랜잭션이 동시에 실행됐더라도 트랜잭션이 커밋됐을 때의 결과가 트랜잭션이 순차적으로 실행됐을 때의 결과와 동일하도록 보장한다.\n\n#### 지속성\n\n- 트랜잭션이 성공적으로 커밋됐다면 하드웨어 결함이 발생하거나 데이터베이스가 죽더라도 트랜잭션에서 기록한 모든 데이터는 손실되지 않는다는 보장이다.\n\n### 단일 객체 연산과 다중 객체 연산\n\n- ACID에서 원자성과 격리성은 클라이언트가 한 트랜잭션 내에서 여러 번의 쓰기를 하면 데이터베이스가 어떻게 해야하는지를 서술한다.\n- 다중 객체 트랜잭션은 어떤 읽기 연산과 쓰기 연산이 동일한 트랜잭션이 속하는지 알아낼 수단이 있어야 한다.\n- 관계형 데이터베이스에서 이것은 전형적으로 클라이언트와 데이터베이스 서버 사이의 TCP 연결을 기반으로 한다.\n- 어떤 특정 연결 내에서 `BEGIN TRANSACTION` 문과 `COMMIT` 문 사이의 모든 것은 같은 트랜잭션에 속하는 것으로 여긴다.\n- 반명 비관계형 데이터베이스는 한 연산 내에서 여러 키를 갱신하는 다중 객체 연산을 묶는 방법이 없는 경우가 많다.\n- 어떤 키에 대한 연산은 성공하고 나머지 키에 대한 연산은 실패해서 데이터베이스가 부분적으로 갱신된 상태가 될 수 있다.\n\n#### 단일 객체 쓰기\n\n- 저장소 엔진들은 보편적으로 한 노드에 존재하는 단일 객체 수준에서 원자성과 격리성을 제공하는 것을 목표로 한다.\n- 어떤 데이터베이스는 증가 연산처럼 더 복잡한 원자적 연산을 제공하기도 한다.\n- 이러한 단일 객체 연산은 여러 클라이언트에서 동시에 같은 객체에 쓰려고 할 때 갱신 손실을 방지하므로 유용하다.\n\n#### 다중 객체 트랜잭션의 필요성\n\n- 다중 객체 트랜잭션은 여러 파티션에 걸쳐서 구현하기가 어렵고 매우 높은 가용성과 성능이 필요한 곳에서는 방해가 되는 시나리오도 있기 때문에 지원하기가 어렵다.\n- 단일 객체 삽입, 갱신, 삭제만으로 충분한 사용 사례가 있다. 트랜잭션이 없더라도 이런 애플리케이션ㅇ들은 구현할 수 있다.\n- 하지만 원자성이 없으면 오츄 처리가 훨씬 더 복잡해지고 격리성이 없으면 동시성 문제가 생길 수 있다.\n\n#### 오류와 어보트 처리\n\n- 트랜잭션의 핵심 기능은 오류가 생기면 어보트되고 아전하게 재시도할 수 있다는 것이다.\n- 하지만 리더 없는 복제를 사용하는 데이터스토어는 이러한 철학을 따르지 않는다. `최선을 다하는 원칙`을 기반으로 더 많은 일을 한다.\n\n## 완화된 격리 수준\n\n- 두 트랜잭션이 동일한 데이터에 접근하지 않으면 서로 의존하지 않으므로 병렬 실행 될 수 있다.\n- 동시성 문제(경쟁 조건)는 트랜잭션이 다른 트랜잭션에서 동시에 변경한 데이터를 읽거나 두 트랜잭션이 동시에 같은 데이터를 변경하려고 할 때만 나타난다.\n- `트랜잭션 격리`를 제공함으로써 애플리케이션 개발들에게 동시성 문제를 감췄다.\n- 직렬성 격리는 성능 빙용이 있고 많은 데이터베이스들은 그 비용을 지불하려고 하지 않는다.\n- 따라서 어떤 동시성 이슈로부터는 보호해주지만 모든 이슈로부터 보호해주지는 않는 완화된 격리 수준을 사용하는 시스템들이 흔하다.\n- 이번 절에서는 완화된(비직렬성) 격리 수준 몇 가지를 살펴보고 발생할 수 있는 경쟁 조건과 발생할 수 없는 경쟁 조건을 설명한다.\n\n### 커밋 후 읽기\n\n- 가장 기본적인 수준의 트랜잭션 격리는 `커밋 후 읽기(read committed)`다.\n    - 데이터베이스 읽을 때 커밋된 데이터만 보게 된다. (더티 읽기가 없음)\n    - 데이터베이스에서 쓸 때 커밋된 데이터만 덮어쓰게 된다. (더티 쓰기가 없음)\n\n#### 더티 읽기 방지\n\n- 트랜잭션이 데이터베이스에 데이터를 썻지만 아직 커밋되거나 어보트되지 않았을 때, 다른 트랜잭션이 커밋되지 않은 데이터를 읽을 수 있는 것을 더티 읽기라고 부른다.\n    - 트랜잭션이 일부는 갱신된 값을, 일부는 갱신되지 않은 값을 볼 수 있다.\n    - 커밋되지 않은 데이트를 볼 수 있다.\n\n#### 더티 쓰기 방지\n\n- 아직 커밋되지 않은 데이터에 다른 트랜잭션이 쓰기 작업을 하는 것을 `더티 쓰기(dirty write)`라고 한다.\n\n#### 커밋후 읽기 구현\n\n- 더티 쓰기의 가장 흔한 방법으로 데이터베이스는 로우 수준 잠금을 사용해 더티 쓰기를 방지한다.\n    - 트랜잭션에서 특정 객체(로우나 문서)를 변경하고 싶다면 먼저 해당 객체에 대한 잠금을 획득하고, 트랜잭션이 완려될 때까지 잠금을 보유하고 있어야 한다.\n    - 다른 트랜잭션이 쓰기를 원한다면 첫 번째 트랜잭션이 완료되어 잠금을 얻어 진행할 수 있다.\n- 더티 읽기는 잠금을 써서 객체를 읽기 원하는 트랜잭션이 잠시 잠금을 획득한 후 읽기가 끝난 후 바로 해제하게 하는 것 이다.\n    - 그러나 읽기 잠금은 트랜잭션들의 응답 시간에 해를 끼치며 운용성이 나쁘다.\n    - 쓰여진 모든 객체에 대해 데이터베이스는 과거에 커밋된 값과 현재 쓰기 잠금을 갖고 있는 트랜잭션에서 쓴 새로운 값을 모두 기억한다.\n    - 해당 트랜잭션이 그 객체를 읽으려고 하면 과거의 값을 읽게 된다.\n\n### 스냅숏 격리와 반복 읽기\n\n- 커밋된 읽기 격리 수준을 사용하더라도 동시성 버그가 생길 수 있다.\n    - 앨리스는 두 계좌에 500달러 씩 있고, 한 계좌에서 다른 계좌로 100달러를 전송하는 트랜잭션을 실행한다.\n    - 트랜잭션이 처리되고 있는 순간에 계좌 잔고를 보게 되면 입금되기 전 상태인 500달러, 출금된 후 상태인 400달러를 보게되어 총 900달러만 있는 것처럼 나온다.\n    - 앨리스가 봤던 계좌 잔고들은 읽은 시점에 커밋된 상태였다.\n    - 이런 현상을 `비반복 읽기(nonrepeatable read)`나 `읽기 스큐(read skew`)라고 한다.\n    - 스냅\n- 스냅숏 격리는 이런 문제의 가장 흔한 해결책이다.\n    - 각 트랜잭션은 데이터베이스의 일관된 스냅숏으로부터 읽는다.\n    - 즉 트랜잭션은 시작할 때 데이터베이스에 커밋된 상태였던 모든 데이터를 본다.\n\n#### 스냅숏 격리 구현\n\n- 스냅숏 격리 구현은 커밋 후 읽기 격리처럼 쓰기 잠금을 사용한다. 그러나 읽을 때는 아무 잠금도 필요하지 않다.\n- 스냅숏 격리의 핵심 원리는 `읽는 쪽에서 쓰는 쪽을 결코 차단하지 않고 쓰는 쪽에서 읽는 쪽을 결코 차단하지 않는다는` 것이다.\n- 따라서 데이터베이스는 잠금 경쟁 없이 일관성 있는 스냅숏에 오래 실행되는 읽기 작업을 처리할 수 있다.\n- 여러 트랜잭션에서 서로 다른 시점의 데이터베이스 상태를 봐야 할 수도 있기 때문에 데이터베이스는 객체마다 커밋된 버전 여러 개를 유지할 수 있어야 한다.\n- 이런 기법을 `다중 버전 동시성 제어(MVCC)`라고 한다.\n- 데이터베이스가 커밋 후 읽기 격리만 제공할 필요가 있다면 객체마다 커멋된 버전, 커멋되지 않은 버전 두 개씩만 유지하면 충분하다.\n    - 커밋 후 읽기는 질의마다 독립된 스냅숏을 사용하고 스냅숏 격리는 전체 트랜잭션에 대해 동일한 스냅숏을 사용하는 것이다.\n\n### 갱신 손실 방지\n\n- 커밋 후 읽기와 스냅숏 격리 수준은 동시에 실행되는 쓰기 작업이 있을 때 읽기 전용 트랜잭션이 무엇을 볼 수 있는지에 대한 보장과 관련된 것 이다.\n- 갱신 손실 문제는 애플리케이션이 데이터베이스에서 값을 읽고 변경한 후 변경된 값을 다시 쓸 때 발생할 수 있다.\n- 이 작업을 동시에 하면 두 번째 쓰기 작업이 첫 번째 변경을 포함하지 않으므로 변경 중 하나는 손실될 수 있다.\n\n#### 원자적 쓰기 연산\n\n- 이 연산은 애플리케이션 코드에서 read-modify-write 주기를 구현할 필요를 없애 준다\n- 다음 명령은 대부분의 관계형 데이터베이스에서 동시성 안전(concurrency-safe)하다.\n\n```jsx\nUPDATE conters SET value = value + 1 WHERE key = 'foo';\n```\n\n- 원자적 연산은 보통 객체를 읽을 때 독접적인(exclusive) 잠금을 획득해서 구현한다. 갱신이 적용될 때까지 다른 트랜잭션에서 그 객체를 읽지 못한다.\n- ORM 프레임워크를 사용하면 데이터베이스가 원자적 연산을 사용하는 대신  read-modify-write 주기를 실행하는 코드를 작성하기 쉽다.\n\n#### 명시적인 잠금\n\n- 데이터베이스에 내장된 원자적 연산이 필요한 기능을 제공하지 않을 때 갱신 손실을 막는 또 다른 선택지는 애플리케이션에서 갱신할 객체를 명시적으로 잠금하는 것이다.\n- read-modify-write 주기를 수행할 수 있고 다른 트랜잭션이 동시에 같은 객체를 읽으려고 하면 read-modify-write 주기가 완료될 때까지 기다리도록 강제된다.\n- `SELEFT FOR UPDATE` 절은 이 질의에 의해 반환된 모든 로우에 잠금을 획득해야 함을 가르킨다.\n\n#### 갱신 손실 자동 감지\n\n- 지금까지 설명한 갱신 손실 방지 방법은 연산을 순차적으로 실행되도록 강제함으로써 갱신 손실을 방지하는 방법이다.\n- 대안으로 이들의 병렬 실행을 허용하고 트랜잭션 관리자가 갱신 손실을 발견하면 트랜잭션을 어보트 시키고 쓰기를 재시도하도록 강제하는 방법이 있다.\n- Mysql의 반복 읽기는 갱신 손실을 감지하지 않는다.\n\n#### Compare-and-set\n\n- 트랜잭션을 제공하지 않는 데이터베이스 중에는 원자적 compare-and-set 연산을 제공하는 것도 있다.\n\n```jsx\nUPDATE wiki_pages SET content = 'new content'\nWHERE id = 1234 AND content = 'old content'\n```\n\n#### 충돌 해소와 복제\n\n- 복제가 적용된 데이터베이스에서 갱신 손실을 막는 것은 다른 차원의 문제다.\n- 여러 쓰기가 동시에 실행되고 비동기식으로 복제되는 것을 허용하므로 데이터의 최신 복사본이 하나만 있으리라고 보장할 수 없다.\n- **동시 쓰기 감지** 처럼 여러 개의 충돌된 버전(sibling)을 생성하는 것을 허용하고 사후에 충돌을 해소하고 병합하는 것이다.\n\n### 쓰기 스큐(write skew)와 팬텀\n\n- 쓰기 스큐는 두 트랜잭션이 같은 객체들을 읽어서 그중 `일부`를 갱신할 때 나타날 수 있다.\n    - `동일한 객체를 갱신하는 경우` 더티 쓰기나 갱신 손실 이상 현상을 겪는다.\n\n## 직렬성\n\n- 여러 트랜잭션이 병렬로 실행되더라도 최종 결과는 동시성 없이 한 번에 하나씩 직렬로 실행될 때와 같도록 보장한다.\n- 즉 데이터베이스가 발생할 수 있는 **모든** 경쟁 조건을 막아준다.\n- 오늘날 직렬성을 제공하는 데이터베이스는 대부분 세 가지 기법 중 하나를 사용한다.\n    - 트랜잭션을 순차적으로 실행하기\n    - 2단계 잠금\n    - 직렬성 스냅숏 격리 같은 낙관적 동시성 제어\n    \n\n### 실제적인 직렬 실행\n\n- 한 번에 트랜잭션 하나씩만 직렬로 단일 스레드에서 실행하면 된다.\n- 과거 30년 동안 높은 성능을 위해 다중 스레드 동시성이 필수적인 것으로 여겨졌지만 최근이 돼서야 단일 스레드 루프에서 트랜잭션을 실행하는 게 실현 가능하도고 결론지었다.\n    - 램 가격이 저렴해지면서 활성화된 데이터셋 전체를 메모리에 유지할 수 있을 정도가 됐다.\n    - OLTP 트랜잭션이 보통 짧고 실행하는 읽기와 쓰기의 개수가 적다는 것을 알았다. 반대로 오래 실행되는 분석 질의는 직렬 실행 루프 밖에서 일관된 스냅숏을 사용해 실행할 수 있다.\n    \n\n#### 트랜잭션을 스토어드 프로시저 안에 캡슐화하기\n\n- 트랜잭션이 사용자의 입력을 기다려야 한다면 데이터베이스는 대부분 유휴 상태일 것 이다.\n- 이를 효율적으로 처리할 수 없어서 거의 모든 OLTP 애플리케이션은 트랜잭션 내에서 사용자 응답을 대기하는 것을 회피함으로써 트랜잭션을 짧게 유지한다.\n- 애플리케이션에서 질의를 실행하고 그 결과를 읽고, 첫 번째 결과에 따라 다른 질의를 실행할 수 도 있다.\n- 이러한 상호작용식 트랜잭션을 데이터베이스에서 동시성을 허용하지 않으면 처리량은 끔직해 질 것 이다.\n- 트랜잭션 코드 전체를 스토어드 프로시저 형태로 데이터베이스에 미리 제출하여 사용할 수 있다.\n\n#### 스토어드 프로시저의 장단점\n\n- 데이터베이스 벤더마다 제각각 스토어드 프로시저용 언어가 있다.\n- 데이터베이스에서 실행되는 코드는 관리하기 어렵다.\n- 데이터베이스 인스턴스 하나를 공유하기 때문에 잘못 작성된 스토어드 프로시저는 서버에 훨씬 민감하다.\n\n#### 파티셔닝\n\n- 각 트랜잭션이 단일 파티션 내에서만 데이터를 읽고 쓰도록 데이터셋을 파티셔닝할 수 있다면 각 파티셔닝은 다른 파티션과 독립적으로 실행되므로 처리량을 높일 수 있다.\n- 그러나 여러 파티션에 접근해야 하는 트랜잭션이 있다면 해당 트랜잭션이 접근하는 모든 타피션에 걸쳐서 코디네이션을 해야하므로 엄청나게 느려진다.\n\n#### 직렬 실행 요약\n\n- 트랜잭션은 작고 빨라야 한다. 느린 트랜잭션이 모든 트랜잭션 처리를 지연시킬 수 있기 때문이다.\n- 활성화된 데이터셋이 메모리에 적재될 수 있는 경우로 사용이 제한된다.\n- 쓰기 처리량이 단일 CPU 코어에서 처리할 수 정도로 충분히 낮아야 한다.\n- 여러 파티션에 걸친 트랜잭션도 쓸 수 있지만 엄격한 제한이 있다.\n\n### 2단계 잠금(2PL)\n\n- 데이터베이스 직렬성을 구현하는데 널리 쓰인 유일한 알고리즘이다.\n- 트랜잭션 A가 객체 하나를 읽고 트랜잭션 B가 그 객체에 쓰기를 원한다면 B는 진행하기 전에 A가 커밋되거나 어보트될 때까지 기다려야 한다.(B가 A 몰래 갑자기 객체를 변경하지 못하도록 보장된다.)\n- 트랜잭션 A가 객체에 썻고 트랜잭션 B가 그 객체를 읽기 원한다면 B는 진행하기 전에 A가 커밋되거나 어보트될 때까지 기다려야 한다.\n\n<aside>\n💡 2단게 잠금(2PL)과 2단계 커밋(two-phase commit, 2PC)은 아주 비슷하게 들리지만 완전히 다르다.\n\n</aside>\n\n#### 2단계 잠금 구현\n\n- 2PL은 마이SQL 서버에서 직렬성 격리 수준을 구현하는데 사용된다.\n- 읽는 쪽과 쓰는 쪽을 막는 것은 데이터베이스의 각 객체의 잠금을 사용해 구현한다.\n    - 트랜잭션이 객체를 읽기를 원한다면 먼저 공유 모드로 잠금을 획득해야 한다. 동시에 여러 트랜잭션이 공유 모드로 잠금을 획득하는 것은 허용되지만 만약 그 객체에 이미 독점 모드로 잠금을 획든한 트랜잭션이 있으면 이 트랜잭션이 완료될 때까지 기다려야 한다.\n    - 트랜잭션이 객체에 쓰기를 원한다면 먼저 독점 모드로 잠금을 획득해야 한다. 다른 어떤 트랜잭션도 동시에 작므을 획득할 수 없으므로 그 객체에 작믁ㅁ이 존재한다면 트랜잭션은 대기해야 한다.\n    - 트랜잭션이 객체를 읽다가 쓰기를 실행할 때는 공유 잠금을 독점 잠금으로 업그레이드해야 한다. 업그레이드는 독점 잠금을 직접 획득할 때와 똑같이 동작한다.\n    - 트랜잭션이 잠금을 획득한 후에는 트랜잭션이 종료될때 까지 잠금을 갖고 있어야 한다. 2PL의 첫 번째 단계는 잠금을 획득할 때이고 두 번째 단계는 모든 잠금을 해제할 때다.\n    - 트랜잭션이 서로 잠금을 해제하기를 기다리느라 멈춰 있는 상황을 `교착 상태`라고 한다.\n    \n\n### 직렬성 스냅숏 격리(Serializable Snapshot Isolation, SSI)\n\n- 직렬성 격리와 좋은 성능이 공종하는 `직렬성 스냅숏 격리`라는 알고리즘이 유망하다.\n\n#### 비관적 동시성 제어 대 낙관적 동시성 제어\n\n- 2단계 잠금은 `비관적` 동시성 제어 메커니즘이다.\n    - 뭔가 잘못될 가능성이 있으면 뭔가를 하기 전에 상황이 다시 안전해질 때까지 기다리는 게 낫다는 원칙을 기반으로 한다.\n- 직렬성 스냅숏 격리는 `낙관적` 동시성 제어 기법이다.\n    - 트랜잭션이 커밋되기를 원할 때 데이터베이스는 격리가 위반됐는지 확인한다.\n    - 만약 그렇다면 트랜잭션은 어보트되고 재시도해야 한다.\n- 낙관적 동시성 제어는 경쟁이 심하면 어보트시켜야 할 트랜잭션의 비율이 높아지므로 성능이 떨어진다.\n- 예비 용량이 충분하고 트랜잭션 사이의 경쟁이 너무 심하지 않으면 낙관적 동시성 제어 기법은 비관적 동시성 제어보다 성능이 좋은 경향이 있다.\n- `SSI`는 스냅숏 격리를 기반으로 한다. 모든 읽기의 데이터는 데이터베이스의 일관된 스냅숏을 보게 된다.\n\n## 정리\n\n#### 동시성 제어를 위한 격리 수준\n\n- **더티 읽기**\n    - 한 클라이언트가 다른 클라이언트가 썻지만 아직 커밋되지 않은 데이터를 읽는다. 커밋 후 읽기 또는 그보다 강한 격리 수준은 더티 읽기를 방지한다.\n- **더티 쓰기**\n    - 한 클라이언트가 다른 클라이언트가 썻지만 아직 커밋되지 않은 데이터를 덮어쓴다. 거의 모든 트랜잭션 구현은 더티 쓰기를 방지한다.\n- **읽기 스큐(반복 읽기)**\n    - 클라이언트는 다른 시점에 데이터베이스의 다른 부분을 본다. 이 문제를 막기 위해 어느 시점의 일관된 스냅숏으로부터 읽는 스냅숏 격리를 가장 흔히 사용한다.\n- **갱신 손실**\n    - 두 클라이언트가 동시에 `read-modify-write` 주기를 실행한다. 다른 트랜잭션의 변경을 포함하지 않은 채로 쓴 내용을 덮어써서 데이터 손실이 일어난다.\n- **쓰기 스큐**\n    - 트랜잭션이 무언가를 읽고 읽은 값을 기반으로 어떤 결정을 하고 그 결정을 데이터베이스에 쓴다. 그러나  쓰기를 실행하는 시점에는 결정의 전체가 더 이상 참이 아니다. 직렬성 격리만 이런 이상 현상을 막을 수 있다.\n- **팬텀 읽기**\n    - 트랜잭션이 어떤 검색 조건에 부합하는 객체를 읽는다. 다른 클라이언트가 그 검색 결과에 영향을 주는 쓰기를 실행한다.\n\n#### 직렬성 트랜잭션을 구현하는 방법\n\n- 트랜잭션을 순서대로 실행하기\n    - 트랜잭션의 실행 시간이 아주 짧고 트랜잭션 처리량이 단일 CPU 코어에서 처리할 수 있을 정도로 트랜잭션 처리량이 낮다면 아주 간단하고 효과적인 선택이다.\n- 2단계 잠금\n    - 수십년 동안 직렬성을 구현하는 표준적인 방법이지만 성능 특성 때문에 사용을 피하는 애플리케이션이 많다.\n- 직렬성 스냅숏 격리\n    - 낙관적 방법을 사용해서 트랜잭션이 차단되지 않고 진행할 수 있게 한다. 트랜잭션이 커밋을 원할 때 트랜잭션을 확인해서 실행이 직렬적이지 않으면 어보트시킨다."},{"excerpt":"파티셔닝과 복제 데이터셋이 매우 크거나 질의 처리량이 매우 높다면 복제만으로 부족하고 데이터를 파티션으로 쪼갤 필요가 있다. 이 작업을 이라고 한다. 파티션을 나눌 때는 보통 각 데이터 단위(레코드, 로우, 문서)가 하나의 파티션에 속하게 한다. 데이터 파티셔닝을 원하는 주된 이유는 확장성이다. 보통 복제와 파티셔닝을 함께 적용해 각 파티션의 복사본을 여…","fields":{"slug":"/ch6/"},"frontmatter":{"date":"January 28, 2022","title":"6장 - 파티셔닝","tags":["데이터 중심 애플리케이션 설계"]},"rawMarkdownBody":"\n## 파티셔닝과 복제\n\n- 데이터셋이 매우 크거나 질의 처리량이 매우 높다면 복제만으로 부족하고 데이터를 파티션으로 쪼갤 필요가 있다. 이 작업을 `샤딩`이라고 한다.\n- 파티션을 나눌 때는 보통 각 데이터 단위(레코드, 로우, 문서)가 하나의 파티션에 속하게 한다.\n- 데이터 파티셔닝을 원하는 주된 이유는 **확장성**이다.\n- 보통 복제와 파티셔닝을 함께 적용해 각 파티션의 복사본을 여러 노드에 저장한다.\n\n<!-- more -->\n\n<aside>\n💡 몽고DB, 엘라스틱서치, 솔라클라우드의 샤드(shared), HBase에서는 리전(region), 빅테이블에서는 태블릿(tablet), 카산드라, 리악에서는 브이노드(vnode), 카우치베이스에서는 브이버켓(vBucket)이라 부른다.\n\n</aside>\n\n## 키-값 데이터 파티셔닝\n\n- 파티셔닝의 목적은 데이터와 질의 부하를 노드 사이에 고르게 분산시키는 것이다.\n- 파티셔닝이 고르게 이뤄지지 않아 다른 파티션보다 데이터가 많거나 질의를 많이 받는 파티션이 있다면 **쏠렸다(skewed)** 고 말한다.\n- 불균형하게 부하가 높은 파티션을 `핫스팟`이라고 한다.\n- 어떤 레코드를 어느 노드에 저장해야 할까?\n\n### 키 범위 기준 파티셔닝\n\n- 종이 백과사전처럼 각 파티션에 연속된 범위의 키를 할당한다.\n- 각 범위들 사이의 경계를 알면 어떤 키가 어느 파티션에 속하는지 쉽게 찾을 수 있다.\n- 키 범위의 경계는 데이터에 맞춰 조정해야 한다. 데이터가 키 경계별로 고르게 분포하지 않을 수도 있기 때문이다.\n- 키 범위 기준 파티셔닝은 접근 패턴이 핫스팟을 유발할 수도 있다.\n    - 특정 키에만 부하가 물려 해당 파티션만 과부하가 걸리고 나머지 파티션은 유휴 상태로 남아 있을 수 있다.\n- 빅테이블, HBase, 리싱크DB, 2.4버전 이전의 몽고DB에서 사용된다.\n\n### 키의 해시값 기준 파티셔닝\n\n- 쏠림과 핫스팟의 위험ㄷ 때문에 많은 분산 데이터스토어는 키의 파티션을 정하는데 해시 함수를 사용한다.\n- 카산드라와 몽고DB는 MD5를 사용한다.\n- 각 파티션에 해시값 범위를 할당하고 해시값이 파티션의 범위에 속하는 모든 키를 그 파티션에 할당하면 된다.\n- 키의 해시값을 사용해서 파티셔닝을 하면 정렬 순서가 유지되지 않아 범위 질의를 처리하는데 불리해진다.\n- 리악, 카우치베이스,볼트모트에서는 기본키에 대한 범위 질의가 지원되지 않는다.\n- 카산드라는 두 가지 파티셔닝 전략 모두 사용한다.\n    - 카산드라에서 테이블을 선언할 때 여러 컬럼을 포함하는 **복합키**를 지정할 수 있다.\n    - 키의 첫 부분만 해싱을 적용하고 나머지 컬럼은 SS테이블에서 데이터를 정렬하는 색인을 사용한다.\n    - 첫 번째 컬럼에 대해서는 범위 질의를 쓸 수 없지만, 첫 번째 컬럼을 고정된 값으로 지정하면 다른 컬럼에 대해서는 범위 스캔을 수행할 수 있다.\n\n### 쏠린 작업부하와 핫스팟 완화\n\n- 해시값 기준 파티셔닝은 동일한 키를 읽고 쓰는 극단적인 상황에서는 모든 요청이 동일한 파티션으로 쏠리게 된다.\n- 현대 데이터 시스템은 대부분 크게 쏠린 작업부하를 자동으로 보정하지 못하므로 애플리케이션에서 쏠림을 완화해야 한다.\n    - 예를 들어, 요청이 쏠리는 키를 발견했을 때, 임의의 숫자 2개만 붙이더라도 작업이 100개의 다른 키로 균등하게 분산된다.\n    - 어떤 키가 쪼개졌는지 추적할 방법도 있어야 한다.\n\n## 파티셔닝과 보조 색인\n\n- 보조 색인은 보통 특정한 값이 발생한 항목을 검색하는 수단이다.\n- 보조 색인은 관계형 데이터베이스의 핵심 요소이며 솔라나 엘라스틱서치 같은 검색 서버에게는 **존재의 이유**다.\n- 보조 색인은 파티션에 깔끔하게 대응되지 않는 문제점이 있다.\n\n### 문서 기준 보조 색인 파티셔닝\n\n- 고유 ID 기준으로 문서를 파티셔닝한다.\n- 각 파티션은 자신의 보조 색인을 유지하며 그 파티션에 속하는 문서만 담당한다.\n- 데이터베이스에서 문서 추가, 삭제, 갱신 등의 쓰기 작업을 실행할 때는 쓰려고 하는 문서 ID를 포함하는 파티션만 다루면 된다.\n- 그러한 까닭에 문서 파티셔닝 색인은 `지역 색인(local index)` 라도도 부른다.\n- 보조 색인의 모든 데이터가 한 파티셔닝에 없을 수도 있다. 따라서 모든 파티션으로 질의를 보내서 얻은 결과를 모두 모아야 한다.\n- 이런식의 질의를 보내는 방법을 `스캐터/개더(scatter/gather)`라고 한다.\n- 몽고DB, 리악, 카산드라, 엘라스틱서치, 솔라클라우드, 볼트DB는 모두 문서 기준 보조 색인을 사용한다.\n\n### 용어 기준 보조 색인 파티셔닝\n\n- 예를 들어 보조 색인의 a-r 까지의 글자로 시작하면 파티션 0에, s-z까지의 글자로 시작하는 색깔은 파티션 1에 저장되도록 파티셔닝한다.\n- 찾고자 하는 용어에 따라 색인의 파티션이 결정되므로 이런 식의 색인을 용어 기준으로 파티셔닝됐다라고 한다.\n- **용어**라는 이름은 전문 색인에서 나왔는데 문서에 등장하는 모든 단어를 말한다.\n- 문서 파티셔닝 색인에 비해 `전역(용여 파티셔닝)` 색인이 갖는 이점은 읽기가 효율적이라는 것이다.\n- 하지만 전역 색인은 쓰기가 느리고 복잡하다는 단점이 있다.\n- 단일 문서를 쓸 때 해당 색인의 여러 파티셔네 영향을 줄 수 있기 때문이다.\n- 현실에서는 전역 보조 색인은 대게 비동기로 갱신된다.\n    - 아마존 다이나모DB는 정상적인 상황에는 전역 보조 색인을 갱신하는데 1초도 안걸린다.\n\n## 파티션 재균형화\n\n- 시간이 지나면 데이터베이스에 변화가 생긴다.\n    - 질의 처리량이 증가해서 늘어난 부하를 처리하기 위해 CPU를 추가하고 싶다.\n    - 데이터셋 크기가 증가해서 데이터셋 저장에 사용할 디스크와 램을 추가하고 싶다.\n    - 장비에 장애가 발생해서 그 장비가 담당하던 역할을 다른 장비가 넘겨받아야 한다.\n- 이런 변화가 생기면 데이터 요청이 한 노드에서 다른 노드로 옮겨야 하는데 이런 과정을 `재균형화(rebalancing)`라고 한다.\n- 재균형화가 실행될 때 만족시킬 것으로 기대되는 최소 요구사항이 있다.\n    - 재균형화 후, 부하가 노드 사이에 균등하게 분배돼야 한다.\n    - 재균형화 도중에도 데이터베이스는 읽기 쓰기 요청을 받으들여야 한다.\n    - 재균형화가 빨리 샐행되고 네트워크와 디스크 I/O 부하를 최소화할 수 있도록 노드들 사이에 데이터가 필요 이상으로 옮겨져서는 안된다.\n\n### 재균형화 전략\n\n#### 쓰면 안되는 방법: 해시값에 모드 N연산을 실행\n\n- 해시값에 `mod` 연산을 쓰게 되면 노드 개수 N이 바꾸면 대부분의 키가 노드 사이에 옮겨져야 한다는 점이다.\n- 키가 자주 이동하면 재균형화 비용이 지나치게 커진다.\n\n#### 파티션 개수 고정\n\n- 파티션을 노드 대수보다 많이 만들고 각 노드에 여러 파티션을 할당하는 것이다.\n- 클러스터에 노드가 추가되면 새 노드는 파티션이 다시 균일하게 분배될 때까지 기존 노드에서 파티션 몇개를 뻇어올 수 있다.\n- 파티션은 노드 사이에서 통째로 이동하기만 한다. 파티션 개수는 바뀌지 않고 파티션에 할당된 키도 변경되지 않는다.\n- 이 방식을 사용할 때는 보통 데이터베이스가 처음 구축될 때 파티션 개수가 고정되고 이후에 변하지 않는다.\n- 파티션을 쪼개거나 합치는게 가능하지만 운영성 어려움이 많아 처음 설정하는 파티션 개수가 사용 가능한 노드 대수의 최대치가 되므로 미래에 증가될 것을 수용하기에 충분히 높은 값을 선택해야 한다.\n- 파티션이 너무 크면 재균형화를 실행할 때와 노드 장애로부터 복구할 때 비용이 크다. 파티션이 너무 작으면 오버헤드가 너무 커진다.\n- 파티션 크기가 적당할 때 성능이 가장 좋지만 파티션 개수는 고정돼 있고 데이터셋 크기는 변한다면 적절한 크기를 정하기 어렵다.\n\n#### 동적 파티셔닝\n\n- 키 범위 파티셔닝에서 파티션의 경계와 개수가 고정돼 있는게 매우 불편하다. 이런 이유로 파티션을 동적으로 만든다.\n- 파티션 크기가 설정된 값을 넘어서면 파티션을 두 개로 쪼개 각각에 원래 파티션의 절반 정도의 데이터가 포함되게 한다.\n- 반대로 데이터가 많이 삭제되어 파티션 크기가 임계값 아래로 떨어지면 인접한 파티션과 합쳐질 수 있다.\n- 큰 파티션이 쪼개진 후 부하의 균형을 맞추기 위해 분할된 파티션 중 하나가 다른 노드로 이동될 수 있다.\n- 동적 파티셔닝은 파티션 개수가 전체 데이터에 맞춰 조정된다는 이점이 있다.\n    - 단, 데이터 셋이 작을 때는 모든 쓰기 요청이 하나의 노드에서 실행되고 다른 노드들은 유휴 상태에 머물게 된다.\n    - 이 문제를 완하하기 위해서 몽고DB에서는 초기 파티션 집합을 설정할 수 있게 한다. (사전분할이라고 부른다)\n- 동적 파티셔닝은 커 범위 파티셔닝뿐만 아니라 해시 파티셔닝에서도 똑같이 사용될 수 있다.\n\n#### 노드 비례 파티셔닝\n\n- 카산드라와 케타마에서 사용되는 방법은 파티션 개수가 노드 대수에 비례하게 하는 것이다.\n- 노드 대수가 변함 없는 동안은 개별 파티션 크기가 데이터셋 크기에 비례해서 증가하지만 노드 대수를 늘리면 파티션 크기는 다시 작아진다.\n- 새 노드가 클러스터에 추가되면 고정된 개수의 파티션을 무작위로 선택해 분할하고 각 분할된 파티션의 절반은 그대로 두고 절반은 새 노드에 할당한다.\n\n### 운영: 자동 재균형화와 수동 재균형화\n\n- 완전 자동 재균형화`(시스템이 자동으로 언제 파티션을 노드 사이에 이동할지 결정함)`와 완전 수동 재균형화`(관리자가 명시적으로 파티션을 노드에 할당하도록 설정하고 관리자가 재설정할 때만 파티션 할당이 변경됨)` 사이에는 중간 지점이 있다.\n- 카우치베이스, 리악, 볼드모트는 자동으로 파티션 할당을 제안하지만 반영되려면 관리자가 확정해야 한다.\n- 완전 자동 개균형화는 유지보수에 손이 덜 가지만, 예측하기 어렵다.\n\n## 요청 라우팅\n\n- 클라이언트에서 요청을 보내려고 할 때 어느 노드로 접속을 해야할까?\n    - 클라이언트가 아무 노드에 접속하게 한다.그 후, 요청을 처리할 노드로 전달해서 응답을 받는다.\n    - 클라이언트의 모든 요청을 라우팅 계층으로 먼저 보낸다. 라우팅 계층에서는 각 요청을 처리할 노드를 알아내고 그에 따라 해당 노드에 요청을 전달한다.\n    - 클라이언트가 파티셔닝 방법과 파티션이 어떤 노드에 할당됐는지를 알고 있게 한다.\n- 모든 경우에 핵심 문제는 라우팅 결정을 내리는 구성요소`(노드 중 하나, 라우팅 계층, 클라이언트 측)`가 노드에 할당된 파티션의 변경 사항을 어떻게 아느냐다.\n- 많은 분산 데이터 시스템은 클러스터 메타데이터를 추적하기 위해 주키퍼 같은 별도의 코디네이션 서비스를 사용한다.\n    - 각 노드는 주키퍼에 자신을 등록하고 주키퍼는 파티션과 노드 사이의 신뢰성 있는 할당 정보를 관리한다.\n    - 노드사 추가되거나 삭제되면 주키퍼는 라우팅 계층에 이를 알려서 라우터 정보를 최신화 한다.\n    - HBase, 솔라클라우드, 카프카 등\n- `가십 프로토콜(gossip protocol)`을 사용해서 클러스터 상태 변화를 노드 사이에 전달하는 방식도 있다.\n    - 아무 노드나 요청을 받을 수 있고 요청을 받은 노드는 요청을 처리할 노드에게 요청을 전달한다.\n    - 이 모델은 데이터베이스 노드에 복잡성은 더하지만 주키퍼 같은 외부 코디네이션 서비스에 의존하지 않는다.\n\n### 병렬 질의 실행\n\n- 지금까지는 단일 키를 읽거나 간단한 질의에 대해서만 설명했다.\n- 그러나 분석용으로 자주 사용되는 `대규모 병렬 처리(MPP)` 관계형 데이터 베이스 제품은 훨씬 더 복잡한 종류의 질의를 지원한다.\n- MPP 옵티마이저는 복잡한 질의를 여러 실행 단계와 파티션으로 분해하며 이들 중 다수는 데이터베이스 클러스터 내의 서로 다른 노드에서 병렬적으로 실행될 수 있다.\n\n## 정리\n\n- 저장과 처리할 데이터가 많아서 장비 한 대로 처리하는게 불가능해지면 파티셔닝이 필요하다.\n- 파티셔닝의 목적은 핫스팟이 생기지 않게 하면서 데이터와 질의 부하를 여러 장비에 균일하게 분배하는 것이다.\n- 그렇게 하려면 데이터에 적합한 파티셔닝 방식을 선택해야 하고 클러스터 노드에 추가되거나 제거될 때 파티션 재균형화를 실행해야 한다.\n\n### 파티셔닝 기법\n\n#### 키 범위 파티셔닝\n\n- 키가 정렬돼 있고 개별 파티션은 키 범위 경계에 속한다.\n- 키가 정렬되어 있어 범위 질의에 효율적이지만 핫스팟이 생길 위험이 있다.\n- 파티션이 너무 커지면 키 범위를 두 개로 쪼개 동적으로 재균형화를 실행한다.\n\n#### 해시 파티셔닝\n\n- 키에 해시 함수를 적용하여 키 범위 파티셔닝을 적용한다.\n- 범위 질의에 비효율적이지만 부하를 더욱 균일하게 분산할 수 있다.\n\n### 보조 파티셔닝 기법\n\n#### 문서 파티셔닝 색인(지역 색인)\n\n- 보조 색인을 기본키와 값이 저장된 파티션에 저장한다.\n- 쓸 때는 파티션 하나만 갱신하면 되지만 보조 색인을 읽으려면 모든 파티션에 걸쳐서 스캐터/개더를 사용해야 한다.\n\n#### 용어 파티셔닝 색인(전역 색인)\n\n- 색인된 값을 사용해서 보조 색인을 별도로 파티셔닝 한다.\n- 문서를 쓸 때는 보조 색인 여러 개를 갱신해야 하지만 읽기는 단일 파티션에서 실행될 수 있다."},{"excerpt":"복제 란 네트워크로 연결된 여러 장비에 동일한 데이터 복사본을 유지한다는 의미이다. 데이터 복제가 필요한 이유는 다음과 같다. 지리적으로 사용자와 가깝게 데이터를 유지해 지연 시간을 줄인다. 시스템의 일부에 장애가 발생해도 지속적으로 동작할 수 있게 해 가용성을 높인다. 읽기 질의를 제공하는 장비의 수를 확장해 읽기 처리량을 늘린다. 복제에서 모든 어려움…","fields":{"slug":"/ch5/"},"frontmatter":{"date":"January 23, 2022","title":"5장 - 복제","tags":["데이터 중심 애플리케이션 설계"]},"rawMarkdownBody":"\n- **복제** 란 네트워크로 연결된 여러 장비에 동일한 데이터 복사본을 유지한다는 의미이다.\n- 데이터 복제가 필요한 이유는 다음과 같다.\n    - 지리적으로 사용자와 가깝게 데이터를 유지해 지연 시간을 줄인다.\n    - 시스템의 일부에 장애가 발생해도 지속적으로 동작할 수 있게 해 가용성을 높인다.\n    - 읽기 질의를 제공하는 장비의 수를 확장해 읽기 처리량을 늘린다.\n- 복제에서 모든 어려움은 복제된 데이터의 변경 처리에 있다.\n- 노드 간 복제를 위한 세 가지 인기 알고리즘이 있다.\n    - **단일 리더 (single-leader)**\n    - **다중 리더 (multi-leader)**\n    - **리더 없는 (leaderless)**\n\n<!-- more -->\n    \n## 리더와 팔로워\n\n- 데이터베이스의 복사본을 저장하는 각 노드를 **복제 서버(replica)** 라고 한다.\n- 모든 복제서버의 동일한 데이터를 유지하기 위해 데이터베이스의 모든 쓰기는 복제 서버에서 처리돼야 한다.\n- 이 문제를 위한 가장 일반적인 해결책은 `리더 기반 복제(마스터 슬레이브 복제`)이다. 동작은 다음과 같다.\n    - 클라이언트가 데이터베이스에 쓰기를 할 때 요청을 리더에게 보내야 한다.\n    - 리더는 먼저 로컬 저장소에 새로운 데이터를 기록한다.\n    - 리더가 로컬 저장소에 새로운 데이터를 기록할 때마다 데이터 변경을 복제 로그나 변경 스트림의 일부로 팔로워에게 전송한다.\n    - 각 팔로워가 리더로부터 로그를 받으면 리더가 처리한 것과 동일한 순서로 모든 쓰기를 적용해 그에 맞게 데이터베이스의 로컬 복사본을 갱신한다.\n    - **클라이언트가 데이터베이스로부터 읽기를 할 때는 리더 또는 팔로워에게 질의할 수 있지만, 쓰기는 리더에게만 허용된다.**\n\n\n### 동기식 대 비동기식 복제\n\n- 복제 시스템의 중요한 세부 사항은 복제가 **동기식**으로 발생하는지 **비동기식**으로 발생하는지 여부이다.\n- `팔로워 1`의 복제는 동기식 복제이다. 리더는 `팔로워 1`이 쓰기를 수신했느지 확인해 줄 때까지 기다린다.\n- `팔로워 2`의 복제는 비동기식이다. 리더는 메시지를 전송하지만 팔로워의 응답을 기다리지 않는다.\n- 동기식 복제의 장점은 팔로워가 리더와 일관성 있게 최신 데이터 복사본을 가지는 것을 보장한다.\n- 단점은 팔로워가 죽거나 다른 어떤 이유로 인해 동기 팔로워가 응답하지 않으면 쓰기가 처리될 수 없다는 뜻이다.\n- 현실적으로 데이터베이스에서 동기식 복제를 사용하려면 보통 **할로워 하나**는 동기식으로 하고 그 밖에는 비동기식으로 하는 것을 의미한다.\n- 동기식 팔로워가 사용할 수 없게 되거나 느려지면 비동기식 팔로워 중 하나가 동기식이 된다. 이런 설정을 `반동식(semi-synchronous)`이라 한다.\n\n### 새로운 팔로워 설정\n\n- 때대로 복제 서버수를 늘리거나 장애 노드의 대체를 위해 새로운 팔로워를 설정해야 한다.\n- 클라이언트는 지속적으로 데이터베이스에 기록하고 데이터는 항상 유동적이기 때문에 표준 파일 복사본은 다른 시점에 데이터베이스의 다른 부분을 보게 된다.\n- 다행이 팔로워 설증은 대게 중단시간 없이 수행할 수 있다.\n    - 리더의 데이터베이스 스냅숏을 일정 시점에 가져온다.\n    - 스냅숏을 새로운 노드에 복사한다.\n    - 팔로워는 리더에 연결해 스냅숏 이후 발생한 모든 데이터 변경을 요청한다. 이것은 스냅숏이 리더의 복제 로그의 정확한 위치와 연관돼야 한다. 이 위치의 명칭을 MySQL 에서는 `이진로그 좌표(binlog coordinate)` 라 부른다.\n    - 팔로워가 스냅숏 이후 데이터 변경의 미처리분을 모두처리했을 때 따라잡았다고 한다.\n    \n\n### 노드 중단 처리\n\n#### 팔로워 장애: 따라잡기 복구\n\n- 각 팔로워는 리더로부터 수신한 데이터 변경 로그를 로컬 디스크에 보관한다.\n- 팔로워가 죽어 재시작하거나 리더와 팔로워 사이의 네트워크가 일시적으로 중단된다면 로그를 통해 쉽게 복구 할 수 있다.\n    - 먼저 보관된 로그에서 결함이 발생하기 전에 처리한 마지막 트랜잭션을 알아낸다.\n    - 트랜잭션 이후 팔로워 연결이 끊어진 동안 발생한 데이터 변경을 모두 요청한다.\n    \n\n#### 리더 장애: 장애 복구\n\n- 팔로워 중 하나를 새로운 리더로 변경해야 하고 클라이언트는 새로운 리더로 쓰기를 전송하기 위해 재설정이 필요하며 다른 팔로워는 새로운 리더로부터 데이터 변경을 소비하기 시작해야 한다. 이 과정을 **장애 복구(failover)** 라 한다.\n    - **리더가 장애인지 판단한다.** 대부분의 시스템은 타임아웃을 사용해 노드가 죽은 것으로 판단한다.\n    - **새로운 리더를 선택한다.** 이전에 선출된 제어 노드(controller node)에 의해 새로운 리더가 임명될 수 있다. 보통 리더의 최신 데이터 변경사항을 가진 복제 서버가 된다.\n    - **새로운 리더 사용을 위해 시스템을 재설정한다.** 이전 리더가 팔로워가 되고 새로운 리더를 인식할 수 있게끔 해야 한다.\n\n### 복제 로그 구현\n\n#### 구문 기반 복제 (Statement-Based Replication)\n\n- 리더는 모든 쓰기 요청을 기록하고 쓰기를 실행한 다음 구문 로그를 팔로워에게 전송한다.\n- 관계형 데이터베이스는 모든 INSERT, UPDATE, DELETE 구문을 팔로워에게 전달하고 각 팔로워는 클라이언트에서 직접 받은 것처럼 SQL 구문을 파싱하고 실행한다.\n- 이 접근법은 복제가 깨질 수 있는 사례가 있다.\n    - `NOW(), RAND()` 같은 비결정적 함수를 호출하는 모든 구문은 각 복제 서버마다 다른 값을 생성할 수 있다.\n    - 자동증가 컬럼을 사용하는 구문이나 데이터베이스에 있는 데이터에 의존한다면 각 복제서버에서 정확히 같은 순서로 실행돼야 한다. 그렇지 않으면 효과가 달라질 수 있다.\n    - 부수 효과를 가진 구문`(트리거, 스토어드 프로시저, 사용자 정의 함수)`은  부수 효과가 완벽하게 결정적이지 않으면 각 복제 서버에서 다른 부수 효과가 발생할 수 있다.\n- 해결책으로 리더는 구문을 기록할 때 모든 비결정적 함수 호출을 고정 값을 반환하게끔 대체할 수 있다.\n\n<aside>\n💡 MySQL 5.1 이전 버전에서 구문 기반 복제가 사용되고 구문에 비결정성이 있다면 로구 기반 복제(row-based replication)으로 변경한다.\n\n</aside>\n\n#### 쓰기 전 로그 배송\n\n- 일반적으로 모든 쓰기는 로그에 기록된다.\n- 리더는 디스크에 로그를 기록하는 일 외에도 팔로워에게 네트워크로 로그를 전송하기도 한다.\n- 팔로워가 이 로그를 처리하면 리더에서 있는 것과 정확히 동일한 데이터 구조의 복제본이 만들어진다.\n- 이 복제 방식의 가장 큰 단점은 로그가 제일 저수준의 데이터를 기술한다는 점이다.\n    - 쓰기 전 로그(WAL)은 어떤 디스크 블록에서 어떤 바이트를 변경했는지와 같은 상세 정보를 포함한다.\n    - 이렇게 하면 복제가 저장소 엔진과 밀접하게 엮이는 문제가 발생한다.\n\n#### 로우 기반 로그 복제\n\n- 복제 로그를 저장소 엔진 내부와 분리하기 위한 대안으로 복제와 저장소 엔진을 위해 다른 로그 형식을 사용하는 것이다.\n- 이 같은 종류의 복제 로그를 저장소 엔진의 물리적 데이터 표현과 구별하기 위해 논리적 로그라고 부른다.\n    - 삽입된 로우의 로그는 모든 칼럼의 새로운 값을 포함한다.\n    - 삭제된 로우의 로그는 로우를 고유하게 식별하는 데 필요한 정보를 포함한다.\n    - 갱신된 로우의 로그는 로우를 고유하게 식별하는데 필요한 정보와 모든 칼럼의 새로운 값을 포함한다.\n- 여러 로우를 수정하는 트랜잭션은 여러 로그 레코드를 생성한 다음 트랙잭션이 커밋됐음을 레코드에 표시한다.\n- 논리적 로그는 저장소 엔진 내부와 분리했기 때문에 하위 호환성을 더 쉽게 유지할 수 있고 다른 버전의 데이터베이스 소프트웨어나 심지어 다른 저장소 엔진을 실행할 수 있다.\n- 논리적 로그 형식은 외부 애플리케이션에서 파싱하기 더 쉽다. 색이이나 캐시 구축을 위해 데이터 웨어하우스 같은 외부 시스템에 데이터베이스의 내용을 전송하고자 할 때 유용하다. 이 기술을 `변경 데이터 캡처(chage data capture)`라 부른다.\n\n#### 트리거 기반 복제\n\n- 지금까지 설명한 복제 접근 방식은 애플리케이션 코드의 사용 없이 데이터베이스 시스템에 의해 구현된다.\n- 데이터의 서브셋만 복제하거나 데이터베이스를 다른 종류의 DB로 복제해야 하거나 충돌 해소 로직이 필요하다면 복제를 애플리케이션 층으로 옮겨야 한다.\n- 트리거난 데이터 변경을 분리된 테이블에 로깅할 수 있는 기회를 가진다.\n- 이 테이블로부터 데이터 변경을 외부 프로세스가 읽고 필요한 애플리케이션 로직을 적용해 다른 시스템으로 데이터 변경을 복제한다.\n- 이 방식은 데이터베이스에 내장된 복제보다 버그나 제한 사항이 더 많이 발생하지만 유연성 때문에 유용하다.\n\n## 복제 지연 문제\n\n- 복제는 내결합성에만 필요한 것이 아니라 확장서으 지연시간 등의 이유로 필요할 수 있다.\n- 리더 기반 복제는 모든 쓰기가 단일 노드를 거쳐야 하고 읽기 전용 질의는 어떤 복제 서버에서도 가능하다.\n- 애플리케이션이  비동기 팔로워에서 데이터를 읽을 때 팔로워가 뒤처진다면 지난 정보를 볼 수 도 있다.\n- 하지만 데이터베이스에 쓰기를 멈추고 잠시 동안 기다린다면 팔로워는 결국 리더와 일치하게 되는데 이런 효과를 **최종적 일관성**이라고 한다.\n- 애플리케이션에서 지연이 크면 불일치 문제가 발생할 수 있고 해결 방법을 간략히 설명한다.\n\n### 자신이 쓴 내용 읽기\n\n- 비동기식 복제 방식에서 문제는 사용자가 쓰기를 수행한 직후 데이터를 본다면 새로운 데이터가 복제 서버에 반영되지 않아 사용자가 제출한 데이터가 유실된 것 처럼 보일 수 있다.\n- 이런 상황에서는 `쓰기 후 읽기 일관성`이 필요하다. 이것은 사용자가 페이지를 재로딩했을 때 항상 자신이 제출한 모든 갱신을 볼 수 있음을 보장하며 다른 사용자에 대해서는 보장하지 않는다.\n- 쓰기 후 읽기 일관성을 구현하는 방법은 다음과 같다.\n    - 사용자가 수정한 내용을 읽을 때는 리더에서 읽고 그 밖에는 팔로워에서 읽는다.\n        - 실제로 질의하지 않고 무엇이 수정됐는지 알 수 있는 방법이 필요하다.\n        - 예를 들어 SNS에서 항상 사용자 소유의 프로필은 리더에서 읽고 다른 사용자의 프로필은 팔로워에서 읽는 간단한 규칙을 사용한다.\n        - 애플리케이션 내 대부분의 내용을 사용자가 편집할 가능성이 있다면 이 접근 방식은 효율적이지 않다.\n        - 이런 경우에는 마지막 생신 시각을 찾아서 특정 시간동안은 리더에서 모든 읽기를 수행하도록 한다.\n        - 또한 팔로워에서 복제 지연을 모니터링해 리더보다 특정 시간 이상 늦은 모든 팔로워에 대한 질의를 금지할 수 있다.\n    - 클라이언트가 가장 최그 쓰기의 타임스탬프를 기억할 수 있다.\n        - 시스템 사용자 읽기를 위한 복제 서버가 최소한 해당 타임스탬프까지 갱신을 반영하게 할 수 있다.\n        - 복제 서버가 최신 내용이 아닌 경우에는 다른 복제 서버가 읽기를 처리하거나 복제 서버가 따라잡을 때까지 질의를 대기시킬 수 있다.\n\n### 단조 읽기\n\n- 비동기식 복제 방식의 두번째 문제로 사용자가 **시간이 거꾸로 흐르는 현상**을 목격할 수 있다는 것이다.\n- 리더에서 쓰기 한 내용이 팔로워 1,2 에 반영되는 시점에 차이가 생기게 되면 최신 복제 서버를 읽었을 땐 데이터가 반환되지만 아직 쓰기가 반영되지 않은 복제 서버를 읽었을 땐 아무것도 반환되지 않을 수 있다.\n- `단조 읽기(monotonic read)`는 이런 종류의 이상 현상이 발생하지 않음을 보장한다.\n\n### 일관된 순서로 읽기\n\n- 각각의 팔로워의 지연 때문에 일련의 쓰기 순서가 바뀌는 이상 현상이 발생할 수 있다.\n- 이런 종류의 이상 현상을 방지하려면 `일관된 순서 읽기(Consistent Prfix Read)` 같은 보장이 필요하다.\n- 일련의 쓰기가 특정 순서로 발생한다면 이 쓰기를 읽는 모든 사용자는 같은 순서로 쓰여진 내용을 보게 됨을 보장한다.\n\n### 복제 지연을 위한 해결책\n\n- 앞서 설명한 것처럼 애플리케이션이 기본 데이터베이스보다 더 강력한 보장을 제공하는 할 수 있지만 애플리케이션 코드에서 이 문제를 다루기에는 너무 복잡해서 잘못되기 쉽다. `(ex: 특정 종류의 리더에서 읽기 수행)`\n- 트랜잭션은 애플리케이션이 더 단순해지기 위해 데이터베이스가 강력한 보장을 제공하는 방법이다.\n- 하지만 분산 데이터베이스로 전환하는 과정에서 많은 시스템이 트랜잭션을 포기했다.\n- 트랜잭션 성능과 가용성 측면에서 너무 비싸고, 확장 가능 시스템에서는 어쩔 수 없이 최종적 일관성을 사용해야 한다는 주장이 있다.\n- 남은 부분에서는 이 미묘한 차이를 다루고, 여러 대안 메커니즘을 설명한다.\n\n## 다중 리더 복제\n\n- 단일 리더 복제는 어떤 이유로 리더에 연결할 수 없다면 데이터베이스에 쓰기를 할 수 없다는 단점이 있다.\n- 리더 기반 복제 모델은 쓰기를 허용하는 노드를 하나 이상 두는 것으로 자연스럽게 확장된다.\n- 이 방식을 **다중 리더** 설정`(마스터/마스터)`라고 한다.\n\n### 다중 리더 복제의 사용 사례\n\n#### 다중 데이터센터 운영\n\n- 각 데이터센터마다 리더와 팔로워를 가질 수 있다.\n- 데이터센터 내에는 리더 팔로워 복제를 사용하고 데이터센터 간에는 각 데이터센터의 리더가 다른 데이터센터의 리더에게 변경 사항을 복제한다.\n- 단일 리더 설정과 다중 리더 설정이 다중 데이터센터에서의 비교이다.\n    - 다중 리더 설정에서 모든 쓰기는 로컬 데이터센터에서 처리한 다음 비동기 방식으로 다른 데이터센터에 복제한다. **사용자가 인지하는 성능은 더 좋아진다.**\n    - 단일 리더 설정에서는 리더가 있는 데이터센터가 고장 나면 장애 복구를 위해 다른 데이터센터에서 팔로워를 리더로 승진시킨다. 다중 리더 설정에서는 데이터센터가 독립적으로 동작하여 **데이터센터 중단 내성을 가진다.**\n    - 단일 리더 설정에서는 데이터센터 내 연결의 쓰기는 동기식이기 때문에 데이터센터 내 연결 문제에 매우 민감하다. 비동기 복제를 사용하는 다중 리더 설정은 네트워크 문제에 보다 잘 견딘다.\n- 다중 리더 복제에는 이점이 있지만 큰 단점도 있다.\n    - 동일한 데이터를 다른 두 개의 데이터 센터에서 동시에 변경할 수 있다. 이때 발생하는 쓰기 충돌은 반드시 해걀해야 한다.\n\n#### 오프라인 작업을 하는 클라이언트\n\n- 다중 리더 복제가 인터넷 연결이 끊어진 동안 애플리케이션이 계속 동작해야 하는 경우다.\n- 오프라인 상태에서 데이터를 변경하면 디바이스가 다음에 온라인 상태가 됐을 때 서버와 다른 디바이스를 동기화해야 한다.\n- 이 경우 모든 디바이스에는 리더처럼 동작하는 로컬 데이터베이스가 있다.\n- 그리고 모든 디바이스 상에서 복제 서버 간 다중 리더 복제를 비동기 방식으로 수행하는 프로세스(동기화)가 있다.\n\n#### 협업 편집\n\n- 동시에 여러 사람이 문서를 편집할 수 있는 애플리케이션을 실시간 협업 편집 애플리케이션이라고 한다.\n- 한 사용자가 문서를 편집할 때 변경 내용을 즉시 로컬 복제 서버에 적용하고 나서 동일한 문서를 편집하는 다른 사용자와 서버에 비동기 방식으로 복제한다.\n- 편집 충돌이 없음을 보장하려면 애플리케이션은 사용자가 편집하기 전에 문서의 잠금을 얻어야 한다.\n- 하지만 더 빠른 협업을 위해 변경 단위를 매우 작게(예를 들면 단일 키 입력) 해서 잠금을 피할 수 있다.\n\n### 쓰기 충돌 다루기\n\n- 다중 리더 복제에서 제일 큰 문제는 쓰기 충돌이 발생한다는 점이다.\n\n#### 동기 대 비동기 충돌 감지\n\n- 단일 리더 데이터베이스에서 첫 번째 쓰기가 완료될 때까지 두 번째 쓰기를 차단해 기다리게 하거나 두 번째 쓰기 트랜잭션을 중단해버린다.\n- 반면 다중 리더 설정에서는 두 쓰기는 모두 성공하며 충돌은 이후 특정 시점에서 비동기로만 감지한다.\n\n#### 충돌 회피\n\n- 충돌을 처리하는 제일 간단한 전략은 충돌을 피하는 것이다.\n- 특정 레코드의 모든 쓰기가 동일한 리더를 거치도록 애플리케이션이 보장한다면 충돌은 발생하지 않는다.\n- 예를 들어 애플리케이션에서 특정 사용자의 요청을 동일한 데이터센터로 항상 라우팅하고 데이터센터 내 리더를 사용해 읽기와 쓰기를 하게끔 보장할 수 있다.\n- 한 사용자 관점에서보면 구성은 기본적으로 단일 리더이다.\n\n#### 일관된 상태 수렴\n\n- 다중 리더 설정에서는 쓰기 순서가 정해지지 않아 최종 값이 무엇인지 명확하지 않다.\n- 단순하게 각 복제 서버가 쓰기를 본 순서대로 적용한다면 데이터베이스의 일관성은 없는 상태가 된다.\n- 충돌을 해소하는 방법은 다양하다.\n    - 각 쓰기에 고유 ID(타임스탬프, UUID 등)을 부여하고 가장 높은 ID를 가진 쓰기를 고른다.\n    - 각 복제 서버에 고유 ID를 부여하고 높은 숫자의 복제 서버에서 생신 쓰기가 낮은 숫자의 복제 서벙서 생신 쓰기보다 항상 우선적으로 적용되게 한다.\n    - 어떻게든 값을 병합한다. (예를 들면 사전순)\n    - 명시적 데이터 구조에 충돌을 기록해 모든 정보를 기록한다. 나중에 충돌을 해소하는 애플리케이션 코드를 작성한다.\n\n#### 사용자 정의 충돌 해소 로직\n\n- 충돌을 해소하는 가장 적합한 방법은 애플리케이션에 따라 다르다.\n- 대부분의 다중 리더 복제 도구는 애플리케이션 코드를 사용해 충돌 해소 로직을 작성한다.\n    - 쓰기 수행 중\n        - 복제된 변경 사항 로그에서 데이터베이스 시스템이 충돌을 감지하자마자 충돌 핸들러를 호출한다.\n    - 읽기 수행 중\n        - 충돌을 감지하면 모든 충돌 쓰기를 저장한다.\n        - 다음 번 데이터를 읽을 때 이런 여러 버전의 데이터가 애플리케이션에 반환된다.\n        - 애플리케이션은 사용자에게 충돌 내용을 보여주거나 자동으로 충돌을 해소할 수 있다.\n\n### 다중 리더 복제 토폴리지\n\n- 복제 토폴리지는 쓰기를 한 도느에서 다른 노드로 전달하는 통신 경로를 설명한다.\n- 리더가 둘 이상이라면 다양한 토폴로지 구성이 가능하다.\n    - **전체 연결(all-to-all)**\n        - 모든 리더가 각자의 쓰기를 다른 모든 리더에게 전송한다.\n    - **원형 토폴리지(circular topology)**\n        - 각 노드가 한의 노드로부터 쓰기르 받고, 이 쓰기를 다른 한 노드에 전달한다.\n    - **별 모양 토폴로지**\n        - 지정된 로트 노드 하나가 다른 모든 노드에 쓰기를 전달한다.\n- 원형과 별 모양 토폴리지의 문제점은 하나의 노드에 장애가 발생하면 장애가 다른 노드 간 복제 메시지 흐름에 방해를 준다.\n- 전체 연결 토폴로지는 여러 경로를 따라 이동할 수 있으며 단일 장애점을 피할 수 있기 때문에 내결함성이 좋다.\n- 하지만 일부 네트워크 연결이 다른 연결보다 빠르면 일부 복제 메시지가 다른 메시지를 추월하여 잘못된 순서로 메시지가 도착할 수 있다.\n\n## 리더 없는 복제\n\n- 일부 데이터 저장소 시스템은 리더의 개념을 버리고 모든 복제 서버가 클라이언트부터 쓰기를 직접 받을 수 있게 허용하는 접근 방식을 사용하기도 한다.\n- 리악, 카산드라, 볼드모트는 리더 없는 복제 모델의 오픈 소스 데이터스토어이고, 이런 종류의 데이터베이스를 다이나모 스타일이라고 한다.\n\n### 노드가 다운됐을 때 데이터베이스에 쓰기\n\n- 세 개의 복제 서버를 가진 데이터베이스가 있고 복제 서버 중 하나를 사용할 수 없다고 가정하자.\n    - 클라이언트가 쓰기를 세 개의 모든 복제 서버에 병렬로 전송한다.\n    - 사용 가능한 두 개의 복제 서버는 쓰기를 받았지만 사용 불가능한 복제 서버는 쓰기를 놓쳤다.\n    - 이제  사용할 수 없었던 노드가 온라인 상태가 되고 클라이언트가 이 노드에서 읽기를 시작한다.\n    - 따라서 클라이언트가 해당 노드에서 데이터를 읽는 다면 `오래된 값`을 얻을 수 있다.\n\n#### 읽기 복구와 안티 엔트로피\n\n- 복제 계획은 최종적으로 모든 데이터가 모든 복제 서버에 복사된 것을 보장해야 한다.\n- 다이나모 스타일 데이터스토어는 다음 두 가지 방법을 주로 사용한다.\n    - **읽기 복구**\n        - 클라이언트가 여러 노드에서 병렬로 읽기를 수행하면 오래된 응답을 감지할 수 있다.\n        - 클라이언트가 복제 서버에서 응답받은 값이 오래된 값이라는 사실을 알고 해당 복제 서버에 값을 다시 기록한다.\n        - 거의 읽지 않는 값은 일부 복제본에서 누락돼 내구성이 떨어진다.\n    - **안티 엔트로피 처리**\n        - 백그라운드 프로세스를 두고 복제 서버 간 데이터 차이를 지속적으로 찾아 누락된 데이터를 다른 서버로 복사한다.\n        - 리더 기반 복제에서의 로그와 달리 **안티 엔트로피 처리**는 특정 순서로 쓰기를 복사하기 때문에 상당한 지연이 있을 수 있다.\n\n#### 읽기와 쓰기를 위한 정족수(Quorum)\n\n- n개의 복제 서버가 있을 때 모든 쓰기는 w개의 노드에서 쓰기가 확정되고 모든 읽기는 최소한 r개의 노드에 질의해야 한다. `w + r > n` 이면 읽을 때 최신 값을 얻는 것으로 기대한다.\n- 최소한 r개의 노드 중 하나에서 최신 값을 읽을 수 있기 때문이다.\n- 이런 r 과 w를 따르는 읽기와 쓰기를 정속수(Quorum) 읽기와 쓰기라고 부른다.\n- 일반적인 선택은 n을 홀수(보통 3,5)로 하고 `w = r = (n+1) /2 (반올림)`로 설정한다.\n- 쓰기가 적고 읽기가 많은 작업부하는 `w=n, r= 1` 로 설정할 수 있다.\n\n### 정족수 일관성의 한계\n\n- `w + r > n` 이 되게끔 w와 r을 선택한다면 일반적으로 모든 읽기는 최신 값을 반환할 것으로 기대한다.\n- 하지만 `w + r > n` 인 경우에도 오래된 값을 반환하는 에지 케이스가 있다.\n    - 두 개의 쓰기가 동시에 발생하면 어떤 쓰기가 먼저 일어났는지 분명하지 않다.\n    - 쓰기와 읽기가 동시에 발생하면 쓰기는 일부 복제 서버에만 반영될 수 있다.\n    - 쓰기가 일부 복제 서버에서는 성공했지만 다른 복제 서버에서 실패해 전체 성공한 서버가 w 복제 서버 보다 적다면 읽기에 해당 쓰기 값이 반환될 수도 있고 아닐 수도 있다.\n    - 새 값을 전달하는 노드가 고장나면 예전 값을 가진 다른 복제 서버에서 해당 데이터가 복원되고 새로운 값을 저장한 복제 서버 수가 w보다 낮아져 정족수 조건이 깨진다.\n    \n\n#### 최신성 모니터링\n\n- 리더 기반 복제에서 데이터베이스는 복제 지연에 대한 지표를 모니터링 시스템에 제공된다.\n- 이것은 쓰기가 리더에 적용되고 같은 순서로 팔로워에도 적용되고 각 노드가 복제 로그의 위치를 가지기 때문에 가능하다.\n- 하지만 리더 없는 복제 시스템에서는 쓰기가 적용된 순서를 고정할 수 없어 모니터링이 더 어렵다.\n- 최종적 일관성은 의도적으로 모호한 보장이지만 운용성을 위해서는 “최종적을”을 정량화할 수 있어야 한다.\n\n### 느슨한 정족수와 암시된 핸드오프\n\n- 쓰기 가용성을 높이기 위해 정족수 w를 만족하지 않아도 일단 연결 할 수 있는 노드에 기록하는 방식을 `느슨한 정족수`라고 부른다.\n- 네트워크 장애 상황이 해제되면 한 노드가 다른 노드를 위해 일시적으로 수용한 모든 쓰기를 해당 홈 노드로 전송하는 방식을 암시된 핸드오프(hinted handoff)라고 한다.\n- 느슨한 정족수는 쓰기 가용성을 높이는데 유용하지만 `w + r > n`인 경우에도 키의 최신 값을 읽는다고 보장하지 않는다.\n\n### 동시 쓰기 감지\n\n- 다이나모 스타일 DB에서는 여러 클라이언트가 동시에 같은 키에 쓰는 것을 허용하기 때문에 엄격한 종속수를 사용하더라도 충돌이 발생한다.\n- **네트워크 지연과 부분적인 장애 때문에 쓰기 요청이 다른 노드에 다른 순서로 도착할 수 있다.**\n- 최종적인 일관성을 달성하기 위해 복제본들은 동일한 값이 돼야 한다.\n\n#### 최종 쓰기 승리(Last Write Wins, LWW)\n\n- 각 복제본이 가진 예전 값을 버리고 가장 최신 값으로  덮어쓰는 방법이다.\n- 클라이언트가 쓰기 요청을 데이터베이스 노드에 전송할 때 다른 클라이언트에 대해서는 아는 것이 없기 때문에 “최신”인지 명확하게 결정하기 어렵다.\n- 그래서 자연적인 순서는 없지만 타임스탬프 같은 임의로 순서를 정할 수 있다.\n    - LWW라 불리는 충돌 해소 알고리즘은 카산드라에서 유일하게 제공하는 충돌 해소 방법이다.\n- LWW는 지속성을 희생한다. 동일한 키에 여러 번의 동시 쓰기가 발생하면 쓰기 중 하나만 남고 다른 쓰기는 모두 무시된다.\n\n#### “이전 발생” 관계와 동시성\n\n- Insert 후 해당 데이터를 Update 하는 작업이 있을 때, Update 하는 작업은 Insert 작업 기반이기 때문에 B 작업은 나중에 발생해야 한다. 이를 B(update)는 A(insert)에 `인과성이 있다`고 한다.\n- 작업 B가 작업 A에 대해서 알거나 어떤 방식으로든 A에 의존적이라면 작업 A는 작업 B의 `이전 발생(heppens-befoe`이다.\n- 분산 시스템에서 두 작업이 정확히 같은 시각에 발생했는지 알기란 상당히 어렵다.\n- 동시성을 정의하기 위해 정확한 시각은 중요하지 않다. 두 작업이 발생한 물리적인 시각보다 각 작업이 서로 알지 못하면 단순히 두 작업은 동시에 수행됐다 말한다.\n\n#### 이전 발생 관계 파악하기\n\n- 서버는 버전 번호를 보고 두 작업이 동시에 수행됐는지 여부를 결정할 수 있다.\n    - 서버가 모든 키에 대한 버전 정보를 유지하고 키를 기록할 때마다 버전 정보를 증가시킨다.\n    - 클라이언트가 키를 읽을 때는 서버는 최신 버전뿐만 아니라 쓰기 전에 키값도 반환한다.\n    - 클라이언트가 키를 기록할 때는 이전 읽기의 버전 번호를 포함해야하고 이전 읽기에서 받은 모든 값을 함께 합쳐야 한다.\n    - 서버가 특정 버전 번호를 가진 쓰기를 받을 때 해당 버전 이하 모든 값을 덮어 쓸 수 있다. 이보다 높은 버전 번호의 모든 값은 유지해야 한다. 이 값들은 유입된 쓰기와 동시에 발생했기 때문이다.\n\n#### 동시에 쓴 값 병합\n\n- 여러 작업이 동시에 발생하면 클라이언트는 동시에 쓴 값을 합쳐 정리해야 한다. 이런 동시 값을 `형제(sibling) 값` 이라고 한다.\n- 간단한 접근 방식으로 버전 번호나 타임스탬프 기반으로 하나의 값을 선택하는 방법(LWW)이 있지만 데이터 손실이 생길 수 있다. 그래서 애플리케이션 코드 내에서 더욱 지능적으로 대처해야 한다.\n\n#### 버전 벡터\n\n## 정리\n\n- 복제는 다양한 용도로 사용할 수 있다.\n    - **고가용성**\n        - 한 장비가 다운될 때도 시스템이 계속 동작하게 된다.\n    - **연결이 끊긴 작업**\n        - 네트워크 중단이 있을 때도 애플리케이션이 계속 동작할 수 있게 한다.\n    - **지연 시간**\n        - 지리적으로 사용자에게 가까이 데이터를 배치해 사용자가 더 빠르게 작업할 수 있게 한다.\n    - **확장성**\n        - 복제본에서 읽기를 수행해 단일 장비에서 다룰 수 있는 양보다 많은 양의 읽기 작업을 처리할 수 있다.\n    \n- 복제에 대한 주요 접근 방식\n    - **단일 리더 복제**\n        - 클라이언트는 모든 쓰기를 단일 리더로 전송하고 리더는 데이터 변경 이벤트 스트림을 다른 복제 서버로 전송한다. 팔로워의 읽기가 오래된 값일 수도 있다.\n        - 이해하기 쉽고 충돌 해소에 대한  우려가 없어서 널리 사용된다.\n    - **다중 리더 복제**\n        - 클라이언트의 각 쓰기가 여러 리더로 전송될 수 있고 각 리더는 다른 리더와 팔로워에게 전송한다.\n    - **리더 없는 복제**\n        - 각 쓰기가 여러 노드로 전송할 수 있고, 클라이언트는 오래된 데이터를 감지하고 이를 바로잡기 위해 병렬로 여러 노드에서 읽는다.\n- 다중 리더 복제나 리더 없는 복제는 노드의 결함, 네트워크 중단, 지연 시간 급증이 있는 상황에서 견고하다. 하지만 어렵고 일관성이 거의 보장되지 않는다는 점이 단점이다.\n- 복제 지연으로 발생할 수 있는 이상 현상들\n    - **쓰기 후 읽기 일관성**\n        - 사용자는 자신이 제출한 데이터를 항상 볼 수 있어야 한다.\n    - **단조 읽기**\n        - 사용자가 어떤 시점에 데이터를 본 후에는 예전 시점의 데이터는 나중에 볼 수 없다.\n    - **일관된 순서로 읽기**\n        - 사용자는 인과성이 있는 상태의 데이터를 봐야 한다."},{"excerpt":"데이터 타입이나 스키마가 변경될 때 애플리케이션 코드에 대한 변경이 종종 발생한다. 하지만 대규모 애플리케이션에서 코드 변경은 대게 즉시 반영할 수 없다. 서버 측 애플리케이션에서는 한 번에 몇 개의 노드에 새 버전을 배포하고 새로운 버전이 원할하게 실행되는지 확인한 다음 서서히 모든 노드에서 실행되게 하는 방식이 있다. 클라이언트 측 애플리케이션은 사용…","fields":{"slug":"/ch4/"},"frontmatter":{"date":"January 18, 2022","title":"4장 - 부호화와 발전","tags":["데이터 중심 애플리케이션 설계"]},"rawMarkdownBody":"\n- 데이터 타입이나 스키마가 변경될 때 애플리케이션 코드에 대한 변경이 종종 발생한다.\n- 하지만 대규모 애플리케이션에서 코드 변경은 대게 즉시 반영할 수 없다.\n    - 서버 측 애플리케이션에서는 한 번에 몇 개의 노드에 새 버전을 배포하고 새로운 버전이 원할하게 실행되는지 확인한 다음 서서히 모든 노드에서 실행되게 하는 `순회식 업그레이드(rolling upgrade)`방식이 있다.\n    - 클라이언트 측 애플리케이션은 사용자에 전적으로 좌우된다. 어떤 사용자는 한동안 업데이트를 설치하지 않을 수도 있다.\n- 이것은 예전 버전의 코드와 새로운 버전의 코드, 이전의 데이터 타입과 새로운 데이터 타입이 모든 시스템에 동시에 공존할 수 있다는 의미이다.\n    - `하위 호환성 : 새로운 코드는 예전 코드가 기록한 데이터를 읽을 수 있어야 한다.`\n    - `상위 호환성 : 예전 코드는 새로운 코드가 기록한 데이터를 읽을 수 있어야 한다.`\n- 새로운 코드 쓰기는 예전 버전의 코드가 기록한 데이터의 형식을 알기에 명시적으로 해당 형식을 다룰 수 있기 때문에 `하위 호환성`을 일반적으로 어렵지 않다.\n- `상위 호환성`은 예전 버전의 코드가 새 버전의 코드에 의해 추가된 것을 무시할 수 있어야 하므로 다루기 더 어렵다.\n\n<!-- more -->\n\n# 데이터 부호화 형식\n\n프로그램은 보통 두 가지 형태로 표현된 데이터를 사용한다.\n\n- 메모리에 객체, 구조체, 리스트, 배열, 해시 테이블, 트리 등으로 데이터를 유지한다.\n    - 이런 데이터 구조는 CPU에서 효율적으로 접근하고 조작할 수 있게 최적화된다.\n- 데이터를 파일에 쓰거나 네트워크를 통해 전송하기 위해 바이트열의 형태로 부호화해야 한다.\n    - 일련의 바이트열은 보통 메모리에서 사용하는 데이터 구조와 상당히 다르다.\n- 인메모리 표현에서 바이트열로 전환을 `부호화(직렬화,마샬링)`이라 부른다.\n- 그 반대를 `복호화(파싱, 역직렬화, 언마샬링)`이라고 한다.\n\n### 언어별 형식\n\n- 많은 프로그래밍 언어는 인메모리 객체를 바이트열로 부호화하는 기능을 제공한다.\n    - 자바의 Serializable, 루비의 Marshal, 파이썬의 pickle 등\n- 프로그래밍 언어에 내장된 부호화 라이브러리는 편리하지만 심각한 문제점 또한 많다.\n    - 부호화는 보통 특정 프로그래밍 언어와 묶여 있어 다른 언어에서 데이터를 읽기 어렵다.\n    - 동일한 객체 유형의 데이터를 복원하려면 복호화 과정이 임의의 클래스를 인스턴스화할 수 있어야 한다. 이것은 종종 보안 문제의 원인이 된다.\n    - 데이터 버전 관리는 보통 나중에 생각하게 된다. 데이터를 빠르고 쉽게 부호화하기 위해 상위, 하위 호환성의 불편한 문제가 등한시되곤 한다.\n    - 자바의 내장 직렬화는 성능이 좋지 않고 비대해지는 부호화로 유명하다.\n    \n\n### JSON과 XML, 이진 변형\n\n- 수(number)의 부호화에는 많은 애매함이 잇다. XML과 CSV에서 number 와 숫자(digit)로 구성된 문자열을 구분할 수 있다. JSON은 문자열과 수를 구분하지만 정수와 부동소수점 수를 구별하지 않고 정밀도를 지정하지 않는다.\n- JSON과 XML은 유니코드(사람이 읽을 수 있는 텍스트)을 잘 지원하지만 이진 문자열을 지원하지 않는다. 이진 데이터를 Base64 텍스트로 부호화해 이런 제한을 피하지만 정공법과는 조금 다르다.\n- CSV는 스키마가 없으므로 각 로우와 컬럼의 의미를 정의하는 작업은 애플리케이션이 해야한다.\n\n### 이진 부호화\n\n- JSON과 XML은 이진 형식과 비교하면 둘다 훨씬 많은 공간을 사용한다.\n- 이런 관찰이 JSON 용으로 사용 가능한 다양한 이진 부호화의 개발로 이어졌지만 JSON과 XML의 텍스트 버전처럼 널리 채택되진 않았다.\n- JSON과 XML은 스키마를 사용하지 않기 때문에 부호화된 데이터 안에 모든 객체의 필드 이름을 포함해야 한다.\n\n```jsx\n{\n\t\"userName\" : \"Martin\"\n\t\"favoriteNumber\" : 1337,\n  \"interests\" : [\"daydreaming\", \"hacking\"]\n}\n```\n\n### 스리프트와 프로토콜 버퍼\n\n- 스리프트와 프로토콜 버퍼 모두 부호화할 데이터를 위한 스키마가 필요하다.\n- 프로토콜 버퍼로 정의한 스키마 예\n\n```jsx\nmessage Person {\n\trequired string user_name      = 1; # 필드 태그 1\n\toptional int64 favorite_number = 2; # 필드 태그 2\n\trepeated string interests      = 3; # 필드 태그 3\n}\n```\n\n- 스키마의 `필드 태그(field tags)`를 사용해서 필드 이름의 철자 없이도 어떤 필드를 다루는지 알려줄 수 있다.\n- 가변 길이 정수(variable-length integer)를 사용해서 더 적은 바이트로 숫자를 부호화할 수 있다.\n\n### 필드 태그와 스키마의 발전\n\n- 스키마는 시간이 지남에 따라 변한다. 이를 `스키마 발전(schema evolution)`이라고 한다.\n- 각 필드는 태그 숫자(1,2,3)로 식별하고 데이터 타입은 주석으로 단다.\n- 부호화된 데이터는 필드 이름을 전혀 참조하지 않기 때문에 스키마에서 필디 이름은 변경할 수 있다.\n- 그러나 필드 태그는 기존의 모든 부호화된 데이터를 인식 불가능하게 만들 수 있기 때문에 변경할 수 없다.\n- 필드에 새로운 태그 번호를 부여하는 방식으로 스키마에 새로운 필드를 추가할 수 있다. 이는 상위 호환성을 유지하게 한다. **즉 예전 코드가 새로운 코드로 기록된 레코드를 읽을 수 있다.**\n- 새로운 필드를 추가한 경우 이를 optional로 하거나 기본값을 가지게 하여 하위 호환성을 유지할 수 있다.\n\n### 데이터타입과 스키마 발전\n\n- 필드의 데이터타입을 변경하는 것은 불가능하지는 않지만 값이 정확하지 않거나 잘릴 위험이 있다.\n    - 예를 들어 32비트 정수를 64비트 정수로 바꾼다고 가정하자.\n    - 파서가 누락된 비트를 0으로 채울 수 있기 때문에 새로운 코드는 예전 코드를 읽을 수 있다. `(하위 호환성)`\n    - 새로운 코드가 기록한 데이터를 예전 코드가 읽는 경우 32비트로 읽게 되므로 값이 잘리게 된다. `(상위 호환성)`\n- 프로토콜 버퍼에는 목록이나 배열 데이터타입이 없지만 `repeated` 표시자가 있다.\n- 이것은 단일 값인 optional 필드를 다중값인 repeated 필드로 변경해도 문제가 없다.\n- 이전 데이터를 읽는 새로운 코드는 optional 로 읽게 되고, 새로운 데이터를 읽는 예전 코드는 목록의 마지막 엘리먼트만 보게 된다.\n\n### 스키마의 장점\n\n- 스키마 언어는 XML 스키마나 JSON 스키마보다 훨씬 간단하며 더 자세한 유효성 검사 규칙을 지원한다. `ex) “이 필드의 문자열 값은 이 정규 표현식에 일치해야 한다”`\n- 데이터베이스 벤더는 데이터베이스 네트워크 프로토콜로부터 응답을 인메모리 데이터 구조로 복호화하는 드라이버(ODBC, JDBC API)를 제공한다.\n- 부호화된 데이터에서 필드 이름을 생략할 수 있기 때문에 크기가 훨씬 작을 수 있다.\n- 스키마는 유용한 문서화 형식이다. 복호화할 때 스키마가 최신 상태인지를 확신할 수 있다.\n- 스키마 데이터베이스를 유지하면 스키마 변경이 적용되기 전에 상위 호환성과 하위 호환성을 확인할 수 있다.\n- 정적 타입 프로그래밍 언어 사용자에게 스키마로부터 코드를 생성하는 기능은 제공할 수 있다.\n\n# 데이터플로우(DataFlow) 모드\n\n- 데이터플로우는 매우 추상적인 개념으로서 하나의 프로세스에서 다른 프로세스로 데이터를 전달하는 방법은 아주 많다.\n    - 데이터베이스를 통해\n    - 서비스 호출을 통해\n    - 비동기 메시지 전달을 통해\n\n## 데이터베이스를 통한 데이터플로우\n\n- 데이터베이스에 기록하는 프로세스는 데이터를 부호화하고 데이터베이스에서 읽는 프로세스는 데이터를 복호화한다.\n- **이전에 기록한 내용을 미래의 자신이 복호화하기 위해 하위 호환성은 분명히 필요하다.**\n- 일반적으로 동시에 다양한 프로세스가 데이터베이스를 접근하는 일은 흔하다.\n- 일부 프로세스는 새로운 코드를 수행 중이고 일부 다른 프로세스는 예전 코드로 수행 중이라면, 순회식 업그레이드로 현재 새로운 버전을 배포하는 도중이라면 일부 인스턴스는 아직 갱신되지 않았지만 일부 인스턴스는 이미 갱신될 수 있다.\n- **이것은 데이터베이스 내 값이 새로운 버전의 코드로 기록된 다음 현재 수행 중인 예전 버전의 코드로 그 값을 읽을 가능성이 있기 때문에 상위 호환성도 필요하다.**\n- 새로운 버전의 애플리케이션이 기록한 데이터를 예전 버전의 애플리케이션에서 갱신하는 경우 데이터를 유시할 수 있기 때문에 주의가 필요하다.\n\n\n### 다양한 시점에 기록된 다양한 값\n\n- 애플리케이션의 새로운 버전을 배포할 때 몇 분내에 예전 버전을 새로운 버전으로 완전히 대체할 수 있지만 데이터베이스는 그렇지 않다.\n- 5년된 데이터는 그 이후로 명시적으로 다시 기록하지 않는 한 원래의 부호화 상태 그대로 있다. 이런 상황을 `데이터가 코드보다 더 오래 산다(data outlives code)`라 한다.\n- 데이터를 새로운 스키마로 다시 기록(마이그레이션)하는 작업은 가능하다. 하지만 대용량 데이터셋 대상으로는 값비싼 작업이기 때문에 이런 상황을 피한다.\n- 대부분의 관계형 데이터베이스는 기존 데이터를 다시 기록하지 않고 널을 기본값으로 갖는 새로운 컬럼을 추가하는 간단한 스키마 변경을 허용한다. `(MySQL은 전전체 테이블을 다시 기록한다.)`\n- 링크드인 문서 데이터베이스인 에스프레소는 아브로 스키마 발전 규칙을 사용한다.\n\n## 서비스를 통한 데이터플로우: REST와 RPC\n\n- 네트워크를 통해 통신해야 하는 프로세스가 있을 때 해당 통신을 배치하는 가장 일반적인 방법은 **클라이언트와 서버의 두 역할로 배치한다.**\n- 웹 브라우저를 위해 서버로 `GET, POST` 요청을 통해 모든 웹 브라우저로 모든 웹사이트를 접속할 수 있다.\n- 모바일 디바이스나 데스크톱 앱을 통해 서버에 요청할 수 있다. 이 경우 서버 응답은 보통 사람이 볼 수 있게 표시하는 JSON 같은 데이터를 많이 사용한다.\n- 서버 자체가 다른 서비스의 클라이언트일 수 있다. 하나의 서비스가 다른 서비스의 일부 기능이나 데이터가 필요하다면 해당 서비스에 요청을 보낸다. 이런 개발 방식을 전통적으로 서비스 지향 설계, 최근에는 마이크로서비스 설계라고 한다.\n- 서비스 지향 및 마이크로서비스 아키텍처의 핵심 설계 목표는 서비스를 배포와 변경에 독립적으로 만들어 애플리케이션 변경과 유지보수를 더 쉽게 할 수 있게 만드는 것 이다.\n- 각 서비스는 한 팀이 소유해야 하고 해당 팀은 다른 팀과의 조정 없이 자주 서비스의 새로운 버전을 출시할 수 있어야 한다.\n- **따라서 서버와 클라이언트가 사용하는 데이터 부호화는 서비스 API의 버전 간 호환이 가능해야한다.**\n\n### 웹 서비스\n\n- 웹 서비스에는 대중적인 `REST`와 `SOAP`가 있다.\n- `REST` 는 프로토콜이 아니라 HTTP의 원칙을 토대로 한 설계 철학이다.\n- `REST` 는 간단한 데이터 타입을 강조하며 URL을 사용해 리소스를 식별하고 캐시 제어, 인증, 콘텐츠 유형 협상에 HTTP 기능을 사용한다.\n- `SOAP` 는 네트워크 API 요청을 위한 XML 기반 프로토콜이다.\n- HTTP와 독립적이며 대부분의 HTTP 기능을 사용하지 않는다.\n- `SOAP` 웹 서비스의 API는 웹 서비스 기술 언어(WSDL)의 XML 기반 언어를 사용해 기술한다.\n- WSDL은 클라이언트가 로컬 클래스와 메서드 호출을 사용해 원격 서비스에 접근하는 코드 생성이 가능하다.\n- WSDL은 사람이 읽을 수 있게 설계하지 않았고 SOAP 메시지를 수동으로 구성하기에는 너무 복잡하기 때문에 SOAP 사용자는 도구 지원과 코드 생성과 IDE에 크게 의존한다.\n\n### 원격 프로시저 호출(RPC) 문제\n\n- 웹 서비스는 네트워크 상에서 API 요청을 하기 위한 여러 기술 중 하나이다.\n    - EJB, RMI 는 자바로만 제한된다.\n    - 분산 컴포넌트 객체모델(DCOM)은 마이크로소프트 플랫폼으로 제한된다.\n    - 공통 객체 요청 브로커 설계(CORBA)는 지나치게 복잡하고 하위,상위 호환성을 제공하지 않는다.\n- 이러한 웹 서비스는 원격 프로시저 호출(RPC)의 아이디어를 기반으로 한다.\n- RPC 모델은 원격 네트워크 서비스 요청을 같은 프로세스 안에서 특정 프로그래밍 언어의 함수나 메서드를 호출하는 것과 동일하게 사용 가능하게 해준다.\n- RPC 가 처음에는 편리한 것 같지만 근본적으로 결함이 있다.\n    - 로컬 함수는 예측 가능하다. 그래서 제어 가능한 매개변수에 따라 성공하거나 실패한다.\n    - 네트워크 요청은 어렵다. 네트워크 문제로 요청과 응답이 유실되거나 요청에 응답하지 않을 수 있다.\n    - 예를 들어 실패한 요청을 다시 보내는 것과 같은 대첵을 세워야 한다.\n    \n1. *네트워크 요청은 타임아웃으로 결과 없이 반환될 수 있다.*\n2. *실패한 네트워크 요청을 다시 시도할 때 요청이 실제로는 처리되고 응답만 유실될 수 있다. 이 경우 프로토콜에 중복 제거기법을 적용하지 않으면 재시도는 작업이 여러번 수행되는 원인이 된다.*\n3. *네트워크 요청은 함수 호출보다 훨씬 느리고 지연 시간은 매우 다양하다.*\n4. *네트워크 요청은 모든 매개변수를 네트워크로 전송할 수 있게끔 바이트열로 부호화해야한다.*\n5. *클라이언트와 서비스는 다른 프로그래밍 언어로 구현할 수 있다. 모든 언어가 같은 타입을 가지는 것은 아니기에 깔끔하지 않는 모습이 될 수 있다.*\n\n### RPC의 현재 방향\n\n- gRPC는 프로토콜 버퍼를 이용한 RPC 구현이다.\n- 차세대 RPC 프레임워크는 원격 요청이 로컬 함수 호출과 다르다는 사실을 더욱 분명히 한다.\n- Rest.li는 실패할지도 모를 비동기 작업을 캡슐화하기 위해 `퓨처(future)`를 사용한다.\n- REST 상에서 JSON과 같은 부류의 프로토콜보다 이진 부호화 형식을 사용하는 사용자 정의 RPC 프로토콜이 우수한 성능을 제공할 수 도 있다.\n- RESTful API는 다른 중요한 이점이 있다.\n    - 테스트와 디버깅에 적합(웹 브라우저나 curl을 사용해 간단히 요청을 보낼 수 있다)\n    - 모든 주요 프로그래밍 언어와 플랫폼이 지원하고 사용 가능한 다양한 도구 생태계(서버, 캐시 로드 밸런서, 프록시, 방화벽, 모니터링, 디버깅 도구, 테스팅 도구)등이 있다.\n\n## 메시지 전달 데이터 플로\n\n- RPC와 데이터베이스 간 비동기 메시지 전달 시스템을 살펴본다.\n- 이 시스템은 클라이언트 요청을 낮은 지연 시간으로 다른 프로세스에 전달한다는 점에서는 RPC와 비슷하다.\n- 메시지를 직접 네트워크 연결로 전송하지 않고 임시로 메시지를 저장하는 `메시지 브로커(message broker)(또는 메시지 큐)나 메시지 지향 미들웨어` 라는 중간 단계를 거쳐 전송한다는 점은 데이터베이스와 유사하다.\n- 메시지 브로커를 사용하는 방식은 직접 RPC를 사용하는 방식과 비교했을 때 여러 장점이 있다.\n    - 수신자가 사용 불가능하거나 과부하 상태라면 메시지 브로커가 버퍼처럼 동작할 수 있기 때문에 시스템 안정성이 향상된다.\n    - 죽었던 프로세스에 메시지를 다시 전달할 수 있기 때문에 메시지 유실을 방지할 수 있다.\n    - 송신자가 수신자의 IP 주소나 포트 번호를 알 필요가 없다.\n    - 하나의 메시지를 여러 수신자로 전송할 수 있다.\n    - 논리적으로 송신자는 수신자와 분리된다.\n- 메시지 전달 통신은 일반적으로 단방향이라는 점이 RPC와 다르다.\n- 대게 송신 프로세스는 메시지에 대한 응답을 기대하지 않는다.\n\n### 메시지 브로커\n\n- 프로세스 하나가 메시지를 이름이 저장된 큐나 토픽으로 전송하고 브로커는 해당 큐나 토픽 하나 이상의 소비자 또는 구독자에게 메시지를 전달한다.\n- 동일한 토픽에 여러 생산자와 소비자가 있을 수 있다.\n- 토픽은 단방향 데이터 플로우만 제공한다.\n- 하지만 소비자 스스로 메시지를 다른 토픽으로 게시하거나 원본 메시지의 송신자가 소비하는 응답 큐로 게시할 수 있다.\n- 메시지는 일부 메타데이터를 가진 바이트열로 모든 부호화 형식을 사용할 수 있다.\n- **부호화가 상하위 호환성을 모두 가진다면 메시지 브로커에서 게시자와 소비자를 독립적으로 변경해 임의 순서로 배포할 수 있는 유연성을 얻게 된다.**\n\n### 분산 액터 프레임워크\n\n- **액터 모델(actor model)**은 단일 프로세스 안에서 동시성을 위한 프로그래밍 모델이다.\n- 스레드를 직접 처리하는 대신 로직이 액터에 캡슐화 된다.\n- 액터는 하나의 클라이언트나 엔티티를 나타낸다.\n- 액터는 로컬 상태를 가질 수 있고 비동기 메시지의 송수신으로 다른 액터와 통신한다.\n- 각 액터 프로세스는 한 번에 하나의 메시지만 처리하기 때문에 스레드에 대해 걱정할 필요가 없고 각 액터는 프레임워크와 독립적으로 실행할 수 있다.\n- 이 프로그래밍 모델은 여러 노드 간의 애플리케이션 확장에 사용된다.\n- 송신자와 수신자가 같은 노드에 있는지 다른 노드에 있는지 관계없이 동일한 메시지 전달 구조를 사용한다.\n- 다른 노드에 있는 경우 메시지는 명백하게 바이트열로 부호화되고 네트워크를 통해 전송되며 다른 쪽에서 복호화한다.\n- 액터 모델은 단일 프로세스 안에서도 메시지가 유실될 수 있다고 가정하기 때문에 위치 투명성은 RPC보다 액터 모델에서 더 잘 동작한다.\n\n# 정리\n\n- 데이터 구조를 네트워크나 디스크 상의 바이트열로 변환하는 다양한 방법이 있다.\n- 이런 부호화의 세부 사항은 효율성뿐만 아니라 애플리케이션의 아키텍처와 배포의 선택 사항에도 영향을 미친다.\n- 많은 서비스가 새로운 버전의 서비스를 동시에 모든 노드에 배포하는 방식보다 한 번에 일부 노드에만 서서히 배포하는 순회식 업그레이드가 필요하다.\n- 순회식 업그레이드는 정지 시간 없이 새로운 버전의 서비스를 출시 가능하게 하고 배포를 덜 위험하게 만든다.\n- 여러 가지 다른 이유로 다양한 노드에서 다른 버전의 여러 애플리케이션 코드가 실행될 수 있다.\n- 따라서 시스템을 흐르는 모든 데이터는 하위 호환성, 상위 호환성을 제공하는 방식으로 부호화해야 한다."},{"excerpt":"데이터베이스를 강력하게 만드는 데이터 구조 일반적으로 파일 추가 작업은 매우 효율적이기 때문에 로그(log)를 기록할 때 파일을 사용한다. 하지만 파일에서 특정 로그키를 찾을 때마다  만큼 걸리기 때문에 성능이 매우 좋지 않다. 데이터베이스에서 특정 키의 값을 효율적으로 찾기 위해서는 가 필요하다. 색인의 일반적인 개념은 어떤 부가적인 메타데이터를 유지하…","fields":{"slug":"/ch3/"},"frontmatter":{"date":"January 14, 2022","title":"3장 - 저장소와 검색","tags":["데이터 중심 애플리케이션 설계"]},"rawMarkdownBody":"\n# 데이터베이스를 강력하게 만드는 데이터 구조\n\n- 일반적으로 파일 추가 작업은 매우 효율적이기 때문에 로그(log)를 기록할 때 파일을 사용한다.\n- 하지만 파일에서 특정 로그키를 찾을 때마다 `O(n)` 만큼 걸리기 때문에 성능이 매우 좋지 않다.\n- 데이터베이스에서 특정 키의 값을 효율적으로 찾기 위해서는 `색인구조`가 필요하다.\n- 색인의 일반적인 개념은 어떤 부가적인 메타데이터를 유지하는 것이다.\n- 색인을 잘 선택했다면 **읽기 질의 속도가 향상되지만** **모든 색인은 쓰기 속도를 떨어뜨린다**.\n\n<!-- more -->\n\n### 해시 색인\n\n- 키-값 데이터를 색인하기 위해 보통 해시 맵으로 구현한다.\n- `모든 키값과 매핑되는 바이트 오프셋을 유지하는 방법`\n    - 매우 단순하지만 해시 맵을 전부 메모리에 유지하기 때문에 고성능으로 읽기, 쓰기가 보장된다.\n    - 각 키의 값이 자주 갱싱되는 상황에 매우 적합하다.\n    - 예를 들어 키는 동영상 URL 이고, 값은 비디오가 재생된 횟수인 경우다.\n    - 이런 유형의 작업부하에서는 쓰기가 아주 많지만 고유 키는 많지 않다.\n    - 하지만 용량에 커지게 된다면 결국 디스크 공간이 부족해진다.\n- 특정 크기의 세그먼트로 로그를 나누는 방식\n    - 특정 크기에 도달하면 세그먼트 파일을 닫고 새로운 세그먼트 파일에 이후 쓰기를 수행한다.\n    - 컴팩션(compation)은 로그에서 중복된 키를 버리고 각 키의 최신 갱신 값만 유지하는 것을 의미한다.\n\n\n### 추가 전용 쓰기 설계는 낭비인가?\n\n- 추가와 세그먼트 병합은 순차적인 쓰기 작업이기 때문에 무작위 쓰기보다 훨씬 빠르다.\n- 세그먼트 파일이 추가 전용이나 불변이면 동시성과 고장 복구는 훨씬 간단하다.\n- 오래된 세그먼트 병합은 시간이 지남에 따라 조각화되는 데이터 파일 문제를 피할 수 있다.\n\n### 해시 테이블 색인의 제한사항\n\n- 해시 테이블은 메모리에 저장해야 하므로 키가 너무 많으면 문제가 된다.\n- 해시 테이블은 범위 질의에 효율적이지 않다.\n\n### SS테이블과 LSM 트리\n\n- 키-값 쌍을 가지는 세그먼트 구조에서 키-값 쌍을 키로 정렬하는 것을  정렬된 문자열 테이블(SS) 테이블이라고 한다.\n- SS 테이블은 해시 색인을 가진 로그 세그먼트보다 몇 가지 큰 장점이 있다.\n    - 각 세그먼트들이 정렬되어 있기 때문에 병합정렬 알고리즘이 사용가능하다.\n    - 세그먼트 병합이 파일이 사용 가능한 메모리보다 크더라도 간단하고 효율적이다.\n    - 파일에서 특정 키를 찾기 위해 메모리에 모든 키의 색인을 유지할 필요가 없다.\n    - 읽기 요청은 요청 범위 내에서 여러 키-값을 스캔해야 하기 때문에 해당 레코드들을 블록으로 그룹화하고 디슼에 쓰기 전에 압축한다.\n    \n\n### SS테이블 생성과 유지\n\n- B 트리 구조를 사용해서 디스크상에 정렬된 구조를 유지할 수 있다.\n- 하지만 레드 블랙 트리나 AVL 트리로 메모리에 유지하는 편이 훨씬 쉽다.\n    - 쓰기가 들어오면 인메모리 균형 트리 데이터구조에 추가한다. 이 인메모리 트리는 **멤테이블(memtable)** 이라고 한다.\n    - 멤테이블의 메가바이트 정도의 임곗값보다 커지면 SS테이블 파일로 디스크에 기록한다. **트리가 이미 키로 정렬되어 있기 때문에 효율적으로 수핼할 수 있다.**\n    - 새로운 SS테이블 파일은 데이터베이스의 가장 최신 세그먼트가 된다. SS테이블을 디스크에 기록하는 동안 쓰기는 새로운 멤테이블에 계속 된다.\n    - 읽기 요청을 제공하려면 먼저 멤테이블에서 키를 찾고, 디스크 상의 가장 최신 세그먼트순으로 찾는다.\n    - 세그먼트 파일을 합치고 덮어 쓰여지거나 삭제된 값을 버리는 병합과 컴팩션 과정을 백그라운드로 수행한다.\n- 데이터베이스가 고장나면 디스크에 기록되지 않고 멤테이블에 있는 가장 최신 쓰기가 손실된다.\n- 이 문제를 피하기 위해서 매번 쓰기를 즉시 추가할 수 있게 분리된 로그를 디스크 상에 유지해야된다.\n\n### SS테이블에서 LSM 트리 만들기\n\n- 이런 알고리즘은 키-값 저장소 엔진 라이브러리에서 사용된다.\n- 구글의 빅테이블, 카산드라, HBase 등에서도 유사한 저장소 엔진을 사용한다.\n- 원래 이 색인 구조는 `로그 구조화 병합 트리(Log-Structured Merge-Tree)(또는 LSM 트리)`라고 부른다.\n\n### 성능 최적화\n\n- LSM 트리 알고리즘은 데이터베이스에 존재하지 않는 키를 찾는 경우 느릴 수 있다.\n- 멤테이블에 확인한 다음 키가 존재하지 않는다는 사실을 확인하기 전에는 가장 오래된 세그먼트까지 거슬러 올라가야 한다.\n- 이런 종류의 접근을 최적화하기 위해 저장소 엔진은 보통 **블룸 필터(Bloom filter)**를 추가적으로 사용한다.\n- 블룸 필터는 키가 데이터베이스에 존재하지 않음을 알려주므로 존재하지 않는 키를 불필요한 디스크 읽기를 많이 절약할 수 있다.\n- SS테이이블을 압축하고 병합하는 순서와 시기를 결정하는 전략으로 **크기 계층(size-triered)과 레벨 컴팩션(leveled compaction)**가 있다.\n- 사이즈 계층 컴팩션은 상대적으로 좀 더 새롭고 작은 SS테이블을 상대적으로 오래됐고 큰 SS테이블에 연이어 병합한다.\n- 레벨 컴팩션은 키 범위를 더 작은 SS테이블을 나누고 오래된 데이터는 개별 레벨로 이동하기 때문에 컴팩션을 점진적으로 진행해 디스크 공간을 덜 사용한다.\n\n### B 트리\n\n- 가장 널리 사용되는 색인 구조는 **B트리(B-tree)** 이다.\n- 앞에서 살펴본 LSM 트리는 수 메가바이트 이상의 가변 크기를 가진 세그먼트로 나누고 순차적으로 세그먼트를 기록한다.\n- 반면 B트리는 4KB 크기의 고정 크기 블록이나 페이지로 나누고 한 번에 하나의 페이지에 읽기 또는 쓰기를 한다.\n- 디스크가 고정 크기 블록으로 배열되기 때문에 이런 설게는 근본적으로 하드웨어와 조금 더 밀접하 관련이 있다.\n- 하나의 페이지는 B 트리의 루트(root)로 지정되고, 페이지는 여러 키와 하위 페이지의 참조를 포함한다.\n- 각 하위 페이지는 키가 이어지는 범위를 담당하고 참조 사이의 키는 해당 범위 경계가 어디인지 나타낸다.\n- 탐색을 위해서 루트에서 시작하여 페이지 경계 사이로 페이지 참조를 따라가고 최종적으로 **리프 페이지(leaf page)**를 포함하는 페이지에 도달한다.\n- B 트리에서 한 페이지에서 하위 페이지를 참조하는 수를 `분기 계수(bracning factor)` 라고 부르고, 분기 계수는 페이지 참조와 범위 경계를 저장할 공간의 양에 의존적인데 보통 수백게에 달한다.\n- B 트리에 존재하는 **키의 값을 갱신하려면** 키를 포함하고 있는 리프 페이지를 검색하고 페이지의 값을 바꾼 다음 페이지를 디스크에 다시 기록한다.\n- 새로운 키를 추가하려면 새로운 키를 포함하는 범위의 페이지를 찾아 해당 페이지에 키와 값을 추가한다.\n- 새로운 키를 수용한 페이지에 충분한 여유 공간이 없다면 페이지 하나를 반쯤 채워진 페이지 둘로 나누고 상위 페이지가 새로운 키 범위의 하위 부분들을 알 수 있게 생긴한다.\n- 이 알고리즘은 트리가 계속 균형을 유지하는 것을 보장한다.\n- 분기 계수 500의 4KB 페이지의 4단계 트리는 256TB까지 저장할 수 있다.\n\n### 신뢰할 수 있는 B 트리 만들기\n\n- B 트리의 기본적인 쓰기 동작은 새로운 데이터를 디스크 사으이 기존 페이지에 덮어쓴다.\n- 즉, 페이지를 덮어쓰더라도 페이지를 가르키는 모든 참조는 변하지 않는다.\n- LSM 트리와 같은 로그 구조화 색인과는 대조적인 점이다.\n- B 트리의 삽입 과정 중 페이지가 너무 커져 페이지를 나눠야 할 때, 데이터베이스가 고장 난다면 색인이 훼손될 수 있기 때문에 이것은 위험한 동작이다.\n- 데이터베이스가 고장 상황에서 스스로 복구할 수 있게 만들려면 디스크 상에 `쓰기 전 로그(write,ahead log, WAL)(재실행 로그(redo log)`라고 하는 데이터 구조를 추가할 수 있다.\n- 쓰기 전 로그는 트리 페이지에 변경된 내용을 적용하기 전에 모든 B트리의 변경사항을 기록하는 추가 전용 로그이다.\n- 같은 자리에 페이지를 갱신하는 작업할 때, 다중 스레드가 동시에 B 트리에 접근한다면 주의 깊게 동시성 제어를 해야 한다.\n- 동시성 제어는 보통 래치(latch)로 트리의 데이터 구조를 보호한다.\n\n### B 트리 최적화\n\n- 쓰기전 로그(WAL) 유지 대신 일부 데이터 베이스는 `쓰기 시 복사 방식(copy-on-write schem)`을 사용한다. 변경된 페이지는 다른 위치에 기록하고 트리에 상위 페이지의 새로운 버전을 만들어 새로운 위치를 가르키게 한다.\n- 페이지 전체 키가 저장하는게 아니라 키를 축약해 쓰면 공간을 절약할 수 있다. 키가 키 범위 사이의 경계 역할을 하는 데 충분한 정보만 제공하면 된다. 페이지 하나에 키를 더 많이 채우면 트리는 더 높은 분기 계수를 얻는다. 트리 깊이 수준을 낮출 수 있다.\n- B 트리 구현에서 리프 페이지를 디스크 상에 연속된 순서로 나타나게끔 트리르 배치한다.\n    - 일반적으로 페이지는 디스크 상에 위치할 수 있다. 질의가 정렬된 순서로 키 범위의 상단 부분을 스캔해야 된다면 모든 페이지에 대해 디스크 찾기가 필요하기 때문에 비효율적이다.\n    - 하지만 트리가 커지면 순서를 유지하기 어렵다. 반대로 LSM 트리는 병합하는 과정에서 저장소의 큰 세그먼트를 한 번에 다시 쓰기 때문에 디스크에서 연속된 키를 서로 가깝게 유지하기 쉽다.\n- 트리에 포인터를 추가한다. 각 리프 페이지의 양쪽 형제 페이지에 대한 참조를 가지면 상위 페이지로 다시 이동하지 않아도 순서대로 키를 스캔할 수 있다.\n\n### LSM 트리의 장점\n\n- B 트리보다 쓰기 처리량을 높게 유지할 수 있다.\n    - B 트리 색인은 모든 데이터 조각을 최소한 두 번 기록해야 한다.\n    - 해당 페이지내 몇 바이트만 바뀌어도 한 번에 전체 페이지를 기록해야 하는 오버헤드도 있다.\n    - 로그 구조화 색인 또한 SS 테이블의 반복된 컴팩션과 병합으로 여러 번 데이터를 쓴다.\n    - 데이터베이스에 쓰기 한 번이 데이터베이스 수명 동안 디스크에 여러 번의 쓰기를 야기하는 이렇ㄴ 효과를 쓰기 증폭이라 한다.\n    - LSM 트리가 상대적으로 쓰기 증폭이 더 낮다. 트리에서 여러 페이지를 덮어쓰는 것이 아니라 순차적으로 컴팩션된 SS테이블 파일을 쓰기 떄문이다.\n- LSM 트리는 압축률이 더 좋다.\n    - B 트리 저장소 엔진은 파편화로 인해 사용하지 않는 디스크 공간 일부가 남는다.\n    - LSM 트리는 페이지 지향적이지 않고 주기적으로 파편화를 없애기 위해 SS테이블을 다시 기록하기 때문에 저장소 오버헤드가 더 낮다.\n\n### LSM 트리의 단점\n\n- 컴팩션 과정이 때로는 진행 중인 읽기와 쓰기의 성능에 영향을 준다.\n    - 디스크에서 비싼 컴팩션 연산이 끝날 때까지 요청이 대기해야 하는 상황이 발생하기 쉽다.\n    - B 트리의 성능은 로그 구조화 저장소 엔진보다 예측하기 쉽다.\n- 컴팩션 문제는 높은 쓰기 처리량에서 발생한다.\n    - 초기 쓰기(로깅)과 멤테이블을 디스크로 플러싱과 백그라운드에서 수행되는 컴팩션 스레드가 이 대역폭을 공유해야 한다.\n    - 데이터베이스가 점점 커질수록 컴팩션을 위해 더 많은 디스크 대역폭이 필요하다.\n- 쓰기 처리량이 높음에도 컴팩션 설정을 주의 깊게 하지 않으면 컴팩션 유입 쓰기 속도를 따라갈 수 가없다.\n- 로그 구조화 저장소 엔진은 다른 세그먼트에 같은 키의 다중 복사본이 존재할 수 있다.\n    - B 트리의 장점은 각 키가 색인의 한 곳에만 정확하게 존재한다는 점이다.\n    - 강력한 트랜잭션 시맨틱을 제공하는 데이터베이스에는 B 트리가 훨씬 매력적이다.\n\n### 기타 색인 구조\n\n- 키-값 색인의 대표적인 예는 관계형 모델의 **기본키(primary key) 색인**이다.\n- `보조 색인(secondary index)`을 사용하는 방식도 매우 일반적이다. 보조 색인은 키-값 색인에서 쉽게 생성할 수 있다.\n- 기본키 색인과 주요 차이점은 키가 고유하지 않다는 점 이다.\n\n### 색인 안에 값 저장하기\n\n- 색인에서 키는 질의가 검색하는 대상이지만 값은 다음의 두 가지 중 하나에 해당한다.\n- 값은 질의의 실제 로우(문서, 정점)이거나 다른 곳에 저장된 로우를 가르키는 참조다.\n- 후자의 경우 로우가 저장된 곳을 `힙 파일(heap file)`이라고 한다.\n    - 여러 보조 색인이 존재할 때 힙 파일 접근은 중복된 데이터를 피할 수 있다.\n    - 힙 파일 접근 방식은 키를 변경하지 않고 값을 갱신할 때 꽤 효율적이다.\n- 색인 안에 색인된 로우를 저장하는 방식을 클러스터드 `색인(clustered index)`이라고 한다.\n- `클러스터드 색인(색인 안에 모든 로우 데이터를 저장)`과 비클러스터드 `색인(색인 안에 데이터의 참조만 저장)` 사이의 절충안을 **커버링 색인(convering index)**이라 한다.\n- 이 색인은 색인 안에 테이블의 컬럼 일부를 저장한다. 이렇게 하면 일부 질의에 대해서 색인만 사용해 응답이 가능하다. `(이런 경우를 색인이 질의를 커버했다고 말한다)`\n\n### 다중 컬럼 색인\n\n- 다중 컬럼 색인의 가장 일반적인 유형은 `결합 색인(concatenated index)`이라고 한다.\n- 결합 색인은 하나의 컬럼에 다른 컬럼을 추가하는 방식으로 하나의 키에 여러 필드를 단순히 결합한다.\n- 이 방법은 **(성, 이름)**을 키로 전화번호를 값으로 하는 색인을 제공하는 방식과 유사하다.\n- 순서가 정렬돼 있기 때문에 특정 성을 가진 모든 사람을 찾거나 특정 성 이름을 조합을 가진 모든 사람을 찾을 때도 이 색인을 사용할 수 있다.\n- 하지만 특정 이름을 가진 모든 사람을 찾을 때는 쓸모가 없다.\n\n### 모든 것을 메모리에 보관\n\n- 지금까지 설명한 데이터 구조는 모두 디스크 한계에 대한 해결책이었다.\n- 인메모리 데이터베이스도 지속성을 목표로 특수 하드웨어를 사용하거나 디스크에 변경 사항의 로그를 기록하거나 디스크에 주기적인 스냅숏을 기록하거나 다른 장비에 인메로리 상태를 복제하는 방법이 있다.\n- 레디스는 비동기로 디스크에 기록하기 때문에 약한 지속성을 제공한다.\n\n### 트랜잭션 처리나 분석\n\n<aside>\n💡 트랜잭션이 반드시 ACID 속성을 가질 필요는 없다. 트랜잭션 처리는 주기적으로 수행되는 일괄 처리 작업과 달리 클라이언트가 지연 시간이 낮은 읽기와 쓰기를 가능하게 한다는 의미다.\n\n</aside>\n\n- 비록 데이터베이스가 많은 여러 종류의 데이터를 사용하기 시작했지만 기본적인 접근 패턴은 비지니스 트랜잭션 처리와 유사하다.\n- 보통 애플리케이션은 색인을 사용해 일부 키에 대한 적은 수의 레코드를 찾는다. 레코드는 사용자 입력을 기반으로 삽입되거나 갱신된다.\n- 이런 애플리케이션은 대화식이기 때문에 이 접근 패턴을 `온라인 트랜잭션 처리(OLTP)` 라고 한다.\n- 다른 패턴으로 많은 수의 레코드를 스캔해 레코드 당 일부 컬럼만 읽어 집계 통계를 계산해야 한다.\n- 이런 질의는 보통 비지니스 분석가가 작성하며 회사 경영진이 더 나은 의사결정을 하게끔 돕는 보고서를 제공한다. 이런 데이터베이스 사용 패턴을 `온라인 분석 처리(OLAP)`라고 한다.\n- 처음에는 트랜잭션 처리와 분석 질의를 위해 동일한 데이터베이스를 사용했다.\n- 이와 관련해서 SQL은 OLTP, OLAP 유형 질의 모두 잘 동작했다.\n- 몇몇 회사들은 OLAP를위한 개별 데이터베이스에서 분석을 수행하기도 했다. 이 개별 데이터베이스를 `데이터 웨어하우스(data warehouse)`라고 한다.\n\n| 특성 | 트랜잭션 처리 시스템(OLTP) | 분석 시스템(OLAP) |\n| --- | --- | --- |\n| 주요 읽기 패턴 | 질의당 적은 수의 레코드, 키 기준으로 가져옴 | 많은 레코드에 대한 집계 |\n| 주요 쓰기 패턴 | 임의 접근, 사용자 입력을 낮은 지연 시간으로 기록 | 대규모 불러오기 또는 이벤트 스트림 |\n| 주요 사용처 | 웹 애플리케이션을 통한 최종 사용자 | 의사결정 지원을 위한 내부 분석가 |\n| 데이터 표현 | 데이터의 최신 상태 | 시간이 지나며 일어난 이벤트 이력 |\n| 데이터셋 크기 | 기가바이트에서 테라바이트 | 테라바이트에서 페타바이트 |\n\n### 데이터 웨어하우징\n\n- OLTP 시스템은 대개 사업 운영에 대단히 중요하기 때문에 높은 가용성과 낮은 지연 시간의 트랜잭션 처리를 기대한다.\n- 데이터 웨어하우스는 분석가들이 OLTP 작업에 영향을 주지 않고 마음껏 질의할 수 있는 개별 데이터베이스이다.\n- 데이터 웨어하우스는 회사 내의 모든 다양한 OLTP 시스템에 있는 데이터의 읽기 전용 복사본이다.\n- 데이터는 OLTP 데이터베이스에서 주지적인 데이터 덤프나 지속적인 갱신 스트림을 사용해 추출하고 분석 친화적인 스키마로 변환하고 깨끗하게 정리한 다음 데이터 웨어하우스에 적재한다. 이런 과정을 `ETL(Extract-Transform-Load)`이라한다.\n\n\n### OLTP 데이터베이스와 데이터 웨어하우스의 차이점\n\n- SQL은 일반적으로 분석 질의해 적합하기 때문에 데이터 웨어하우스의 데이터 모델은 가장 일반적인 관계형 모델을 사용한다.\n- 표면적으로 데이터 웨어하수으와 관계형 OLTP 데이터베이스 둘 다 SQL 질의 인터페이스를 지원하기 때문에 비슷해 보인다.\n- 하지만 각각 매우 다른 질의 패턴에 맞게 최적화됐기 때문에 시스템 내부는 완전히 다르다.\n- 데이터 웨어하우스의 대표적인 예로 SQL 온 하둡, 아파치 하이브, 스파크 SQL, 클라우데라 임팔라, 페이스북 프레스토, 아파치 타조, 아파치 드릴 등이 있다."},{"excerpt":"데이터  모델은 소프트웨어가 할 수 있는 일과 할 수 없는 일에 지대한 영향을 주므로 애플리케이션에 적합한 데이터 모델을 선택하는 작업은 상당히 중요하다. 관계형 모델과 문서 모델 오늘날 가장 장 알려진 데이터 모델은 관계형 모델을 기반으로 한 SQL 이다. 데이터는 관계(relation) 로 구성되고 각 관계는 순서 없는 튜플(tuple) 의 모음이다.…","fields":{"slug":"/ch2/"},"frontmatter":{"date":"January 10, 2022","title":"2장 - 데이터 모델과 질의 언어","tags":["데이터 중심 애플리케이션 설계"]},"rawMarkdownBody":"\n데이터  모델은 소프트웨어가 할 수 있는 일과 할 수 없는 일에 지대한 영향을 주므로 애플리케이션에 적합한 데이터 모델을 선택하는 작업은 상당히 중요하다.\n\n<!-- more -->\n\n# 관계형 모델과 문서 모델\n\n- 오늘날 가장 장 알려진 데이터 모델은 관계형 모델을 기반으로 한 SQL 이다.\n- 데이터는 **관계(relation)** 로 구성되고 각 관계는 순서 없는 **튜플(tuple)** 의 모음이다.\n\n### NoSQL의 탄생\n\n- 2010년대에 NoSQL은 관계형 모델의 우위를 뒤집으려는 가장 최신 시도이다.\n- NoSQL 데이터베이스를 채택한 데는 다음과 같은 다양한 원동력이 있다.\n    - 대규모 데이터셋이나 매우 높은 쓰기 처리량 달성을 관계형 데이터베이스보다 쉽게 할 수 있는 뛰어난 확장성의 필요\n    - 상용 데이터베이스 제품보다 무료 오픈소스 소프트웨어에 대한 선호도 확산\n    - 관계형 모델에서 지원하지 않는 특수 질의 동작\n    - 관계형 스키마 제한에 대한 불만과 더욱 동적이고 표현력이 풍부한 데이터 모델에 대한 바람\n    \n\n### 객체 관계형 불일치\n\n- 객체지향 프로그램에서 데이터를 관계형 테이블에 저장하려면 애플리케이션 코드와 데이터베이스 모델 객체 사이에 거추장스러운 전환 계층이 필요하다.\n- 이런 모델 사이의 분리를 **임피던스 불일치(impedance mismatch)** 라고 부른다.\n- 관계형 스키마로 표현한 이력서 예시\n- 이력서 같은 데이터 구조는 모든 내용을 갖추고 있는 문서라서 JSON 표현에 매우 적합하다.\n- 몽고DB, 링싱크DB, 카우치DB, 에스프레소 같은 문서 지향 데이터베이스는 JSON 데이터 모델을 지원한다.\n\n### 다대일과 다대다 관계\n\n- 관계형 데이터베이스 예시 그림에서 `region_id` 와 `industry_id`는 평문인 `“그레이터 시애틀 구역”` 과 `“자선활동”`이 아닌 ID로 주어졌다. 왜 일까?\n- 지역과 업계의 표준 목록으로 드롭다운 리스트나 자동 완성 기능을 만들어 사용자가 선택하게 하는 데는 다음과 같은 장점이 있다.\n    - 프로필 간 일관된 스타일과 철자\n    - 모호함 회피 `(예를 들어 이름이 같은 여러 도시가 있는 경우)`\n    - 갱신의 편의성, 이름이 한 곳에만 저장되므로 이름을 변경해야 하는 경우 전반적으로 갱신하기 쉽다.\n    - 현지화 지원, 사이트를 다른 언어로 번역할 때 표준 목록을 현지화해 지역과 업계 사이트를 보는 사람의 언어로 표시할 수 있다.\n    - 더 나은 검색\n- ID나 텍스트 문자열의 저장 여부는 중복의 문제이다.\n    - ID를 사용하게 되면 한 곳에만 저장하고 다른 곳에서 모두 참조를 한다.\n    - 텍스트를 직접 저장한다면 그것을 사용하는 모든 레코드에서 정보를 중복해서 저장하게 된다.\n- 중복된 데이터를 정규화하려면 **다대일 관계**가 필요하다.\n    - 관계형 데이터베이스는 조인이 쉽기 때문에 ID로 다른 테이블의 로우를 참조하는 방식은 일반적이다.\n    - 문서 모델에서 조인에 대한 지원이 약하기 때문에 다대일 관계는 적합하지 않다.\n- 애플리케이션의 초기 버전이 조인 없는 문서 모델에 적합하더라도 애플리케이션 기능이 추가하면서 데이터는 점차 상호 연결되는 경향이 있다.\n    - 이력서의 새로운 기능으로 한 사용자가 또 다른 사용자를 위해 추천서를 작성하는 기능을 넣는다고 해보자.\n    - 추천서는 추천받은 사용자 이력서에는 추천인의 이름과 사진이 함께 보여진다.\n    - 추천인이 자신의 프로필을 갱신한다면 추천인이 작성한 모든 추천서 역시 갱신되어야 한다.\n\n### 문서 데이터베이스는 역사를 반복하고 있나?\n\n- 1970년대 비지니스 데이터를 처리를 위해 가장 많이 사용한 데이터베이스는 **정보 관리 시스템(IMS)** 로 지금의 JSON 모델과 놀랍게도 비슷하다.\n- 문서 데이터베이스처럼 IMS도 일대다 관계에서는 잘 동작한다.\n- 하지만 다대다 관계표현은 어렵고 조인은 지원하지 않는다.\n- 이러한 계층 모델의 한계를 해결하기 위해 관계형 모델과 네트워크 모델이 나왔다.\n\n### 네트워크 모델\n\n- 계층 모델의 트리 구조에서 모든 레코드는 정확하게 하나의 부모가 있다.\n- 네트워크 모델에서 레코드는 다중 부모가 있을 수 있다.\n- 네트워크 모델에서 레코드 간 연결은 프로그래밍 언어의 포인터와 유사하다.\n- 레코드에 접근하는 유일한 방법은 최상위 레코드에서부터 연속된 연결 경로를 따르는 방법이다.\n- 데이터베이스 질의와 갱신을 위한 코드가 복잡하고 유연하지 못한 문제가 있었다.\n\n### 관계형 모델\n\n- 관계형 모델이 하는 일은 알려진 모든 데이터를 배치하는 것이다.\n- 관계형 데이터베이스에서 질의 최적화기(query optimizer)는  질의의 어느 부분을 어떤 순서로 실행할지를 결정하고 사용할 색인을 자동으로 결정한다.\n- 질의 최적화기를 한번 만들면 데이터베이스를 사용하는 모든 애플리케이션이 혜택을 받을 수 있다.\n\n### 문서 데이터베이스와의 비교\n\n- 문서 데이터베이스는 별도의 테이블이 아닌 상위 레코드 내에 중첩된 레코드를 저장한다.\n- 하지만 다대일과 다대다 관계를 표현할 때 관계형 데이터베이스와 문서 데이터베이스는 근본적으로 다르지 않다. 둘 다 관련 항목은 고유한 식별자로 참조한다.\n- 관계형 모델에서는 **외래 키**라 부르고 문서 모델에서는 **문서 참조**라 부른다.\n\n### 관계형 데이터베이스와 오늘날의 문서 데이터베이스\n\n- 문서 데이터 모델을 선호하는 이유는 스키마 유연성, 지역성에 기인한 더 나은 성능때문이고, 일부 애플리케이션의 경우 애플리케이션에서 사용하는 데이터 구조와 더 가깝기 때문이다.\n- 관계형 모델은 조인, 다대일, 다대다 관계를 더 잘 지원함으로써 문서 데이터 모델에 대항한다.\n\n### 어떤 데이터 모델이 애플리케이션 코드를 더 간단하게 할까?\n\n- 애플리케이션에서 데이터가 문서와 비슷한 구조`(일대다 관계 트리로 보통 한 번에 전체 트리를 적재)`라면 문서 모델을 사용하는 것이 좋다.\n- 문서 모델의 제한은 문서 내 중첩 항목을 바로 참조할 수 없어서 `\"사용자 251의 직위 목록의 두 번쨰 항목\"`과 같이 표현해야 한다.\n- **애플리케이션에서 다대다 관계를 사용한다면 관계형 모델이 적합하다.**\n- 비정규화로 조인의 필요성이 줄이기가 가능하지만 애플리케이션 코드는 비정규화된 데이터의 일관성을 유지하기 위해 추가 작업을 해야한다.\n- 일반적으로 어떤 데이터 모델이 애플리케이션 코드를 더 간단하게 만드는지 말할 수 없다.\n- 상호 연결이 많은 데이터의 경우 그래프 모델은 매우 자연스럽다.\n\n### 문서 모델에서의 스키마 유연성\n\n- 대부분의 문서 데이터베이스와 관계형 데이터베이스에서 지원하는 JSON은 문서의 데이터에 어떤 스키마를 강요하지 않는다.\n- 스키마가 없다는 뜻은 임의의 키와 값을 문서에 추가할 수 있고 읽을 때 클라이언트는 문서에 포함된 필드의 존재 여부를 보장하지 않는다는 의미다.\n- 문서 데이터베이스는 종종 스키마리스(schemaless)로 불리지만 데이터베이스가 이를 강요하지 않을 뿐, 암묵적인 스키마`(쓰기 스키마, 읽기 스키마)`가 존재한다.\n- 읽기 스키마는 프로그래밍 언어에서 동적 타입 확인과 유사하고 쓰기 스키마는 정적 타입 확인과 비슷하다.\n- 읽기 스키마 접근 방식은 컬렉션 안의 항목이 어떤 이유로 모든 동일한 구조가 아닐 때 유용하다.\n\n### 정리\n\n- 역사적으로 데이터를 하나의 큰 트리(계층 모델)로 표현하려고 노력했지만 다대다 관계를 표현하기에는 트리 구조가 적절하지 않았다.\n- 이 문제를 해결하기 위해 관계형 모델이 고안됐다.\n- 최근에는 관계형 모델에도 적합하지 않은 애플리케이션이 있다는 사실을 발견했고 새롭게 등장한 비관계형 데이터저장소인 NoSQL은 다음과 같은 두 가지 주요 갈래가 있다.\n    - `문서 데이터베이스`는 데이터가 문서 자체에 포함돼 있으면서 하나의 문서와 다른 문서 간 관계가 거의 없는 사용 사례를 대상으로 한다.\n    - `그래프 데이터베이스`는 문서 데이터베이스와는 정반대로 모든 것이 잠재적으로 관련 있다는 사용 사례를 대상으로 한다.\n- 한 모델을 다른 모델로 흉내 낼 수 있지만, 대부분 엉망이다. 각기 목적에 맞는 다양한 시스템을 보유해야 된다.\n- 문서 및 그래프 데이터베이스가 가진 공통점 중 하나는 일반적으로 저정할 데이터를 위한 스키마를 강제하지 않아 변화하는 요구사항에 맞춰 애플리케이션을 쉽게 변경할 수 있다는 점이다."},{"excerpt":"일반적으로 데이터 중심 애플리케이션은 다음을 필요로 한다. 구동 애플리케이션이나 다른 애플리케이션에서 나중에 다시 데이터를 찾을 수 있게 데이터를 저장 (데이터베이스) 읽기 속도 향상을 위해 값비싼 수행결과를 기억 (캐시) 사용자가 키워드로 데이터를 검색하거나 다양한 방법으로 필터링 할 수 있게 제공 (검색 색인, search Index) 비동기 처리를 …","fields":{"slug":"/ch1/"},"frontmatter":{"date":"January 05, 2022","title":"1장 - 신뢰할 수 있고 확장 가능하며 유지보수하기 쉬운 애플리케이션","tags":["데이터 중심 애플리케이션 설계"]},"rawMarkdownBody":"\n일반적으로 데이터 중심 애플리케이션은 다음을 필요로 한다.\n\n- 구동 애플리케이션이나 다른 애플리케이션에서 나중에 다시 데이터를 찾을 수 있게 데이터를 저장 **(데이터베이스)**\n- 읽기 속도 향상을 위해 값비싼 수행결과를 기억 **(캐시)**\n- 사용자가 키워드로 데이터를 검색하거나 다양한 방법으로 필터링 할 수 있게 제공 **(검색 색인, search Index)**\n- 비동기 처리를 위해 다른 프로세스로 메시지 보내기 **(스트림 처리, stream processing)**\n- 주기적으로 대량의 누적된 데이터를 분석 **(일괄 처리, batch Processing)** \n\n애플리케이션마다 요구사항이 다르기 때문에 어떤 도구와 어떤 접근 방식이 수행 중인 작업에 가장 적합한지 생각해야 한다.\n\n<!-- more -->\n\n# 신뢰성(Reliability)\n\n하드웨어나 소프트웨어 결함, 인적 오류(humman error) 같은 역경에 직면하더라도 시스템은 지속적으로 올바르게 동작해야 한다.\n\n- 잘못될 수 있는 일을 **결함(fault)** 이라 부른다. 결함을 예측하고 대처할 수 있는 시스템을 **내결함성(fault-tolerant)** 또는 **탄력성(resilient)** 을 지녔다고 말한다.\n- 모든 종류의 결함을 견딜 수 있는 시스템을 만드는 것은 실현 가능하지 않다. 따라서 특정 유형의 **결합 내성**에 대해서만 이야기하는 것이 가능하다.\n- 결합은 장애(failure)와 동일하지 않다. 결함은 사양에서 벗어난 시스템의 한 구성 요소로 정의되지만, **장애**는 사용자에게 필요한 서비스를 제공하지 못하고 시스템 전체가 멈춘 경우다.\n- 결함 확률을 0으로 줄이는 것은 불가능하다. 따라서 결함으로 인해 장애가 발생하지 않게끔 내결함성 구조를 설계하는 것이 가장 좋다.\n\n### 하드웨어 결함\n\n하드디스크가 고장 나고, 램의 고장, 대규모 정전과 같은 결합을 말한다.\n\n- 각 해드웨어 구성 요소에 중복을 추가하는 방법이 일반적이다.\n\n### 소프트웨어 결함\n\n- 소프트웨어 결함을 유발하는 버그는 특정 상황에 의해 발생하기 전까지 오랫동안 나타나지 않는다.\n- 소프트웨어의 체계적 오류 문제는 신속한 해결책이 없다. 시스템의 가정과 상호작용에 대해 주의 깊게 생각하기, 빈틈없는 테스트, 프로세스 격리, 죽은 프로세스의 재시작 허용, 프로덕션 환경의 시스템 동작의 측정, 모니터링, 분석하기와 같은 여러 작은 일들이 문제 해결에 도움을 줄 수 있다.\n\n### 인적 오류\n\n- 대규모 인터넷 서비스에 대한 한 연구에 따르면 운영자의 설정 오류가 중단의 주요 원인이다.\n- 최고의 시스템은 다양한 접근 방식을 결합한다.\n    - 오류의 가능성을 최소화하는 방향으로 설계해라. 잘 설계된 추상화, API, 관리 인터페이스를 사용하면\n    - 실제 데이터를 사용해 안전하게 살펴보고 실험할 수 있지만 실제 사용자에게는 영향이 없는 비 프로덕션 샌드박스를 제공하라\n    - 단위 테스트부터 전체 시스템 통합 테스트와 수동 테스트까지 모든 수준에서 철저하게 테스트하라.\n    - 장애 발생의 영향을 최소화하기 위해 인적 오류를 빠르게 쉽게 복구할 수 있게 하라.\n    - 성능 지표와 오류율 같은 상세하고 명확한 모니터링 대책을 마련하라.\n    - 조작 교육과 실습을 시행하라.\n    \n\n# 확장성(Scalability)\n\n시스템의 데이터 양, 트래픽 양, 복잡도가 증가하면서 이를 처리할 수 있어야 한다.\n\n### 부하 기술하기\n\n부하는 **부하 매개변수(load parameter)** 라 부르는 몇 개의 숫자로 나타낼 수 있다. **웹 서버의 초당 요청 수, 데이터베이스 읽기 대 쓰기 비율, 대화방의 동시 활성 사용자, 캐시 적중률** 등이 될 수 있다.\n\n### 트위터의 예\n\n- 트위터의 주요 두 가지 동작은 다음과 같다.\n    - `트윗 작성 : 사용자는 팔로워에게 새로운 메시지를 개시할 수 있다.`\n    - `홈 타임라인 : 사용자는 팔로우한 사람이 작성한 트윗을 볼 수 있다.`\n- 트위터의 확장성 문제는 트윗 작성이 아닌 팔로우 한 사용자들의 트윗의 수신 문제이다.\n- 이 두가지 동작을 구현하는 방법은 크게 두 가지이다.\n    - 접근 방식 1\n        - 사용자가 자신의 홈 타임라인을 요청하면, 팔로우하는 모든 사람을 찾고, 이 사람들의 모든 트윗을 찾아 시간순으로 정렬하도록 쿼리한다.\n        \n    - 접근 방식 2\n        - 각 수신 사용자용 홈 타인라인 캐시를 유지한다. 사용자가 트우잇을 작성하면 해당 사용자를 팔로우하는 사람을 모두 찾고 각자의 홈 타임라인 캐시에 새로운 트윗을 삽입한다.\n        \n\n- 평균적으로 트윗 게시 요청량이 홈 타임라인 읽기 요청량에 비해 수백 배 적기 때문에 접근 방식2가 훨씬 잘 작동한다.\n- 팔로워가 매우 많다면, 단일 트윗을 쓰기하는데 3천만 건 이상의 쓰기 요청이 될 수 있다.\n- 트위터 사례에서 사용자당 팔로워 분포는 핵심 부하 매개변수가 된다.\n- 트위터는 대부분의 사용자 트윗은 `접근 방식(2)`를 사용하고, 팔로워 수가 매우 많은 소수 사용자는 `접근 방식(1)`처럼 읽는 시점에 사용자의 홈 타임라인에 합친다.\n\n### 성능 기술하기\n\n시스템 부하를 기술하면 부하가 증가할 때 어떤 일이 일어나는지 조사할 수 있다.\n\n- 부하 매개 변수를 증가시키고, 시스템 자원은 변경하지 않고 유지하면 시스템 성능은 어떻게 영향을 받을까?\n- 부하 매개변수를 증가시켰을 때 성능이 변하지 않고 유지되길 원한다면 얼마나 많이 자원을 늘려야할까?\n- 위 두 질문 모두 성능 수치가 필요하다.\n    - 일괄 처리 시스템의 관심사는 **처리량(throughput)**\n    - 온라인 시스템의 관심사는 **응답 시간(response time)**\n    \n\n### 응답시간은 일반적으로 평균보다는 백분위(percentile)를 사용하는 편이 더 좋다.\n\n- 사용자가 보통 얼마나 오랫동안 기다려야 하는지 알고 싶다면 중앙값(p50)이 좋은 지표다.\n- 특이 값이 얼마나 좋지 않는지 알아보려면 상위 백분위를 살펴보는 것이 좋다.\n- `95분위, 99분위, 99.9분위(p55, p99, p999)`가 일반적이다.\n- 예를 들어, 95분위 응답시간이 1.5초라면 100개의 요청 중 95개는 1.5초 미만이고, 5개는 1.5초보다 더 걸린다.\n- **꼬리 지연 시간(tail latency)** 으로 알려진 상위 백분위 응답 시간은 서비스의 사용자 경험에 직접 영향을 주기 때문에 영향을 준다.\n- 아마존은 응답 시간 요구사항을 99.9분위로 기술한다. 왜냐하면 느린 요청을 경험한 고객들이 더 많은 데이터를 가지고 있고 VIP 이기 때문이다.\n\n### 부하 대응 접근 방식\n\n- **용량 확장(scaling up, 수직 확장)** : 좀 더 강력한 장비로 이동\n- **규모 확장(scaling out, 수평 확장)** : 다수의 낮은 사양 장비에 부하를 분산 → 비공유 아키텍처라 부름\n- 범용적이고 모든 상황에 맞는 마법의 확장 아키텍처는 없다.\n    - 예를 들어 크기가 1KB인 초당 100,000건의 요청을 처리하도록 설계된 시스템과 크기가 2GB인 분당 3건의 요청을 처리하기 위해 설계된 시스템은 서로 같은 데이터 처리량이라 해도 매우 다르다.\n- 아키텍처를 결정하는 요소는 **읽기의 양, 쓰기의 양, 저장할 데이터의 양, 데이터 복잡도, 응답 시간 요구사항, 접근 패턴 등이 있다.**\n- 특정 애플리케이션에 적합한 확장성을 갖춘 아키텍처는 주요 동작이 무엇이고 잘 하지 않는 동작이 무엇인지에 대한 가정을 바탕으로 구축한다. 이 가정이 곧 **부하 매개변수**가 된다.\n- 부가 매개변수의 대한 가정이 잘못되면 엔지니어링 노력은 헛수고가 되고 최악의 경우 역효과를 낳는다.\n- 확장성을 갖춘 아키텍처는 보통 익숙한 패턴으로 나열된 범용적인 구성 요소로 구축된다.\n\n# 3. 유지보수성(Maintainability)\n\n- 시간이 지남에 따라 여러 다양한 사람들이 시스템 상에서 작업할 것이기 때문에 모든 사용자가 시스템 상에서 생산적으로 작업할 수 있게 해야한다.\n- 소프트웨어 비용의 대부분은 초기 개발이 아니라 지속해서 이어지는 유지보수에 들어간다.\n    - 버그 수정, 시스템 운영 유지, 장애 조사, 새로운 플랫폼 적응, 새 사용 사례를 위한 변경, 기술 채무 상환, 새로운 기능 추가 등이 있다.\n- 유지보수 고통을 최소화하기 위해 소프트웨어 시스템 설계 원칙은 다음 세 가지다.\n\n### 1. 운용성(operability)\n\n> 운영팀이 시스템을 원활하게 운영할 수 있게 쉽게 만들어라.\n> \n- 좋은 운영성이란 동일하게 반복되는 태스크를 쉽게 수행하게끔 만들어 운영팀이 고부가가치 활동에 노력을 집중한다는 의미이다.\n    - 좋은 모니터링으로 런타임 동작과 시스템의 내부의 대한 가시성 제공\n    - 표준 도구를 이용해 자동화와 통합을 위한 우수한 자원을 제공\n    - 개별 장비 의존성을 회피, 유지보수를 위해 장비를 내리더라도 시스템 전체에 영향을 주지 않고 계속해서 운영 가능해야 함\n    - 좋은 문서와 이해하기 쉬운 운영 모델 제공\n    - 만족할 만한 기본 동작을 제공하고, 필요할 때 기본값을 다시 정의할 수 있는 자유를 관리자에게 부여\n    - 적절하게 자기 회복이 가능할 뿐 아니라 필요에 따라 관리자가 시스템 상태를 수동으로 제어할 수 있게 함\n    - 예측 가능하게 동작하고 예기치 않은 상황을 최소화함\n\n### 2. 단순성(simplicity)\n\n> 시스템에서 복잡도를 최대한 제거해 새로운 엔지니어가 시스템을 이해하기 쉽게 만들어라.\n> \n- 소규모 소프트웨어 프로젝트에서는 간단하고 표현이 풍부한 코드로 말끔하게 시스템을 작성할 수 있지만 프로젝트가 커짐에 따라 시스템은 매우 복잡하고 이해하기 어려워 진다.\n- 복잡도는 다양한 증상으로 나타난다.\n    - 상태 공간의 급증, 모듈 간 강한 커플링, 복잡한 의존성, 일관성 없는 네이밍과 용어, 성능 문제 해결을 목표로 한 해킹, 임시방편으로 문제를 해결한 특수 사례 등\n- 우발적 복잡도란 소프트웨어가 풀어야 할 문제에 내제하지 않고 구현에서만 발생하는 것으로 정의된다.\n- 우발적 복잡도를 제거하기 위한 최상의 도구는 **추상화**다.\n- 좋은 추상화는 다른 다양한 애플리케이션에서도 사용 가능하다. 이런 재사용은 비슷한 기능을 재구현하는 것보다 효율적이고 고품질 소프트웨어로 이어진다.\n\n### 3. 발전성(evolvability)\n\n> 엔지니어가 이후에 시스템을 쉽게 변경할 수 있게 하라. 그래야 요구사항 변경 같은 예기치 않은 사용 사례를 적용하기가 쉽다.\n> \n- 조직 프로세스 측면에서 **애자일** 작업 패턴은 변화에 적응하기 위한 프레임워크를 제공한다.\n- TDD, 리팩토링 같이 자주 변화하는 환경에서 소프트웨어를 개발할 때 도움이 되는 기술 도구와 패턴을 개발하고 있다.\n\n# 정리\n\n- 애플리케이션이 유용하려면 다양한 요구사항을 충족시켜야 한다.\n- `기능적 요구사항` :  여러 방법으로 데이터를 저장하고 조회하고 검색하고 처리하게끔 허용하는 작업과 같이 해야하는 일\n- `비기능적 요구사항` : 보안, 신뢰성, 법규 준수, 확장성, 호환성, 유지보수성과 같은 일반 속성\n- 신뢰성은 결함이 발생해도 시스템이 올바르게 동작하게 만든다는 의미이다.\n- 확장성은 부하가 증가해도 좋은 성능을 유지하기 위한 전략을 의미한다.\n- 유지보수성에는 시스템에서 작업하는 엔지니어와 운영 팀의 삶을 개선하는데 있다."}]}},"pageContext":{}},"staticQueryHashes":[],"slicesMap":{}}